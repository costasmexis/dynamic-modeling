{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from machinelearning_control_fedbatch import generate_dataset, main\n",
    "\n",
    "from src.utils import get_data_and_feed, plot_experiment\n",
    "\n",
    "FILENAME = '../data/data_processed.xlsx'\n",
    "EXPERIMENT = 'BR01'\n",
    "S_IN = 1.43 * 200\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (12, 8)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_df, feeds = get_data_and_feed(\n",
    "    file_name=FILENAME, experiment=EXPERIMENT, keep_only=\"FB\"\n",
    ")\n",
    "\n",
    "full_df['Biomass'].iloc[1] = 5.0\n",
    "\n",
    "# add new line to full_df to simulate an extra data point\n",
    "new_row = pd.DataFrame([{\"Process\": \"FB\", \"RTime\": 5.85, \"V\": 1.56, \"Biomass\": 5.8, \"Glucose\": 0.013, \"Protein\": 0.0}])\n",
    "full_df = pd.concat([full_df, new_row], ignore_index=True)\n",
    "full_df.sort_values(by=\"RTime\", inplace=True)\n",
    "\n",
    "T_FB = full_df[\"RTime\"].iloc[0] # Time of fed-batch\n",
    "T_START = 0\n",
    "T_END = full_df[\"RTime\"].iloc[-1] - T_FB  # End of experiment\n",
    "\n",
    "# inlet flowrate\n",
    "def Fs(t):\n",
    "    if t <= 4.73 - T_FB:\n",
    "        return 0.017\n",
    "    elif t <= 7.33 - T_FB:\n",
    "        return 0.031\n",
    "    elif t <= 9.17 - T_FB:\n",
    "        return 0.060\n",
    "    elif t <= 9.78 - T_FB:\n",
    "        return 0.031\n",
    "    else:\n",
    "        return 0.017\n",
    "\n",
    "# Get initial volume\n",
    "V0 = full_df[\"V\"].iloc[0]\n",
    "\n",
    "# Normalize time\n",
    "full_df[\"RTime\"] = full_df[\"RTime\"] - T_FB\n",
    "feeds[\"Time\"] = feeds[\"Time\"] - T_FB\n",
    "\n",
    "print(f\"Dataset shape: {full_df.shape}\")\n",
    "\n",
    "plot_experiment(full_df, title='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Define the new RTime points for interpolation\n",
    "new_RTime = np.arange(0, 6, 0.5)\n",
    "\n",
    "# Create interpolation functions for V, Biomass, and Glucose\n",
    "interp_V = interp1d(full_df['RTime'], full_df['V'], kind='linear', fill_value='extrapolate')\n",
    "interp_Biomass = interp1d(full_df['RTime'], full_df['Biomass'], kind='linear', fill_value='extrapolate')\n",
    "interp_Glucose = interp1d(full_df['RTime'], full_df['Glucose'], kind='linear', fill_value='extrapolate')\n",
    "\n",
    "# Interpolate the values at new RTime points\n",
    "new_V = interp_V(new_RTime)\n",
    "new_Biomass = interp_Biomass(new_RTime)\n",
    "new_Glucose = interp_Glucose(new_RTime)\n",
    "\n",
    "# Create a DataFrame for the interpolated results\n",
    "full_df = pd.DataFrame({\n",
    "    'RTime': new_RTime,\n",
    "    'V': new_V,\n",
    "    'Biomass': new_Biomass,\n",
    "    'Glucose': new_Glucose,\n",
    "    'Induction': [0] * len(new_RTime)\n",
    "})\n",
    "\n",
    "plot_experiment(full_df, title='Interpolated data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RTime</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biomass</th>\n",
       "      <td>4.163095</td>\n",
       "      <td>19.016762</td>\n",
       "      <td>10.759339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014468</td>\n",
       "      <td>0.009626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>1.554241</td>\n",
       "      <td>1.868158</td>\n",
       "      <td>1.654907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              min        max       mean\n",
       "RTime    0.000000   5.500000   2.750000\n",
       "Biomass  4.163095  19.016762  10.759339\n",
       "Glucose  0.000000   0.014468   0.009626\n",
       "V        1.554241   1.868158   1.654907"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df[['RTime', 'Biomass', 'Glucose', 'V']].describe().T[['min', 'max', 'mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1000, 5)\n"
     ]
    }
   ],
   "source": [
    "# Get dataset (multiple initial conditions)\n",
    "in_train, out_train = generate_dataset(data=full_df, num_points=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_start = 0.0\n",
      "T_end = 5.5\n"
     ]
    }
   ],
   "source": [
    "# parameter values\n",
    "mumax = 0.7267     # 1/hour\n",
    "Ks = 0.1634          # g/liter\n",
    "Yxs = 0.3983         # g/g\n",
    "Sin = 1.43 * 200  # g/liter\n",
    "\n",
    "t_start = full_df['RTime'].iloc[0]\n",
    "t_end = full_df['RTime'].iloc[-1]\n",
    "\n",
    "# initial conditions\n",
    "V0 = full_df['V'].iloc[0]\n",
    "S0 = full_df['Glucose'].iloc[0]\n",
    "X0 = full_df['Biomass'].iloc[0]\n",
    "\n",
    "print(f'T_start = {t_start}')\n",
    "print(f'T_end = {t_end}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss_data: 54.5393, Loss_ode: 16.3721\n",
      "Current learning rate:  0.0001\n",
      "Epoch 10, Loss_data: 30.0977, Loss_ode: 4.0910\n",
      "Current learning rate:  0.0001\n",
      "Epoch 20, Loss_data: 22.1808, Loss_ode: 3.9810\n",
      "Current learning rate:  0.0001\n",
      "Epoch 30, Loss_data: 20.2663, Loss_ode: 3.9362\n",
      "Current learning rate:  0.0001\n",
      "Epoch 40, Loss_data: 19.3342, Loss_ode: 3.8896\n",
      "Current learning rate:  0.0001\n",
      "Epoch 50, Loss_data: 18.6164, Loss_ode: 3.8459\n",
      "Current learning rate:  0.0001\n",
      "Epoch 60, Loss_data: 17.9876, Loss_ode: 3.8252\n",
      "Current learning rate:  0.0001\n",
      "Epoch 70, Loss_data: 17.4167, Loss_ode: 3.8167\n",
      "Current learning rate:  0.0001\n",
      "Epoch 80, Loss_data: 16.8855, Loss_ode: 3.8454\n",
      "Current learning rate:  0.0001\n",
      "Epoch 90, Loss_data: 16.3846, Loss_ode: 3.8332\n",
      "Current learning rate:  0.0001\n",
      "Epoch 100, Loss_data: 15.9103, Loss_ode: 3.8528\n",
      "Current learning rate:  0.0001\n",
      "Epoch 110, Loss_data: 15.4610, Loss_ode: 3.7730\n",
      "Current learning rate:  0.0001\n",
      "Epoch 120, Loss_data: 15.0356, Loss_ode: 3.8414\n",
      "Current learning rate:  0.0001\n",
      "Epoch 130, Loss_data: 14.6320, Loss_ode: 3.8417\n",
      "Current learning rate:  0.0001\n",
      "Epoch 140, Loss_data: 14.2484, Loss_ode: 3.8355\n",
      "Current learning rate:  0.0001\n",
      "Epoch 150, Loss_data: 13.8832, Loss_ode: 3.8311\n",
      "Current learning rate:  0.0001\n",
      "Epoch 160, Loss_data: 13.5349, Loss_ode: 3.7927\n",
      "Current learning rate:  0.0001\n",
      "Epoch 170, Loss_data: 13.2022, Loss_ode: 3.7656\n",
      "Current learning rate:  0.0001\n",
      "Epoch 180, Loss_data: 12.8843, Loss_ode: 3.8031\n",
      "Current learning rate:  0.0001\n",
      "Epoch 190, Loss_data: 12.5802, Loss_ode: 3.7957\n",
      "Current learning rate:  0.0001\n",
      "Epoch 200, Loss_data: 12.2892, Loss_ode: 3.8009\n",
      "Current learning rate:  0.0001\n",
      "Epoch 210, Loss_data: 12.0107, Loss_ode: 3.7910\n",
      "Current learning rate:  0.0001\n",
      "Epoch 220, Loss_data: 11.7441, Loss_ode: 3.7534\n",
      "Current learning rate:  0.0001\n",
      "Epoch 230, Loss_data: 11.4889, Loss_ode: 3.7709\n",
      "Current learning rate:  0.0001\n",
      "Epoch 240, Loss_data: 11.2448, Loss_ode: 3.7653\n",
      "Current learning rate:  0.0001\n",
      "Epoch 250, Loss_data: 11.0110, Loss_ode: 3.7436\n",
      "Current learning rate:  0.0001\n",
      "Epoch 260, Loss_data: 10.7873, Loss_ode: 3.7619\n",
      "Current learning rate:  0.0001\n",
      "Epoch 270, Loss_data: 10.5735, Loss_ode: 3.7445\n",
      "Current learning rate:  0.0001\n",
      "Epoch 280, Loss_data: 10.3689, Loss_ode: 3.7948\n",
      "Current learning rate:  0.0001\n",
      "Epoch 290, Loss_data: 10.1733, Loss_ode: 3.7703\n",
      "Current learning rate:  0.0001\n",
      "Epoch 300, Loss_data: 9.9866, Loss_ode: 3.7413\n",
      "Current learning rate:  0.0001\n",
      "Epoch 310, Loss_data: 9.8086, Loss_ode: 3.7390\n",
      "Current learning rate:  0.0001\n",
      "Epoch 320, Loss_data: 9.6388, Loss_ode: 3.7304\n",
      "Current learning rate:  0.0001\n",
      "Epoch 330, Loss_data: 9.4773, Loss_ode: 3.7681\n",
      "Current learning rate:  0.0001\n",
      "Epoch 340, Loss_data: 9.3237, Loss_ode: 3.7375\n",
      "Current learning rate:  0.0001\n",
      "Epoch 350, Loss_data: 9.1778, Loss_ode: 3.7552\n",
      "Current learning rate:  0.0001\n",
      "Epoch 360, Loss_data: 9.0393, Loss_ode: 3.7499\n",
      "Current learning rate:  0.0001\n",
      "Epoch 370, Loss_data: 8.9080, Loss_ode: 3.7569\n",
      "Current learning rate:  0.0001\n",
      "Epoch 380, Loss_data: 8.7835, Loss_ode: 3.7414\n",
      "Current learning rate:  0.0001\n",
      "Epoch 390, Loss_data: 8.6657, Loss_ode: 3.6901\n",
      "Current learning rate:  0.0001\n",
      "Epoch 400, Loss_data: 8.5541, Loss_ode: 3.7141\n",
      "Current learning rate:  0.0001\n",
      "Epoch 410, Loss_data: 8.4487, Loss_ode: 3.7178\n",
      "Current learning rate:  0.0001\n",
      "Epoch 420, Loss_data: 8.3490, Loss_ode: 3.7220\n",
      "Current learning rate:  0.0001\n",
      "Epoch 430, Loss_data: 8.2549, Loss_ode: 3.7615\n",
      "Current learning rate:  0.0001\n",
      "Epoch 440, Loss_data: 8.1662, Loss_ode: 3.6819\n",
      "Current learning rate:  0.0001\n",
      "Epoch 450, Loss_data: 8.0825, Loss_ode: 3.6632\n",
      "Current learning rate:  0.0001\n",
      "Epoch 460, Loss_data: 8.0037, Loss_ode: 3.6777\n",
      "Current learning rate:  0.0001\n",
      "Epoch 470, Loss_data: 7.9294, Loss_ode: 3.6751\n",
      "Current learning rate:  0.0001\n",
      "Epoch 480, Loss_data: 7.8596, Loss_ode: 3.6944\n",
      "Current learning rate:  0.0001\n",
      "Epoch 490, Loss_data: 7.7939, Loss_ode: 3.6798\n",
      "Current learning rate:  0.0001\n",
      "Epoch 500, Loss_data: 7.7323, Loss_ode: 3.6976\n",
      "Current learning rate:  0.0001\n",
      "Epoch 510, Loss_data: 7.6744, Loss_ode: 3.7202\n",
      "Current learning rate:  0.0001\n",
      "Epoch 520, Loss_data: 7.6202, Loss_ode: 3.6897\n",
      "Current learning rate:  0.0001\n",
      "Epoch 530, Loss_data: 7.5693, Loss_ode: 3.6686\n",
      "Current learning rate:  0.0001\n",
      "Epoch 540, Loss_data: 7.5218, Loss_ode: 3.6578\n",
      "Current learning rate:  0.0001\n",
      "Epoch 550, Loss_data: 7.4774, Loss_ode: 3.7124\n",
      "Current learning rate:  0.0001\n",
      "Epoch 560, Loss_data: 7.4358, Loss_ode: 3.6897\n",
      "Current learning rate:  0.0001\n",
      "Epoch 570, Loss_data: 7.3970, Loss_ode: 3.6295\n",
      "Current learning rate:  0.0001\n",
      "Epoch 580, Loss_data: 7.3608, Loss_ode: 3.6606\n",
      "Current learning rate:  0.0001\n",
      "Epoch 590, Loss_data: 7.3271, Loss_ode: 3.6848\n",
      "Current learning rate:  0.0001\n",
      "Epoch 600, Loss_data: 7.2957, Loss_ode: 3.6215\n",
      "Current learning rate:  0.0001\n",
      "Epoch 610, Loss_data: 7.2665, Loss_ode: 3.6744\n",
      "Current learning rate:  0.0001\n",
      "Epoch 620, Loss_data: 7.2394, Loss_ode: 3.6654\n",
      "Current learning rate:  0.0001\n",
      "Epoch 630, Loss_data: 7.2142, Loss_ode: 3.6635\n",
      "Current learning rate:  0.0001\n",
      "Epoch 640, Loss_data: 7.1909, Loss_ode: 3.6974\n",
      "Current learning rate:  0.0001\n",
      "Epoch 650, Loss_data: 7.1694, Loss_ode: 3.6375\n",
      "Current learning rate:  0.0001\n",
      "Epoch 660, Loss_data: 7.1493, Loss_ode: 3.6641\n",
      "Current learning rate:  0.0001\n",
      "Epoch 670, Loss_data: 7.1309, Loss_ode: 3.6869\n",
      "Current learning rate:  0.0001\n",
      "Epoch 680, Loss_data: 7.1137, Loss_ode: 3.6426\n",
      "Current learning rate:  0.0001\n",
      "Epoch 690, Loss_data: 7.0979, Loss_ode: 3.6684\n",
      "Current learning rate:  0.0001\n",
      "Epoch 700, Loss_data: 7.0834, Loss_ode: 3.6563\n",
      "Current learning rate:  0.0001\n",
      "Epoch 710, Loss_data: 7.0699, Loss_ode: 3.6962\n",
      "Current learning rate:  0.0001\n",
      "Epoch 720, Loss_data: 7.0576, Loss_ode: 3.6706\n",
      "Current learning rate:  0.0001\n",
      "Epoch 730, Loss_data: 7.0463, Loss_ode: 3.6781\n",
      "Current learning rate:  0.0001\n",
      "Epoch 740, Loss_data: 7.0359, Loss_ode: 3.6624\n",
      "Current learning rate:  0.0001\n",
      "Epoch 750, Loss_data: 7.0263, Loss_ode: 3.6553\n",
      "Current learning rate:  0.0001\n",
      "Epoch 760, Loss_data: 7.0176, Loss_ode: 3.6773\n",
      "Current learning rate:  0.0001\n",
      "Epoch 770, Loss_data: 7.0097, Loss_ode: 3.6950\n",
      "Current learning rate:  0.0001\n",
      "Epoch 780, Loss_data: 7.0024, Loss_ode: 3.6798\n",
      "Current learning rate:  0.0001\n",
      "Epoch 790, Loss_data: 6.9957, Loss_ode: 3.6717\n",
      "Current learning rate:  0.0001\n",
      "Epoch 800, Loss_data: 6.9896, Loss_ode: 3.6769\n",
      "Current learning rate:  0.0001\n",
      "Epoch 810, Loss_data: 6.9841, Loss_ode: 3.6526\n",
      "Current learning rate:  0.0001\n",
      "Epoch 820, Loss_data: 6.9790, Loss_ode: 3.7020\n",
      "Current learning rate:  0.0001\n",
      "Epoch 830, Loss_data: 6.9744, Loss_ode: 3.6584\n",
      "Current learning rate:  0.0001\n",
      "Epoch 840, Loss_data: 6.9702, Loss_ode: 3.6506\n",
      "Current learning rate:  0.0001\n",
      "Epoch 850, Loss_data: 6.9662, Loss_ode: 3.6872\n",
      "Current learning rate:  0.0001\n",
      "Epoch 860, Loss_data: 6.9628, Loss_ode: 3.6258\n",
      "Current learning rate:  0.0001\n",
      "Epoch 870, Loss_data: 6.9596, Loss_ode: 3.6001\n",
      "Current learning rate:  0.0001\n",
      "Epoch 880, Loss_data: 6.9567, Loss_ode: 3.6515\n",
      "Current learning rate:  0.0001\n",
      "Epoch 890, Loss_data: 6.9539, Loss_ode: 3.6623\n",
      "Current learning rate:  0.0001\n",
      "Epoch 900, Loss_data: 6.9515, Loss_ode: 3.6209\n",
      "Current learning rate:  0.0001\n",
      "Epoch 910, Loss_data: 6.9491, Loss_ode: 3.6491\n",
      "Current learning rate:  0.0001\n",
      "Epoch 920, Loss_data: 6.9470, Loss_ode: 3.6669\n",
      "Current learning rate:  0.0001\n",
      "Epoch 930, Loss_data: 6.9449, Loss_ode: 3.6377\n",
      "Current learning rate:  0.0001\n",
      "Epoch 940, Loss_data: 6.9432, Loss_ode: 3.6355\n",
      "Current learning rate:  0.0001\n",
      "Epoch 950, Loss_data: 6.9414, Loss_ode: 3.6646\n",
      "Current learning rate:  0.0001\n",
      "Epoch 960, Loss_data: 6.9400, Loss_ode: 3.6414\n",
      "Current learning rate:  0.0001\n",
      "Epoch 970, Loss_data: 6.9390, Loss_ode: 3.6772\n",
      "Current learning rate:  0.0001\n",
      "Epoch 980, Loss_data: 6.9374, Loss_ode: 3.6527\n",
      "Current learning rate:  0.0001\n",
      "Epoch 990, Loss_data: 6.9369, Loss_ode: 3.6181\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1000, Loss_data: 6.9362, Loss_ode: 3.6723\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1010, Loss_data: 6.9348, Loss_ode: 3.6649\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1020, Loss_data: 6.9335, Loss_ode: 3.6337\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1030, Loss_data: 6.9326, Loss_ode: 3.6424\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1040, Loss_data: 6.9319, Loss_ode: 3.6506\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1050, Loss_data: 6.9314, Loss_ode: 3.6540\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1060, Loss_data: 6.9313, Loss_ode: 3.6707\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1070, Loss_data: 6.9308, Loss_ode: 3.6163\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1080, Loss_data: 6.9294, Loss_ode: 3.6776\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1090, Loss_data: 6.9285, Loss_ode: 3.6188\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1100, Loss_data: 6.9279, Loss_ode: 3.6387\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1110, Loss_data: 6.9269, Loss_ode: 3.6329\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1120, Loss_data: 6.9263, Loss_ode: 3.7790\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1130, Loss_data: 6.9288, Loss_ode: 3.7053\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1140, Loss_data: 6.9288, Loss_ode: 3.6574\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1150, Loss_data: 6.9271, Loss_ode: 3.6531\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1160, Loss_data: 6.9242, Loss_ode: 3.6820\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1170, Loss_data: 6.9195, Loss_ode: 3.6272\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1180, Loss_data: 6.9111, Loss_ode: 3.6486\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1190, Loss_data: 6.8921, Loss_ode: 3.6377\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1200, Loss_data: 6.9248, Loss_ode: 3.9418\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1210, Loss_data: 6.9282, Loss_ode: 3.6415\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1220, Loss_data: 6.9279, Loss_ode: 3.7144\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1230, Loss_data: 6.9271, Loss_ode: 3.6546\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1240, Loss_data: 6.9260, Loss_ode: 3.6399\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1250, Loss_data: 6.9244, Loss_ode: 3.6352\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1260, Loss_data: 6.9221, Loss_ode: 3.6276\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1270, Loss_data: 6.9187, Loss_ode: 3.6581\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1280, Loss_data: 6.9119, Loss_ode: 3.6442\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1290, Loss_data: 6.9021, Loss_ode: 3.6620\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1300, Loss_data: 6.8871, Loss_ode: 3.6886\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1310, Loss_data: 6.8624, Loss_ode: 3.6085\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1320, Loss_data: 6.8098, Loss_ode: 3.6264\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1330, Loss_data: 6.7084, Loss_ode: 3.5921\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1340, Loss_data: 6.4246, Loss_ode: 3.6081\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1350, Loss_data: 5.3685, Loss_ode: 3.5063\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1360, Loss_data: 4.0620, Loss_ode: 3.9401\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1370, Loss_data: 3.7998, Loss_ode: 3.6185\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1380, Loss_data: 3.4744, Loss_ode: 3.3797\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1390, Loss_data: 3.2443, Loss_ode: 3.2951\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1400, Loss_data: 3.0046, Loss_ode: 3.2706\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1410, Loss_data: 2.8145, Loss_ode: 3.2575\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1420, Loss_data: 2.6508, Loss_ode: 3.1951\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1430, Loss_data: 2.5023, Loss_ode: 3.2105\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1440, Loss_data: 2.3637, Loss_ode: 3.1699\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1450, Loss_data: 2.2388, Loss_ode: 3.1556\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1460, Loss_data: 2.1226, Loss_ode: 3.1590\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1470, Loss_data: 2.0186, Loss_ode: 3.1227\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1480, Loss_data: 1.9211, Loss_ode: 3.1244\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1490, Loss_data: 1.8290, Loss_ode: 3.0692\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1500, Loss_data: 1.7429, Loss_ode: 3.0679\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1510, Loss_data: 1.6641, Loss_ode: 3.0337\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1520, Loss_data: 1.5893, Loss_ode: 3.0450\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1530, Loss_data: 1.5175, Loss_ode: 3.0390\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1540, Loss_data: 1.4493, Loss_ode: 2.9728\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1550, Loss_data: 1.3851, Loss_ode: 2.9403\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1560, Loss_data: 1.3267, Loss_ode: 2.9591\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1570, Loss_data: 1.2703, Loss_ode: 2.9438\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1580, Loss_data: 1.2147, Loss_ode: 2.9382\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1590, Loss_data: 1.1628, Loss_ode: 2.9295\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1600, Loss_data: 1.1147, Loss_ode: 2.8674\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1610, Loss_data: 1.0666, Loss_ode: 2.8656\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1620, Loss_data: 1.0235, Loss_ode: 2.9087\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1630, Loss_data: 0.9814, Loss_ode: 2.8359\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1640, Loss_data: 0.9402, Loss_ode: 2.9334\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1650, Loss_data: 0.9020, Loss_ode: 2.7883\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1660, Loss_data: 0.8647, Loss_ode: 3.7424\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1670, Loss_data: 0.8430, Loss_ode: 3.2128\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1680, Loss_data: 0.8272, Loss_ode: 2.9061\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1690, Loss_data: 0.7892, Loss_ode: 2.8125\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1700, Loss_data: 0.7517, Loss_ode: 2.8039\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1710, Loss_data: 0.7218, Loss_ode: 2.7275\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1720, Loss_data: 0.6965, Loss_ode: 2.7441\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1730, Loss_data: 0.6653, Loss_ode: 2.7157\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1740, Loss_data: 0.6414, Loss_ode: 2.7005\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1750, Loss_data: 0.6137, Loss_ode: 2.6869\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1760, Loss_data: 0.5896, Loss_ode: 2.6603\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1770, Loss_data: 0.5690, Loss_ode: 2.6891\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1780, Loss_data: 0.5491, Loss_ode: 2.6182\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1790, Loss_data: 0.5267, Loss_ode: 2.5900\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1800, Loss_data: 0.5025, Loss_ode: 2.7051\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1810, Loss_data: 0.4846, Loss_ode: 2.6338\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1820, Loss_data: 0.4725, Loss_ode: 2.6839\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1830, Loss_data: 0.4568, Loss_ode: 2.5132\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1840, Loss_data: 0.4373, Loss_ode: 2.5794\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1850, Loss_data: 0.4164, Loss_ode: 2.5784\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1860, Loss_data: 0.3941, Loss_ode: 2.6245\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1870, Loss_data: 0.4971, Loss_ode: 4.8411\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1880, Loss_data: 0.4502, Loss_ode: 3.2570\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1890, Loss_data: 0.4345, Loss_ode: 3.0542\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1900, Loss_data: 0.4202, Loss_ode: 2.7561\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1910, Loss_data: 0.3835, Loss_ode: 2.7043\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1920, Loss_data: 0.3785, Loss_ode: 2.6239\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1930, Loss_data: 0.3528, Loss_ode: 2.6159\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1940, Loss_data: 0.3366, Loss_ode: 2.5579\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1950, Loss_data: 0.3200, Loss_ode: 2.5495\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1960, Loss_data: 0.3093, Loss_ode: 2.5109\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1970, Loss_data: 0.2960, Loss_ode: 2.5038\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1980, Loss_data: 0.2855, Loss_ode: 2.4814\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1990, Loss_data: 0.2751, Loss_ode: 2.4687\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2000, Loss_data: 0.2651, Loss_ode: 2.3774\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2010, Loss_data: 0.2540, Loss_ode: 2.3859\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2020, Loss_data: 0.2470, Loss_ode: 2.4057\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2030, Loss_data: 0.2374, Loss_ode: 2.3456\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2040, Loss_data: 0.2290, Loss_ode: 2.3120\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2050, Loss_data: 0.2228, Loss_ode: 2.2808\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2060, Loss_data: 0.2153, Loss_ode: 2.2675\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2070, Loss_data: 0.2094, Loss_ode: 2.2298\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2080, Loss_data: 0.1998, Loss_ode: 2.2261\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2090, Loss_data: 0.1987, Loss_ode: 2.2041\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2100, Loss_data: 0.1824, Loss_ode: 2.1735\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2110, Loss_data: 0.1771, Loss_ode: 2.2224\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2120, Loss_data: 0.1730, Loss_ode: 2.1209\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2130, Loss_data: 0.1761, Loss_ode: 2.1193\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2140, Loss_data: 0.1598, Loss_ode: 2.1364\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2150, Loss_data: 0.1643, Loss_ode: 2.0464\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2160, Loss_data: 0.1531, Loss_ode: 2.1323\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2170, Loss_data: 0.1481, Loss_ode: 2.1556\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2180, Loss_data: 0.1513, Loss_ode: 2.1323\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2190, Loss_data: 0.1415, Loss_ode: 2.2877\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2200, Loss_data: 0.1400, Loss_ode: 1.9758\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2210, Loss_data: 0.1382, Loss_ode: 2.0026\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2220, Loss_data: 0.1970, Loss_ode: 28.7505\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2230, Loss_data: 2.6896, Loss_ode: 8.0060\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2240, Loss_data: 0.9040, Loss_ode: 4.1537\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2250, Loss_data: 0.4051, Loss_ode: 2.9755\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2260, Loss_data: 0.4362, Loss_ode: 2.8065\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2270, Loss_data: 0.2621, Loss_ode: 2.7642\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2280, Loss_data: 0.2154, Loss_ode: 2.7475\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2290, Loss_data: 0.2176, Loss_ode: 2.6713\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2300, Loss_data: 0.2161, Loss_ode: 2.6369\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2310, Loss_data: 0.2113, Loss_ode: 2.5853\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2320, Loss_data: 0.2013, Loss_ode: 2.5904\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2330, Loss_data: 0.1905, Loss_ode: 2.5514\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2340, Loss_data: 0.1825, Loss_ode: 2.5272\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2350, Loss_data: 0.1751, Loss_ode: 2.5126\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2360, Loss_data: 0.1659, Loss_ode: 2.4707\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2370, Loss_data: 0.1586, Loss_ode: 2.4769\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2380, Loss_data: 0.1509, Loss_ode: 2.4443\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2390, Loss_data: 0.1444, Loss_ode: 2.4612\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2400, Loss_data: 0.1401, Loss_ode: 2.4006\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2410, Loss_data: 0.1335, Loss_ode: 2.4098\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2420, Loss_data: 0.1278, Loss_ode: 2.3882\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2430, Loss_data: 0.1241, Loss_ode: 2.3631\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2440, Loss_data: 0.1197, Loss_ode: 2.3695\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2450, Loss_data: 0.1165, Loss_ode: 2.3273\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2460, Loss_data: 0.1121, Loss_ode: 2.3154\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2470, Loss_data: 0.1086, Loss_ode: 2.2818\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2480, Loss_data: 0.1047, Loss_ode: 2.3008\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2490, Loss_data: 0.1021, Loss_ode: 2.2767\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2500, Loss_data: 0.0994, Loss_ode: 2.2814\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2510, Loss_data: 0.0975, Loss_ode: 2.2701\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2520, Loss_data: 0.0956, Loss_ode: 2.2280\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2530, Loss_data: 0.0932, Loss_ode: 2.1920\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2540, Loss_data: 0.0911, Loss_ode: 2.2198\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2550, Loss_data: 0.0899, Loss_ode: 2.1807\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2560, Loss_data: 0.0887, Loss_ode: 2.1840\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2570, Loss_data: 0.0869, Loss_ode: 2.1513\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2580, Loss_data: 0.0848, Loss_ode: 2.1395\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2590, Loss_data: 0.0841, Loss_ode: 2.1681\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2600, Loss_data: 0.0819, Loss_ode: 2.1147\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2610, Loss_data: 0.0808, Loss_ode: 2.0741\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2620, Loss_data: 0.0788, Loss_ode: 2.1090\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2630, Loss_data: 0.0777, Loss_ode: 2.0549\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2640, Loss_data: 0.0762, Loss_ode: 2.0297\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2650, Loss_data: 0.0745, Loss_ode: 2.0466\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2660, Loss_data: 0.0747, Loss_ode: 2.0081\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2670, Loss_data: 0.0721, Loss_ode: 1.9866\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2680, Loss_data: 0.0717, Loss_ode: 1.9532\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2690, Loss_data: 0.0711, Loss_ode: 1.9348\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2700, Loss_data: 0.0688, Loss_ode: 1.8685\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2710, Loss_data: 0.0672, Loss_ode: 1.8798\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2720, Loss_data: 0.0673, Loss_ode: 1.8119\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2730, Loss_data: 0.0648, Loss_ode: 1.8048\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2740, Loss_data: 0.0648, Loss_ode: 1.7509\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2750, Loss_data: 0.0627, Loss_ode: 1.7468\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2760, Loss_data: 0.0613, Loss_ode: 1.7016\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2770, Loss_data: 0.0610, Loss_ode: 1.6723\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2780, Loss_data: 0.0607, Loss_ode: 1.6287\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2790, Loss_data: 0.0591, Loss_ode: 1.6267\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2800, Loss_data: 0.0589, Loss_ode: 1.6358\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2810, Loss_data: 0.0581, Loss_ode: 1.5633\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2820, Loss_data: 0.0579, Loss_ode: 1.5536\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2830, Loss_data: 0.0552, Loss_ode: 1.5585\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2840, Loss_data: 0.0543, Loss_ode: 1.4747\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2850, Loss_data: 0.0568, Loss_ode: 1.5084\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2860, Loss_data: 0.0503, Loss_ode: 1.4537\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2870, Loss_data: 0.0523, Loss_ode: 1.5214\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2880, Loss_data: 0.0521, Loss_ode: 1.4685\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2890, Loss_data: 0.0543, Loss_ode: 1.3657\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2900, Loss_data: 0.0546, Loss_ode: 1.7931\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2910, Loss_data: 0.0444, Loss_ode: 1.3294\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2920, Loss_data: 0.0501, Loss_ode: 1.3115\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2930, Loss_data: 0.0509, Loss_ode: 1.3395\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2940, Loss_data: 0.0517, Loss_ode: 1.2578\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2950, Loss_data: 0.0474, Loss_ode: 1.3017\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2960, Loss_data: 0.0503, Loss_ode: 2.4291\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2970, Loss_data: 0.0426, Loss_ode: 1.8108\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2980, Loss_data: 0.0447, Loss_ode: 1.2275\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2990, Loss_data: 0.0482, Loss_ode: 1.1982\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3000, Loss_data: 0.0498, Loss_ode: 1.1389\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3010, Loss_data: 0.0482, Loss_ode: 1.1278\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3020, Loss_data: 0.0454, Loss_ode: 2.1187\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3030, Loss_data: 0.3185, Loss_ode: 59.9228\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3040, Loss_data: 0.6470, Loss_ode: 25.0121\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3050, Loss_data: 1.6268, Loss_ode: 11.1660\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3060, Loss_data: 1.5663, Loss_ode: 6.3755\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3070, Loss_data: 0.9951, Loss_ode: 4.7389\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3080, Loss_data: 0.6971, Loss_ode: 3.7978\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3090, Loss_data: 0.5783, Loss_ode: 3.4516\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3100, Loss_data: 0.4588, Loss_ode: 3.3104\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3110, Loss_data: 0.3909, Loss_ode: 3.1290\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3120, Loss_data: 0.3456, Loss_ode: 3.0470\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3130, Loss_data: 0.3045, Loss_ode: 2.9275\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3140, Loss_data: 0.2647, Loss_ode: 2.8007\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3150, Loss_data: 0.2352, Loss_ode: 2.7969\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3160, Loss_data: 0.2153, Loss_ode: 2.7294\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3170, Loss_data: 0.2018, Loss_ode: 2.6622\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3180, Loss_data: 0.1900, Loss_ode: 2.5785\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3190, Loss_data: 0.1800, Loss_ode: 2.6030\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3200, Loss_data: 0.1698, Loss_ode: 2.5193\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3210, Loss_data: 0.1635, Loss_ode: 2.5358\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3220, Loss_data: 0.1579, Loss_ode: 2.4959\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3230, Loss_data: 0.1514, Loss_ode: 2.5458\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3240, Loss_data: 0.1476, Loss_ode: 2.4895\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3250, Loss_data: 0.1438, Loss_ode: 2.5084\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3260, Loss_data: 0.1395, Loss_ode: 2.4548\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3270, Loss_data: 0.1362, Loss_ode: 2.4735\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3280, Loss_data: 0.1339, Loss_ode: 2.4401\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3290, Loss_data: 0.1299, Loss_ode: 2.4455\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3300, Loss_data: 0.1267, Loss_ode: 2.3981\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3310, Loss_data: 0.1241, Loss_ode: 2.3804\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3320, Loss_data: 0.1211, Loss_ode: 2.3513\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3330, Loss_data: 0.1195, Loss_ode: 2.3321\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3340, Loss_data: 0.1171, Loss_ode: 2.3634\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3350, Loss_data: 0.1149, Loss_ode: 2.3435\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3360, Loss_data: 0.1137, Loss_ode: 2.2971\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3370, Loss_data: 0.1116, Loss_ode: 2.2994\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3380, Loss_data: 0.1087, Loss_ode: 2.2685\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3390, Loss_data: 0.1065, Loss_ode: 2.2385\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3400, Loss_data: 0.1053, Loss_ode: 2.2028\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3410, Loss_data: 0.1030, Loss_ode: 2.2250\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3420, Loss_data: 0.1011, Loss_ode: 2.2173\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3430, Loss_data: 0.0994, Loss_ode: 2.2057\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3440, Loss_data: 0.0979, Loss_ode: 2.1500\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3450, Loss_data: 0.0963, Loss_ode: 2.1889\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3460, Loss_data: 0.0953, Loss_ode: 2.1369\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3470, Loss_data: 0.0945, Loss_ode: 2.1592\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3480, Loss_data: 0.0932, Loss_ode: 2.1000\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3490, Loss_data: 0.0922, Loss_ode: 2.0574\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3500, Loss_data: 0.0907, Loss_ode: 2.0143\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3510, Loss_data: 0.0890, Loss_ode: 2.0012\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3520, Loss_data: 0.0885, Loss_ode: 2.0197\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3530, Loss_data: 0.0865, Loss_ode: 1.9579\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3540, Loss_data: 0.0858, Loss_ode: 1.9637\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3550, Loss_data: 0.0849, Loss_ode: 1.9044\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3560, Loss_data: 0.0839, Loss_ode: 1.9302\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3570, Loss_data: 0.0830, Loss_ode: 1.9012\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3580, Loss_data: 0.0813, Loss_ode: 1.8502\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3590, Loss_data: 0.0808, Loss_ode: 1.8559\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3600, Loss_data: 0.0799, Loss_ode: 1.8054\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3610, Loss_data: 0.0781, Loss_ode: 1.7985\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3620, Loss_data: 0.0772, Loss_ode: 1.7975\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3630, Loss_data: 0.0765, Loss_ode: 1.7504\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3640, Loss_data: 0.0757, Loss_ode: 1.7656\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3650, Loss_data: 0.0739, Loss_ode: 1.7113\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3660, Loss_data: 0.0725, Loss_ode: 1.7120\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3670, Loss_data: 0.0720, Loss_ode: 1.6716\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3680, Loss_data: 0.0705, Loss_ode: 1.6660\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3690, Loss_data: 0.0695, Loss_ode: 1.6509\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3700, Loss_data: 0.0681, Loss_ode: 1.6430\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3710, Loss_data: 0.0678, Loss_ode: 1.5807\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3720, Loss_data: 0.0670, Loss_ode: 1.5993\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3730, Loss_data: 0.0657, Loss_ode: 1.5830\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3740, Loss_data: 0.0642, Loss_ode: 1.5634\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3750, Loss_data: 0.0636, Loss_ode: 1.5003\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3760, Loss_data: 0.0628, Loss_ode: 1.5176\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3770, Loss_data: 0.0617, Loss_ode: 1.4839\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3780, Loss_data: 0.0611, Loss_ode: 1.4622\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3790, Loss_data: 0.0601, Loss_ode: 1.4676\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3800, Loss_data: 0.0591, Loss_ode: 1.4278\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3810, Loss_data: 0.0586, Loss_ode: 1.4382\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3820, Loss_data: 0.0580, Loss_ode: 1.4168\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3830, Loss_data: 0.0574, Loss_ode: 1.3758\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3840, Loss_data: 0.0565, Loss_ode: 1.3615\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3850, Loss_data: 0.0564, Loss_ode: 1.3521\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3860, Loss_data: 0.0563, Loss_ode: 1.3116\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3870, Loss_data: 0.0558, Loss_ode: 1.3010\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3880, Loss_data: 0.0556, Loss_ode: 1.2751\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3890, Loss_data: 0.0550, Loss_ode: 1.2582\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3900, Loss_data: 0.0538, Loss_ode: 1.2211\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3910, Loss_data: 0.0532, Loss_ode: 1.1934\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3920, Loss_data: 0.0536, Loss_ode: 1.1978\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3930, Loss_data: 0.0524, Loss_ode: 1.1998\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3940, Loss_data: 0.0520, Loss_ode: 1.1777\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3950, Loss_data: 0.0517, Loss_ode: 1.1446\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3960, Loss_data: 0.0505, Loss_ode: 1.1267\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3970, Loss_data: 0.0496, Loss_ode: 1.1485\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3980, Loss_data: 0.0495, Loss_ode: 1.1045\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3990, Loss_data: 0.0495, Loss_ode: 1.0961\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4000, Loss_data: 0.0490, Loss_ode: 1.1297\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4010, Loss_data: 0.0485, Loss_ode: 1.1965\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4020, Loss_data: 0.0473, Loss_ode: 1.0430\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4030, Loss_data: 0.0472, Loss_ode: 1.0075\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4040, Loss_data: 0.0472, Loss_ode: 1.1762\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4050, Loss_data: 0.0458, Loss_ode: 1.0668\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4060, Loss_data: 0.0453, Loss_ode: 0.9865\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4070, Loss_data: 0.0453, Loss_ode: 0.9745\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4080, Loss_data: 0.0448, Loss_ode: 0.9707\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4090, Loss_data: 0.0444, Loss_ode: 0.9930\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4100, Loss_data: 0.0442, Loss_ode: 0.9320\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4110, Loss_data: 0.0438, Loss_ode: 1.1042\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4120, Loss_data: 0.0422, Loss_ode: 1.0396\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4130, Loss_data: 0.0427, Loss_ode: 0.9089\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4140, Loss_data: 0.0430, Loss_ode: 0.9009\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4150, Loss_data: 0.0427, Loss_ode: 0.9167\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4160, Loss_data: 0.0422, Loss_ode: 1.0430\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4170, Loss_data: 0.0405, Loss_ode: 1.0758\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4180, Loss_data: 0.0403, Loss_ode: 0.9259\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4190, Loss_data: 0.0409, Loss_ode: 0.8704\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4200, Loss_data: 0.0409, Loss_ode: 0.8795\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4210, Loss_data: 0.0408, Loss_ode: 0.8581\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4220, Loss_data: 0.0404, Loss_ode: 0.8472\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4230, Loss_data: 0.0400, Loss_ode: 0.9218\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4240, Loss_data: 0.0396, Loss_ode: 0.9066\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4250, Loss_data: 0.0388, Loss_ode: 0.8294\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4260, Loss_data: 0.0388, Loss_ode: 0.8228\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4270, Loss_data: 0.0390, Loss_ode: 0.7940\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4280, Loss_data: 0.0386, Loss_ode: 0.9124\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4290, Loss_data: 0.0388, Loss_ode: 1.2108\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4300, Loss_data: 0.0379, Loss_ode: 0.8751\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4310, Loss_data: 0.0381, Loss_ode: 0.8206\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4320, Loss_data: 0.0382, Loss_ode: 0.7887\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4330, Loss_data: 0.0379, Loss_ode: 0.7799\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4340, Loss_data: 0.0375, Loss_ode: 0.7577\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4350, Loss_data: 0.0371, Loss_ode: 0.8085\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4360, Loss_data: 0.0365, Loss_ode: 0.8692\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4370, Loss_data: 0.0368, Loss_ode: 0.7795\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4380, Loss_data: 0.0367, Loss_ode: 0.7549\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4390, Loss_data: 0.0368, Loss_ode: 0.7791\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4400, Loss_data: 0.0359, Loss_ode: 0.7640\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4410, Loss_data: 0.0357, Loss_ode: 0.7929\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4420, Loss_data: 0.0358, Loss_ode: 0.7949\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4430, Loss_data: 0.0360, Loss_ode: 0.7541\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4440, Loss_data: 0.0356, Loss_ode: 0.7260\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4450, Loss_data: 0.0359, Loss_ode: 0.9146\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4460, Loss_data: 0.0353, Loss_ode: 0.7099\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4470, Loss_data: 0.0352, Loss_ode: 0.7126\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4480, Loss_data: 0.0351, Loss_ode: 0.7003\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4490, Loss_data: 0.0348, Loss_ode: 0.6971\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4500, Loss_data: 0.0342, Loss_ode: 1.1418\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4510, Loss_data: 0.0348, Loss_ode: 0.7658\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4520, Loss_data: 0.0351, Loss_ode: 0.7678\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4530, Loss_data: 0.0347, Loss_ode: 0.6772\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4540, Loss_data: 0.0342, Loss_ode: 0.7323\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4550, Loss_data: 0.0344, Loss_ode: 0.6940\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4560, Loss_data: 0.0342, Loss_ode: 0.7156\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4570, Loss_data: 0.0339, Loss_ode: 0.7108\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4580, Loss_data: 0.0340, Loss_ode: 0.7227\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4590, Loss_data: 0.0341, Loss_ode: 0.6781\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4600, Loss_data: 0.0336, Loss_ode: 0.6811\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4610, Loss_data: 0.0338, Loss_ode: 0.6723\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4620, Loss_data: 0.0333, Loss_ode: 0.7243\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4630, Loss_data: 0.0331, Loss_ode: 0.6965\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4640, Loss_data: 0.0334, Loss_ode: 0.6552\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4650, Loss_data: 0.0334, Loss_ode: 0.6504\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4660, Loss_data: 0.0329, Loss_ode: 0.6638\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4670, Loss_data: 0.0334, Loss_ode: 0.7362\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4680, Loss_data: 0.0332, Loss_ode: 0.6963\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4690, Loss_data: 0.0333, Loss_ode: 0.6480\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4700, Loss_data: 0.0331, Loss_ode: 0.6745\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4710, Loss_data: 0.0332, Loss_ode: 0.6920\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4720, Loss_data: 0.0330, Loss_ode: 0.6816\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4730, Loss_data: 0.0323, Loss_ode: 0.6445\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4740, Loss_data: 0.0325, Loss_ode: 0.6260\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4750, Loss_data: 0.0323, Loss_ode: 0.6296\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4760, Loss_data: 0.0321, Loss_ode: 0.8563\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4770, Loss_data: 0.0326, Loss_ode: 0.6357\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4780, Loss_data: 0.0323, Loss_ode: 0.6225\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4790, Loss_data: 0.0323, Loss_ode: 0.6341\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4800, Loss_data: 0.0318, Loss_ode: 0.6338\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4810, Loss_data: 0.0318, Loss_ode: 0.6821\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4820, Loss_data: 0.0326, Loss_ode: 0.7525\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4830, Loss_data: 0.0318, Loss_ode: 0.6819\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4840, Loss_data: 0.0320, Loss_ode: 0.6456\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4850, Loss_data: 0.0316, Loss_ode: 0.6507\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4860, Loss_data: 0.0319, Loss_ode: 0.5981\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4870, Loss_data: 0.0322, Loss_ode: 0.7761\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4880, Loss_data: 0.0318, Loss_ode: 0.5924\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4890, Loss_data: 0.0314, Loss_ode: 0.6145\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4900, Loss_data: 0.0315, Loss_ode: 0.6240\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4910, Loss_data: 0.0319, Loss_ode: 0.7447\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4920, Loss_data: 0.0310, Loss_ode: 0.6922\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4930, Loss_data: 0.0313, Loss_ode: 0.6065\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4940, Loss_data: 0.0308, Loss_ode: 0.6286\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4950, Loss_data: 0.0312, Loss_ode: 0.6056\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4960, Loss_data: 0.0315, Loss_ode: 0.7032\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4970, Loss_data: 0.0309, Loss_ode: 0.6041\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4980, Loss_data: 0.0312, Loss_ode: 0.6289\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4990, Loss_data: 0.0308, Loss_ode: 0.5778\n",
      "Current learning rate:  7e-05\n",
      "Epoch 5000, Loss_data: 0.0310, Loss_ode: 0.5811\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5010, Loss_data: 0.0309, Loss_ode: 0.5738\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5020, Loss_data: 0.0309, Loss_ode: 0.5614\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5030, Loss_data: 0.0307, Loss_ode: 0.5702\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5040, Loss_data: 0.0307, Loss_ode: 0.5632\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5050, Loss_data: 0.0307, Loss_ode: 0.5701\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5060, Loss_data: 0.0307, Loss_ode: 0.5725\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5070, Loss_data: 0.0308, Loss_ode: 0.5580\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5080, Loss_data: 0.0307, Loss_ode: 0.5629\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5090, Loss_data: 0.0307, Loss_ode: 0.5513\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5100, Loss_data: 0.0306, Loss_ode: 0.5548\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5110, Loss_data: 0.0305, Loss_ode: 0.5608\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5120, Loss_data: 0.0304, Loss_ode: 0.5490\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5130, Loss_data: 0.0304, Loss_ode: 0.5626\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5140, Loss_data: 0.0304, Loss_ode: 0.5500\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5150, Loss_data: 0.0302, Loss_ode: 0.5645\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5160, Loss_data: 0.0302, Loss_ode: 0.5463\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5170, Loss_data: 0.0303, Loss_ode: 0.5508\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5180, Loss_data: 0.0303, Loss_ode: 0.5384\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5190, Loss_data: 0.0302, Loss_ode: 0.5340\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5200, Loss_data: 0.0301, Loss_ode: 0.5447\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5210, Loss_data: 0.0301, Loss_ode: 0.5393\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5220, Loss_data: 0.0300, Loss_ode: 0.5377\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5230, Loss_data: 0.0300, Loss_ode: 0.5486\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5240, Loss_data: 0.0300, Loss_ode: 0.5336\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5250, Loss_data: 0.0299, Loss_ode: 0.5384\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5260, Loss_data: 0.0300, Loss_ode: 0.5325\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5270, Loss_data: 0.0299, Loss_ode: 0.5353\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5280, Loss_data: 0.0300, Loss_ode: 0.5470\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5290, Loss_data: 0.0298, Loss_ode: 0.5253\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5300, Loss_data: 0.0297, Loss_ode: 0.5274\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5310, Loss_data: 0.0298, Loss_ode: 0.5222\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5320, Loss_data: 0.0298, Loss_ode: 0.5228\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5330, Loss_data: 0.0299, Loss_ode: 0.5244\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5340, Loss_data: 0.0298, Loss_ode: 0.5320\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5350, Loss_data: 0.0297, Loss_ode: 0.5187\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5360, Loss_data: 0.0297, Loss_ode: 0.5266\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5370, Loss_data: 0.0296, Loss_ode: 0.5258\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5380, Loss_data: 0.0295, Loss_ode: 0.5176\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5390, Loss_data: 0.0292, Loss_ode: 0.5068\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5400, Loss_data: 0.0290, Loss_ode: 0.5100\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5410, Loss_data: 0.0288, Loss_ode: 0.5183\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5420, Loss_data: 0.0286, Loss_ode: 0.4982\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5430, Loss_data: 0.0287, Loss_ode: 0.5058\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5440, Loss_data: 0.0292, Loss_ode: 0.5038\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5450, Loss_data: 0.0291, Loss_ode: 0.4861\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5460, Loss_data: 0.0291, Loss_ode: 0.5015\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5470, Loss_data: 0.0290, Loss_ode: 0.4828\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5480, Loss_data: 0.0287, Loss_ode: 0.5057\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5490, Loss_data: 0.0288, Loss_ode: 0.5055\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5500, Loss_data: 0.0288, Loss_ode: 0.4887\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5510, Loss_data: 0.0286, Loss_ode: 0.4988\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5520, Loss_data: 0.0288, Loss_ode: 0.4934\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5530, Loss_data: 0.0287, Loss_ode: 0.4841\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5540, Loss_data: 0.0285, Loss_ode: 0.4939\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5550, Loss_data: 0.0286, Loss_ode: 0.4879\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5560, Loss_data: 0.0282, Loss_ode: 0.5296\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5570, Loss_data: 0.0287, Loss_ode: 0.4841\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5580, Loss_data: 0.0289, Loss_ode: 0.4971\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5590, Loss_data: 0.0283, Loss_ode: 0.4948\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5600, Loss_data: 0.0284, Loss_ode: 0.4764\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5610, Loss_data: 0.0284, Loss_ode: 0.4801\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5620, Loss_data: 0.0280, Loss_ode: 0.5734\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5630, Loss_data: 0.0286, Loss_ode: 0.4983\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5640, Loss_data: 0.0283, Loss_ode: 0.4799\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5650, Loss_data: 0.0282, Loss_ode: 0.4892\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5660, Loss_data: 0.0280, Loss_ode: 0.4803\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5670, Loss_data: 0.0283, Loss_ode: 0.4757\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5680, Loss_data: 0.0285, Loss_ode: 0.4774\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5690, Loss_data: 0.0283, Loss_ode: 0.4791\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5700, Loss_data: 0.0284, Loss_ode: 0.5106\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5710, Loss_data: 0.0283, Loss_ode: 0.5073\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5720, Loss_data: 0.0281, Loss_ode: 0.4665\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5730, Loss_data: 0.0278, Loss_ode: 0.4741\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5740, Loss_data: 0.0280, Loss_ode: 0.4568\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5750, Loss_data: 0.0278, Loss_ode: 0.4761\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5760, Loss_data: 0.0277, Loss_ode: 0.5140\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5770, Loss_data: 0.0280, Loss_ode: 0.4684\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5780, Loss_data: 0.0280, Loss_ode: 0.4573\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5790, Loss_data: 0.0275, Loss_ode: 0.4622\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5800, Loss_data: 0.0279, Loss_ode: 0.5022\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5810, Loss_data: 0.0277, Loss_ode: 0.4736\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5820, Loss_data: 0.0278, Loss_ode: 0.4910\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5830, Loss_data: 0.0278, Loss_ode: 0.4622\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5840, Loss_data: 0.0275, Loss_ode: 0.4526\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5850, Loss_data: 0.0276, Loss_ode: 0.4605\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5860, Loss_data: 0.0281, Loss_ode: 0.6036\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5870, Loss_data: 0.0277, Loss_ode: 0.4994\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5880, Loss_data: 0.0279, Loss_ode: 0.4979\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5890, Loss_data: 0.0272, Loss_ode: 0.4596\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5900, Loss_data: 0.0270, Loss_ode: 0.4553\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5910, Loss_data: 0.0275, Loss_ode: 0.4601\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5920, Loss_data: 0.0277, Loss_ode: 0.4444\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5930, Loss_data: 0.0274, Loss_ode: 0.4533\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5940, Loss_data: 0.0272, Loss_ode: 0.4706\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5950, Loss_data: 0.0273, Loss_ode: 0.5237\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5960, Loss_data: 0.0274, Loss_ode: 0.4506\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5970, Loss_data: 0.0269, Loss_ode: 0.4479\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5980, Loss_data: 0.0267, Loss_ode: 0.4492\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5990, Loss_data: 0.0272, Loss_ode: 0.4422\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6000, Loss_data: 0.0271, Loss_ode: 0.4413\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6010, Loss_data: 0.0275, Loss_ode: 0.5183\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6020, Loss_data: 0.0270, Loss_ode: 0.4573\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6030, Loss_data: 0.0270, Loss_ode: 0.4424\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6040, Loss_data: 0.0269, Loss_ode: 0.4591\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6050, Loss_data: 0.0270, Loss_ode: 0.4753\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6060, Loss_data: 0.0270, Loss_ode: 0.4606\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6070, Loss_data: 0.0270, Loss_ode: 0.4408\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6080, Loss_data: 0.0271, Loss_ode: 0.4561\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6090, Loss_data: 0.0272, Loss_ode: 0.5020\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6100, Loss_data: 0.0266, Loss_ode: 0.4849\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6110, Loss_data: 0.0267, Loss_ode: 0.4273\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6120, Loss_data: 0.0266, Loss_ode: 0.4239\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6130, Loss_data: 0.0268, Loss_ode: 0.4276\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6140, Loss_data: 0.0272, Loss_ode: 0.5135\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6150, Loss_data: 0.0269, Loss_ode: 0.4306\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6160, Loss_data: 0.0267, Loss_ode: 0.4314\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6170, Loss_data: 0.0261, Loss_ode: 0.4408\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6180, Loss_data: 0.0263, Loss_ode: 0.4340\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6190, Loss_data: 0.0266, Loss_ode: 0.4354\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6200, Loss_data: 0.0267, Loss_ode: 0.4576\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6210, Loss_data: 0.0267, Loss_ode: 0.4795\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6220, Loss_data: 0.0261, Loss_ode: 0.4195\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6230, Loss_data: 0.0260, Loss_ode: 0.4268\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6240, Loss_data: 0.0266, Loss_ode: 0.4871\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6250, Loss_data: 0.0265, Loss_ode: 0.4269\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6260, Loss_data: 0.0261, Loss_ode: 0.4299\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6270, Loss_data: 0.0260, Loss_ode: 0.4184\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6280, Loss_data: 0.0258, Loss_ode: 0.4282\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6290, Loss_data: 0.0257, Loss_ode: 0.6029\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6300, Loss_data: 0.0264, Loss_ode: 0.4388\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6310, Loss_data: 0.0261, Loss_ode: 0.4609\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6320, Loss_data: 0.0256, Loss_ode: 0.4232\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6330, Loss_data: 0.0256, Loss_ode: 0.4214\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6340, Loss_data: 0.0262, Loss_ode: 0.4077\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6350, Loss_data: 0.0261, Loss_ode: 0.4314\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6360, Loss_data: 0.0259, Loss_ode: 0.4253\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6370, Loss_data: 0.0257, Loss_ode: 0.4148\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6380, Loss_data: 0.0255, Loss_ode: 0.4303\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6390, Loss_data: 0.0253, Loss_ode: 0.4905\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6400, Loss_data: 0.0255, Loss_ode: 0.4152\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6410, Loss_data: 0.0255, Loss_ode: 0.4071\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6420, Loss_data: 0.0252, Loss_ode: 0.4203\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6430, Loss_data: 0.0252, Loss_ode: 0.4466\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6440, Loss_data: 0.0253, Loss_ode: 0.4125\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6450, Loss_data: 0.0257, Loss_ode: 0.4340\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6460, Loss_data: 0.0253, Loss_ode: 0.4055\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6470, Loss_data: 0.0251, Loss_ode: 0.4111\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6480, Loss_data: 0.0253, Loss_ode: 0.4126\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6490, Loss_data: 0.0258, Loss_ode: 0.5066\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6500, Loss_data: 0.0251, Loss_ode: 0.4169\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6510, Loss_data: 0.0252, Loss_ode: 0.4069\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6520, Loss_data: 0.0248, Loss_ode: 0.3967\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6530, Loss_data: 0.0249, Loss_ode: 0.3954\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6540, Loss_data: 0.0253, Loss_ode: 0.4106\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6550, Loss_data: 0.0257, Loss_ode: 0.4917\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6560, Loss_data: 0.0253, Loss_ode: 0.4413\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6570, Loss_data: 0.0246, Loss_ode: 0.3993\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6580, Loss_data: 0.0244, Loss_ode: 0.4063\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6590, Loss_data: 0.0251, Loss_ode: 0.4031\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6600, Loss_data: 0.0246, Loss_ode: 0.4127\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6610, Loss_data: 0.0247, Loss_ode: 0.4019\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6620, Loss_data: 0.0249, Loss_ode: 0.4116\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6630, Loss_data: 0.0245, Loss_ode: 0.3965\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6640, Loss_data: 0.0246, Loss_ode: 0.3936\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6650, Loss_data: 0.0245, Loss_ode: 0.4060\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6660, Loss_data: 0.0246, Loss_ode: 0.4124\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6670, Loss_data: 0.0245, Loss_ode: 0.3820\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6680, Loss_data: 0.0240, Loss_ode: 0.4402\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6690, Loss_data: 0.0243, Loss_ode: 0.3937\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6700, Loss_data: 0.0243, Loss_ode: 0.3811\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6710, Loss_data: 0.0239, Loss_ode: 0.3764\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6720, Loss_data: 0.0243, Loss_ode: 0.3938\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6730, Loss_data: 0.0240, Loss_ode: 0.3796\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6740, Loss_data: 0.0240, Loss_ode: 0.3840\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6750, Loss_data: 0.0239, Loss_ode: 0.4207\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6760, Loss_data: 0.0244, Loss_ode: 0.3908\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6770, Loss_data: 0.0238, Loss_ode: 0.4246\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6780, Loss_data: 0.0236, Loss_ode: 0.3845\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6790, Loss_data: 0.0236, Loss_ode: 0.3893\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6800, Loss_data: 0.0241, Loss_ode: 0.3790\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6810, Loss_data: 0.0239, Loss_ode: 0.3849\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6820, Loss_data: 0.0241, Loss_ode: 0.3827\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6830, Loss_data: 0.0239, Loss_ode: 0.3851\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6840, Loss_data: 0.0237, Loss_ode: 0.3786\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6850, Loss_data: 0.0234, Loss_ode: 0.3706\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6860, Loss_data: 0.0234, Loss_ode: 0.3777\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6870, Loss_data: 0.0232, Loss_ode: 0.4544\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6880, Loss_data: 0.0240, Loss_ode: 0.4116\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6890, Loss_data: 0.0233, Loss_ode: 0.3762\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6900, Loss_data: 0.0231, Loss_ode: 0.3727\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6910, Loss_data: 0.0234, Loss_ode: 0.3732\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6920, Loss_data: 0.0235, Loss_ode: 0.3710\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6930, Loss_data: 0.0232, Loss_ode: 0.3872\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6940, Loss_data: 0.0231, Loss_ode: 0.3789\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6950, Loss_data: 0.0230, Loss_ode: 0.3964\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6960, Loss_data: 0.0231, Loss_ode: 0.3712\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6970, Loss_data: 0.0232, Loss_ode: 0.3587\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6980, Loss_data: 0.0232, Loss_ode: 0.3735\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6990, Loss_data: 0.0233, Loss_ode: 0.3727\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7000, Loss_data: 0.0230, Loss_ode: 0.3694\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7010, Loss_data: 0.0229, Loss_ode: 0.5631\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7020, Loss_data: 0.0231, Loss_ode: 0.3636\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7030, Loss_data: 0.0227, Loss_ode: 0.4121\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7040, Loss_data: 0.0226, Loss_ode: 0.3617\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7050, Loss_data: 0.0231, Loss_ode: 0.3647\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7060, Loss_data: 0.0233, Loss_ode: 0.3735\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7070, Loss_data: 0.0227, Loss_ode: 0.3703\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7080, Loss_data: 0.0228, Loss_ode: 0.3634\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7090, Loss_data: 0.0228, Loss_ode: 0.3531\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7100, Loss_data: 0.0225, Loss_ode: 0.3585\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7110, Loss_data: 0.0227, Loss_ode: 0.3499\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7120, Loss_data: 0.0229, Loss_ode: 0.3610\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7130, Loss_data: 0.0224, Loss_ode: 0.3619\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7140, Loss_data: 0.0224, Loss_ode: 0.3718\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7150, Loss_data: 0.0224, Loss_ode: 0.3573\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7160, Loss_data: 0.0225, Loss_ode: 0.3524\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7170, Loss_data: 0.0226, Loss_ode: 0.3613\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7180, Loss_data: 0.0230, Loss_ode: 0.4692\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7190, Loss_data: 0.0221, Loss_ode: 0.3642\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7200, Loss_data: 0.0222, Loss_ode: 0.3608\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7210, Loss_data: 0.0222, Loss_ode: 0.3471\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7220, Loss_data: 0.0221, Loss_ode: 0.3691\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7230, Loss_data: 0.0220, Loss_ode: 0.3763\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7240, Loss_data: 0.0223, Loss_ode: 0.3516\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7250, Loss_data: 0.0218, Loss_ode: 0.3487\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7260, Loss_data: 0.0219, Loss_ode: 0.3570\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7270, Loss_data: 0.0218, Loss_ode: 0.3688\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7280, Loss_data: 0.0219, Loss_ode: 0.3487\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7290, Loss_data: 0.0213, Loss_ode: 0.4686\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7300, Loss_data: 0.0221, Loss_ode: 0.3705\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7310, Loss_data: 0.0214, Loss_ode: 0.3452\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7320, Loss_data: 0.0217, Loss_ode: 0.3487\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7330, Loss_data: 0.0216, Loss_ode: 0.3582\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7340, Loss_data: 0.0215, Loss_ode: 0.3576\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7350, Loss_data: 0.0216, Loss_ode: 0.3291\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7360, Loss_data: 0.0216, Loss_ode: 0.3376\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7370, Loss_data: 0.0216, Loss_ode: 0.3509\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7380, Loss_data: 0.0227, Loss_ode: 0.5997\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7390, Loss_data: 0.0218, Loss_ode: 0.3742\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7400, Loss_data: 0.0214, Loss_ode: 0.3443\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7410, Loss_data: 0.0213, Loss_ode: 0.3419\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7420, Loss_data: 0.0215, Loss_ode: 0.3354\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7430, Loss_data: 0.0214, Loss_ode: 0.3327\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7440, Loss_data: 0.0214, Loss_ode: 0.3365\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7450, Loss_data: 0.0212, Loss_ode: 0.3405\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7460, Loss_data: 0.0213, Loss_ode: 0.3438\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7470, Loss_data: 0.0218, Loss_ode: 0.4770\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7480, Loss_data: 0.0209, Loss_ode: 0.3727\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7490, Loss_data: 0.0207, Loss_ode: 0.3392\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7500, Loss_data: 0.0211, Loss_ode: 0.3498\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7510, Loss_data: 0.0211, Loss_ode: 0.3314\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7520, Loss_data: 0.0211, Loss_ode: 0.3367\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7530, Loss_data: 0.0211, Loss_ode: 0.3255\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7540, Loss_data: 0.0209, Loss_ode: 0.3321\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7550, Loss_data: 0.0210, Loss_ode: 0.3298\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7560, Loss_data: 0.0209, Loss_ode: 0.3254\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7570, Loss_data: 0.0209, Loss_ode: 0.3311\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7580, Loss_data: 0.0209, Loss_ode: 0.3274\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7590, Loss_data: 0.0209, Loss_ode: 0.3326\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7600, Loss_data: 0.0209, Loss_ode: 0.3233\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7610, Loss_data: 0.0207, Loss_ode: 0.3271\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7620, Loss_data: 0.0207, Loss_ode: 0.3242\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7630, Loss_data: 0.0205, Loss_ode: 0.3210\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7640, Loss_data: 0.0206, Loss_ode: 0.3178\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7650, Loss_data: 0.0206, Loss_ode: 0.3225\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7660, Loss_data: 0.0205, Loss_ode: 0.3261\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7670, Loss_data: 0.0205, Loss_ode: 0.3234\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7680, Loss_data: 0.0206, Loss_ode: 0.3216\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7690, Loss_data: 0.0204, Loss_ode: 0.3168\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7700, Loss_data: 0.0206, Loss_ode: 0.3275\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7710, Loss_data: 0.0205, Loss_ode: 0.3245\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7720, Loss_data: 0.0204, Loss_ode: 0.3193\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7730, Loss_data: 0.0204, Loss_ode: 0.3288\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7740, Loss_data: 0.0205, Loss_ode: 0.3231\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7750, Loss_data: 0.0203, Loss_ode: 0.3239\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7760, Loss_data: 0.0203, Loss_ode: 0.3216\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7770, Loss_data: 0.0202, Loss_ode: 0.3212\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7780, Loss_data: 0.0200, Loss_ode: 0.3260\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7790, Loss_data: 0.0201, Loss_ode: 0.3144\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7800, Loss_data: 0.0202, Loss_ode: 0.3050\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7810, Loss_data: 0.0202, Loss_ode: 0.3153\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7820, Loss_data: 0.0201, Loss_ode: 0.3151\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7830, Loss_data: 0.0201, Loss_ode: 0.3166\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7840, Loss_data: 0.0203, Loss_ode: 0.3135\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7850, Loss_data: 0.0200, Loss_ode: 0.3167\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7860, Loss_data: 0.0201, Loss_ode: 0.3159\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7870, Loss_data: 0.0198, Loss_ode: 0.3160\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7880, Loss_data: 0.0199, Loss_ode: 0.3141\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7890, Loss_data: 0.0198, Loss_ode: 0.3166\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7900, Loss_data: 0.0197, Loss_ode: 0.3144\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7910, Loss_data: 0.0199, Loss_ode: 0.3096\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7920, Loss_data: 0.0198, Loss_ode: 0.3189\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7930, Loss_data: 0.0198, Loss_ode: 0.3117\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7940, Loss_data: 0.0198, Loss_ode: 0.3094\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7950, Loss_data: 0.0197, Loss_ode: 0.3112\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7960, Loss_data: 0.0198, Loss_ode: 0.3120\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7970, Loss_data: 0.0196, Loss_ode: 0.3047\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7980, Loss_data: 0.0197, Loss_ode: 0.3052\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7990, Loss_data: 0.0195, Loss_ode: 0.3107\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8000, Loss_data: 0.0195, Loss_ode: 0.3175\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8010, Loss_data: 0.0193, Loss_ode: 0.3122\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8020, Loss_data: 0.0196, Loss_ode: 0.3079\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8030, Loss_data: 0.0195, Loss_ode: 0.3061\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8040, Loss_data: 0.0195, Loss_ode: 0.3094\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8050, Loss_data: 0.0195, Loss_ode: 0.3108\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8060, Loss_data: 0.0193, Loss_ode: 0.3049\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8070, Loss_data: 0.0194, Loss_ode: 0.3135\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8080, Loss_data: 0.0193, Loss_ode: 0.3039\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8090, Loss_data: 0.0194, Loss_ode: 0.3057\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8100, Loss_data: 0.0192, Loss_ode: 0.3111\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8110, Loss_data: 0.0191, Loss_ode: 0.3071\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8120, Loss_data: 0.0190, Loss_ode: 0.3048\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8130, Loss_data: 0.0193, Loss_ode: 0.3048\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8140, Loss_data: 0.0190, Loss_ode: 0.3055\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8150, Loss_data: 0.0190, Loss_ode: 0.3065\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8160, Loss_data: 0.0189, Loss_ode: 0.3095\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8170, Loss_data: 0.0190, Loss_ode: 0.2954\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8180, Loss_data: 0.0191, Loss_ode: 0.2993\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8190, Loss_data: 0.0189, Loss_ode: 0.3054\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8200, Loss_data: 0.0190, Loss_ode: 0.3067\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8210, Loss_data: 0.0187, Loss_ode: 0.3198\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8220, Loss_data: 0.0187, Loss_ode: 0.3002\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8230, Loss_data: 0.0188, Loss_ode: 0.3025\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8240, Loss_data: 0.0188, Loss_ode: 0.2978\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8250, Loss_data: 0.0191, Loss_ode: 0.3033\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8260, Loss_data: 0.0190, Loss_ode: 0.3130\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8270, Loss_data: 0.0189, Loss_ode: 0.3105\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8280, Loss_data: 0.0186, Loss_ode: 0.3095\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8290, Loss_data: 0.0188, Loss_ode: 0.2940\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8300, Loss_data: 0.0186, Loss_ode: 0.3072\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8310, Loss_data: 0.0182, Loss_ode: 0.3881\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8320, Loss_data: 0.0188, Loss_ode: 0.3138\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8330, Loss_data: 0.0184, Loss_ode: 0.2970\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8340, Loss_data: 0.0186, Loss_ode: 0.2917\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8350, Loss_data: 0.0185, Loss_ode: 0.3054\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8360, Loss_data: 0.0186, Loss_ode: 0.2993\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8370, Loss_data: 0.0184, Loss_ode: 0.3054\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8380, Loss_data: 0.0184, Loss_ode: 0.2971\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8390, Loss_data: 0.0183, Loss_ode: 0.2959\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8400, Loss_data: 0.0181, Loss_ode: 0.3321\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8410, Loss_data: 0.0183, Loss_ode: 0.2942\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8420, Loss_data: 0.0180, Loss_ode: 0.2960\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8430, Loss_data: 0.0185, Loss_ode: 0.3142\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8440, Loss_data: 0.0182, Loss_ode: 0.2943\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8450, Loss_data: 0.0182, Loss_ode: 0.2908\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8460, Loss_data: 0.0182, Loss_ode: 0.2891\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8470, Loss_data: 0.0182, Loss_ode: 0.2912\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8480, Loss_data: 0.0179, Loss_ode: 0.3062\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8490, Loss_data: 0.0180, Loss_ode: 0.3180\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8500, Loss_data: 0.0178, Loss_ode: 0.2939\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8510, Loss_data: 0.0181, Loss_ode: 0.2938\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8520, Loss_data: 0.0178, Loss_ode: 0.2922\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8530, Loss_data: 0.0181, Loss_ode: 0.2950\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8540, Loss_data: 0.0182, Loss_ode: 0.3134\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8550, Loss_data: 0.0176, Loss_ode: 0.2978\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8560, Loss_data: 0.0179, Loss_ode: 0.2905\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8570, Loss_data: 0.0176, Loss_ode: 0.2929\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8580, Loss_data: 0.0180, Loss_ode: 0.2952\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8590, Loss_data: 0.0176, Loss_ode: 0.2886\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8600, Loss_data: 0.0179, Loss_ode: 0.2840\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8610, Loss_data: 0.0174, Loss_ode: 0.3128\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8620, Loss_data: 0.0176, Loss_ode: 0.2887\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8630, Loss_data: 0.0175, Loss_ode: 0.3018\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8640, Loss_data: 0.0176, Loss_ode: 0.2836\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8650, Loss_data: 0.0177, Loss_ode: 0.2911\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8660, Loss_data: 0.0177, Loss_ode: 0.2801\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8670, Loss_data: 0.0176, Loss_ode: 0.2814\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8680, Loss_data: 0.0175, Loss_ode: 0.2865\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8690, Loss_data: 0.0177, Loss_ode: 0.3219\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8700, Loss_data: 0.0173, Loss_ode: 0.2917\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8710, Loss_data: 0.0175, Loss_ode: 0.2904\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8720, Loss_data: 0.0173, Loss_ode: 0.2858\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8730, Loss_data: 0.0173, Loss_ode: 0.2847\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8740, Loss_data: 0.0173, Loss_ode: 0.2806\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8750, Loss_data: 0.0174, Loss_ode: 0.2849\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8760, Loss_data: 0.0178, Loss_ode: 0.3715\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8770, Loss_data: 0.0170, Loss_ode: 0.2953\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8780, Loss_data: 0.0172, Loss_ode: 0.2794\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8790, Loss_data: 0.0172, Loss_ode: 0.2894\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8800, Loss_data: 0.0172, Loss_ode: 0.2782\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8810, Loss_data: 0.0171, Loss_ode: 0.2773\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8820, Loss_data: 0.0172, Loss_ode: 0.2781\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8830, Loss_data: 0.0170, Loss_ode: 0.2739\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8840, Loss_data: 0.0175, Loss_ode: 0.3489\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8850, Loss_data: 0.0168, Loss_ode: 0.3065\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8860, Loss_data: 0.0171, Loss_ode: 0.2822\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8870, Loss_data: 0.0167, Loss_ode: 0.2836\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8880, Loss_data: 0.0170, Loss_ode: 0.2862\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8890, Loss_data: 0.0169, Loss_ode: 0.2772\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8900, Loss_data: 0.0172, Loss_ode: 0.3047\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8910, Loss_data: 0.0166, Loss_ode: 0.2809\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8920, Loss_data: 0.0169, Loss_ode: 0.2765\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8930, Loss_data: 0.0169, Loss_ode: 0.3021\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8940, Loss_data: 0.0166, Loss_ode: 0.2892\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8950, Loss_data: 0.0167, Loss_ode: 0.2716\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8960, Loss_data: 0.0168, Loss_ode: 0.2713\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8970, Loss_data: 0.0168, Loss_ode: 0.2712\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8980, Loss_data: 0.0167, Loss_ode: 0.2778\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8990, Loss_data: 0.0172, Loss_ode: 0.3915\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9000, Loss_data: 0.0164, Loss_ode: 0.2768\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9010, Loss_data: 0.0165, Loss_ode: 0.2783\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9020, Loss_data: 0.0166, Loss_ode: 0.2708\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9030, Loss_data: 0.0164, Loss_ode: 0.2765\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9040, Loss_data: 0.0165, Loss_ode: 0.2763\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9050, Loss_data: 0.0166, Loss_ode: 0.2772\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9060, Loss_data: 0.0164, Loss_ode: 0.2777\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9070, Loss_data: 0.0163, Loss_ode: 0.2886\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9080, Loss_data: 0.0160, Loss_ode: 0.3209\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9090, Loss_data: 0.0163, Loss_ode: 0.2737\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9100, Loss_data: 0.0166, Loss_ode: 0.2866\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9110, Loss_data: 0.0163, Loss_ode: 0.2724\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9120, Loss_data: 0.0165, Loss_ode: 0.2770\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9130, Loss_data: 0.0162, Loss_ode: 0.2694\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9140, Loss_data: 0.0161, Loss_ode: 0.2685\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9150, Loss_data: 0.0161, Loss_ode: 0.2654\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9160, Loss_data: 0.0161, Loss_ode: 0.2703\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9170, Loss_data: 0.0162, Loss_ode: 0.2655\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9180, Loss_data: 0.0163, Loss_ode: 0.2961\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9190, Loss_data: 0.0163, Loss_ode: 0.2769\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9200, Loss_data: 0.0161, Loss_ode: 0.2768\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9210, Loss_data: 0.0159, Loss_ode: 0.2634\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9220, Loss_data: 0.0160, Loss_ode: 0.2640\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9230, Loss_data: 0.0159, Loss_ode: 0.2638\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9240, Loss_data: 0.0161, Loss_ode: 0.2644\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9250, Loss_data: 0.0161, Loss_ode: 0.2808\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9260, Loss_data: 0.0160, Loss_ode: 0.2802\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9270, Loss_data: 0.0158, Loss_ode: 0.2667\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9280, Loss_data: 0.0158, Loss_ode: 0.2650\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9290, Loss_data: 0.0154, Loss_ode: 0.2949\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9300, Loss_data: 0.0159, Loss_ode: 0.2711\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9310, Loss_data: 0.0159, Loss_ode: 0.2696\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9320, Loss_data: 0.0156, Loss_ode: 0.2783\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9330, Loss_data: 0.0158, Loss_ode: 0.2647\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9340, Loss_data: 0.0154, Loss_ode: 0.3032\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9350, Loss_data: 0.0158, Loss_ode: 0.2597\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9360, Loss_data: 0.0155, Loss_ode: 0.2644\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9370, Loss_data: 0.0158, Loss_ode: 0.2655\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9380, Loss_data: 0.0156, Loss_ode: 0.2631\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9390, Loss_data: 0.0156, Loss_ode: 0.2612\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9400, Loss_data: 0.0155, Loss_ode: 0.2619\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9410, Loss_data: 0.0157, Loss_ode: 0.2880\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9420, Loss_data: 0.0158, Loss_ode: 0.2691\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9430, Loss_data: 0.0158, Loss_ode: 0.2855\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9440, Loss_data: 0.0154, Loss_ode: 0.2599\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9450, Loss_data: 0.0155, Loss_ode: 0.2696\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9460, Loss_data: 0.0153, Loss_ode: 0.2657\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9470, Loss_data: 0.0154, Loss_ode: 0.2665\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9480, Loss_data: 0.0154, Loss_ode: 0.2629\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9490, Loss_data: 0.0153, Loss_ode: 0.2592\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9500, Loss_data: 0.0156, Loss_ode: 0.2791\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9510, Loss_data: 0.0154, Loss_ode: 0.2550\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9520, Loss_data: 0.0150, Loss_ode: 0.2727\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9530, Loss_data: 0.0153, Loss_ode: 0.2545\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9540, Loss_data: 0.0157, Loss_ode: 0.2786\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9550, Loss_data: 0.0157, Loss_ode: 0.3138\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9560, Loss_data: 0.0152, Loss_ode: 0.2615\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9570, Loss_data: 0.0151, Loss_ode: 0.2630\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9580, Loss_data: 0.0152, Loss_ode: 0.2667\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9590, Loss_data: 0.0152, Loss_ode: 0.2559\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9600, Loss_data: 0.0153, Loss_ode: 0.2701\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9610, Loss_data: 0.0150, Loss_ode: 0.2695\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9620, Loss_data: 0.0153, Loss_ode: 0.2603\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9630, Loss_data: 0.0153, Loss_ode: 0.2924\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9640, Loss_data: 0.0147, Loss_ode: 0.2752\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9650, Loss_data: 0.0150, Loss_ode: 0.2549\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9660, Loss_data: 0.0150, Loss_ode: 0.2698\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9670, Loss_data: 0.0148, Loss_ode: 0.2643\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9680, Loss_data: 0.0150, Loss_ode: 0.2621\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9690, Loss_data: 0.0146, Loss_ode: 0.2805\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9700, Loss_data: 0.0145, Loss_ode: 0.2685\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9710, Loss_data: 0.0149, Loss_ode: 0.2591\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9720, Loss_data: 0.0147, Loss_ode: 0.2594\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9730, Loss_data: 0.0148, Loss_ode: 0.2586\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9740, Loss_data: 0.0150, Loss_ode: 0.2868\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9750, Loss_data: 0.0148, Loss_ode: 0.2634\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9760, Loss_data: 0.0149, Loss_ode: 0.2528\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9770, Loss_data: 0.0146, Loss_ode: 0.2537\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9780, Loss_data: 0.0148, Loss_ode: 0.2546\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9790, Loss_data: 0.0147, Loss_ode: 0.2595\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9800, Loss_data: 0.0148, Loss_ode: 0.2670\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9810, Loss_data: 0.0146, Loss_ode: 0.2496\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9820, Loss_data: 0.0145, Loss_ode: 0.2625\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9830, Loss_data: 0.0142, Loss_ode: 0.2613\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9840, Loss_data: 0.0144, Loss_ode: 0.2662\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9850, Loss_data: 0.0144, Loss_ode: 0.2589\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9860, Loss_data: 0.0145, Loss_ode: 0.2530\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9870, Loss_data: 0.0146, Loss_ode: 0.2532\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9880, Loss_data: 0.0146, Loss_ode: 0.2572\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9890, Loss_data: 0.0152, Loss_ode: 0.4226\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9900, Loss_data: 0.0147, Loss_ode: 0.2744\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9910, Loss_data: 0.0145, Loss_ode: 0.2531\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9920, Loss_data: 0.0142, Loss_ode: 0.2590\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9930, Loss_data: 0.0144, Loss_ode: 0.2516\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9940, Loss_data: 0.0145, Loss_ode: 0.2549\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9950, Loss_data: 0.0141, Loss_ode: 0.2526\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9960, Loss_data: 0.0142, Loss_ode: 0.2509\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9970, Loss_data: 0.0144, Loss_ode: 0.2550\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9980, Loss_data: 0.0140, Loss_ode: 0.2657\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9990, Loss_data: 0.0141, Loss_ode: 0.2621\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 10000, Loss_data: 0.0141, Loss_ode: 0.2513\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10010, Loss_data: 0.0142, Loss_ode: 0.2448\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10020, Loss_data: 0.0141, Loss_ode: 0.2459\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10030, Loss_data: 0.0141, Loss_ode: 0.2488\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10040, Loss_data: 0.0141, Loss_ode: 0.2583\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10050, Loss_data: 0.0141, Loss_ode: 0.2441\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10060, Loss_data: 0.0140, Loss_ode: 0.2480\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10070, Loss_data: 0.0140, Loss_ode: 0.2437\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10080, Loss_data: 0.0140, Loss_ode: 0.2502\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10090, Loss_data: 0.0140, Loss_ode: 0.2433\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10100, Loss_data: 0.0140, Loss_ode: 0.2485\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10110, Loss_data: 0.0140, Loss_ode: 0.2519\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10120, Loss_data: 0.0140, Loss_ode: 0.2483\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10130, Loss_data: 0.0140, Loss_ode: 0.2494\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10140, Loss_data: 0.0139, Loss_ode: 0.2525\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10150, Loss_data: 0.0140, Loss_ode: 0.2447\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10160, Loss_data: 0.0140, Loss_ode: 0.2453\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10170, Loss_data: 0.0138, Loss_ode: 0.2530\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10180, Loss_data: 0.0138, Loss_ode: 0.2473\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10190, Loss_data: 0.0139, Loss_ode: 0.2458\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10200, Loss_data: 0.0138, Loss_ode: 0.2475\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10210, Loss_data: 0.0139, Loss_ode: 0.2472\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10220, Loss_data: 0.0137, Loss_ode: 0.2522\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10230, Loss_data: 0.0137, Loss_ode: 0.2417\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10240, Loss_data: 0.0137, Loss_ode: 0.2420\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10250, Loss_data: 0.0138, Loss_ode: 0.2448\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10260, Loss_data: 0.0137, Loss_ode: 0.2439\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10270, Loss_data: 0.0137, Loss_ode: 0.2471\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10280, Loss_data: 0.0137, Loss_ode: 0.2390\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10290, Loss_data: 0.0137, Loss_ode: 0.2398\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10300, Loss_data: 0.0137, Loss_ode: 0.2449\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10310, Loss_data: 0.0135, Loss_ode: 0.2446\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10320, Loss_data: 0.0136, Loss_ode: 0.2456\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10330, Loss_data: 0.0137, Loss_ode: 0.2387\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10340, Loss_data: 0.0136, Loss_ode: 0.2446\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10350, Loss_data: 0.0137, Loss_ode: 0.2401\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10360, Loss_data: 0.0134, Loss_ode: 0.2440\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10370, Loss_data: 0.0137, Loss_ode: 0.2404\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10380, Loss_data: 0.0135, Loss_ode: 0.2432\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10390, Loss_data: 0.0135, Loss_ode: 0.2380\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10400, Loss_data: 0.0134, Loss_ode: 0.2443\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10410, Loss_data: 0.0136, Loss_ode: 0.2452\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10420, Loss_data: 0.0134, Loss_ode: 0.2384\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10430, Loss_data: 0.0135, Loss_ode: 0.2389\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10440, Loss_data: 0.0134, Loss_ode: 0.2419\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10450, Loss_data: 0.0135, Loss_ode: 0.2435\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10460, Loss_data: 0.0134, Loss_ode: 0.2376\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10470, Loss_data: 0.0133, Loss_ode: 0.2440\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10480, Loss_data: 0.0134, Loss_ode: 0.2449\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10490, Loss_data: 0.0132, Loss_ode: 0.2430\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10500, Loss_data: 0.0133, Loss_ode: 0.2420\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10510, Loss_data: 0.0133, Loss_ode: 0.2435\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10520, Loss_data: 0.0133, Loss_ode: 0.2408\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10530, Loss_data: 0.0132, Loss_ode: 0.2400\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10540, Loss_data: 0.0133, Loss_ode: 0.2395\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10550, Loss_data: 0.0133, Loss_ode: 0.2459\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10560, Loss_data: 0.0131, Loss_ode: 0.2394\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10570, Loss_data: 0.0132, Loss_ode: 0.2452\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10580, Loss_data: 0.0132, Loss_ode: 0.2470\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10590, Loss_data: 0.0134, Loss_ode: 0.2420\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10600, Loss_data: 0.0132, Loss_ode: 0.2422\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10610, Loss_data: 0.0130, Loss_ode: 0.2421\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10620, Loss_data: 0.0132, Loss_ode: 0.2414\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10630, Loss_data: 0.0133, Loss_ode: 0.2414\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10640, Loss_data: 0.0130, Loss_ode: 0.2426\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10650, Loss_data: 0.0131, Loss_ode: 0.2456\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10660, Loss_data: 0.0132, Loss_ode: 0.2412\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10670, Loss_data: 0.0129, Loss_ode: 0.2417\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10680, Loss_data: 0.0132, Loss_ode: 0.2377\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10690, Loss_data: 0.0130, Loss_ode: 0.2397\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10700, Loss_data: 0.0131, Loss_ode: 0.2492\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10710, Loss_data: 0.0129, Loss_ode: 0.2397\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10720, Loss_data: 0.0130, Loss_ode: 0.2372\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10730, Loss_data: 0.0130, Loss_ode: 0.2382\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10740, Loss_data: 0.0129, Loss_ode: 0.2393\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10750, Loss_data: 0.0130, Loss_ode: 0.2495\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10760, Loss_data: 0.0130, Loss_ode: 0.2488\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10770, Loss_data: 0.0128, Loss_ode: 0.2423\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10780, Loss_data: 0.0130, Loss_ode: 0.2438\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10790, Loss_data: 0.0127, Loss_ode: 0.2449\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10800, Loss_data: 0.0127, Loss_ode: 0.2843\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10810, Loss_data: 0.0130, Loss_ode: 0.2508\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10820, Loss_data: 0.0126, Loss_ode: 0.2382\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10830, Loss_data: 0.0130, Loss_ode: 0.2422\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10840, Loss_data: 0.0127, Loss_ode: 0.2477\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10850, Loss_data: 0.0128, Loss_ode: 0.2420\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10860, Loss_data: 0.0127, Loss_ode: 0.2376\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10870, Loss_data: 0.0128, Loss_ode: 0.2468\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10880, Loss_data: 0.0125, Loss_ode: 0.2390\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10890, Loss_data: 0.0127, Loss_ode: 0.2394\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10900, Loss_data: 0.0128, Loss_ode: 0.2398\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10910, Loss_data: 0.0126, Loss_ode: 0.2425\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10920, Loss_data: 0.0127, Loss_ode: 0.2537\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10930, Loss_data: 0.0127, Loss_ode: 0.2357\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10940, Loss_data: 0.0127, Loss_ode: 0.2372\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10950, Loss_data: 0.0125, Loss_ode: 0.2389\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10960, Loss_data: 0.0128, Loss_ode: 0.2446\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10970, Loss_data: 0.0126, Loss_ode: 0.2342\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10980, Loss_data: 0.0124, Loss_ode: 0.2379\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10990, Loss_data: 0.0128, Loss_ode: 0.2394\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11000, Loss_data: 0.0126, Loss_ode: 0.2422\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11010, Loss_data: 0.0125, Loss_ode: 0.2359\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11020, Loss_data: 0.0126, Loss_ode: 0.2388\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11030, Loss_data: 0.0127, Loss_ode: 0.2368\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11040, Loss_data: 0.0124, Loss_ode: 0.2400\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11050, Loss_data: 0.0125, Loss_ode: 0.2411\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11060, Loss_data: 0.0125, Loss_ode: 0.2346\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11070, Loss_data: 0.0127, Loss_ode: 0.2481\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11080, Loss_data: 0.0124, Loss_ode: 0.2360\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11090, Loss_data: 0.0125, Loss_ode: 0.2339\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11100, Loss_data: 0.0124, Loss_ode: 0.2396\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11110, Loss_data: 0.0126, Loss_ode: 0.2355\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11120, Loss_data: 0.0126, Loss_ode: 0.2338\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11130, Loss_data: 0.0123, Loss_ode: 0.2339\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11140, Loss_data: 0.0124, Loss_ode: 0.2365\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11150, Loss_data: 0.0120, Loss_ode: 0.2982\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11160, Loss_data: 0.0125, Loss_ode: 0.2506\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11170, Loss_data: 0.0123, Loss_ode: 0.2307\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11180, Loss_data: 0.0124, Loss_ode: 0.2307\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11190, Loss_data: 0.0123, Loss_ode: 0.2378\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11200, Loss_data: 0.0121, Loss_ode: 0.2334\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11210, Loss_data: 0.0123, Loss_ode: 0.2323\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11220, Loss_data: 0.0119, Loss_ode: 0.2460\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11230, Loss_data: 0.0124, Loss_ode: 0.2305\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11240, Loss_data: 0.0124, Loss_ode: 0.2310\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11250, Loss_data: 0.0121, Loss_ode: 0.2380\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11260, Loss_data: 0.0120, Loss_ode: 0.2476\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11270, Loss_data: 0.0122, Loss_ode: 0.2351\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11280, Loss_data: 0.0123, Loss_ode: 0.2300\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11290, Loss_data: 0.0117, Loss_ode: 0.2432\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11300, Loss_data: 0.0121, Loss_ode: 0.2311\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11310, Loss_data: 0.0123, Loss_ode: 0.2324\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11320, Loss_data: 0.0120, Loss_ode: 0.2447\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11330, Loss_data: 0.0119, Loss_ode: 0.2344\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11340, Loss_data: 0.0120, Loss_ode: 0.2336\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11350, Loss_data: 0.0120, Loss_ode: 0.2338\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11360, Loss_data: 0.0122, Loss_ode: 0.2447\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11370, Loss_data: 0.0121, Loss_ode: 0.2337\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11380, Loss_data: 0.0119, Loss_ode: 0.2262\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11390, Loss_data: 0.0120, Loss_ode: 0.2337\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11400, Loss_data: 0.0121, Loss_ode: 0.2307\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11410, Loss_data: 0.0123, Loss_ode: 0.2664\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11420, Loss_data: 0.0118, Loss_ode: 0.2450\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11430, Loss_data: 0.0120, Loss_ode: 0.2317\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11440, Loss_data: 0.0118, Loss_ode: 0.2354\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11450, Loss_data: 0.0120, Loss_ode: 0.2369\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11460, Loss_data: 0.0121, Loss_ode: 0.2483\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11470, Loss_data: 0.0118, Loss_ode: 0.2363\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11480, Loss_data: 0.0120, Loss_ode: 0.2338\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11490, Loss_data: 0.0120, Loss_ode: 0.2295\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11500, Loss_data: 0.0117, Loss_ode: 0.2342\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11510, Loss_data: 0.0119, Loss_ode: 0.2324\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11520, Loss_data: 0.0119, Loss_ode: 0.2314\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11530, Loss_data: 0.0120, Loss_ode: 0.2468\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11540, Loss_data: 0.0120, Loss_ode: 0.2355\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11550, Loss_data: 0.0116, Loss_ode: 0.2329\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11560, Loss_data: 0.0117, Loss_ode: 0.2250\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11570, Loss_data: 0.0118, Loss_ode: 0.2303\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11580, Loss_data: 0.0119, Loss_ode: 0.2303\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11590, Loss_data: 0.0121, Loss_ode: 0.2670\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11600, Loss_data: 0.0116, Loss_ode: 0.2403\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11610, Loss_data: 0.0119, Loss_ode: 0.2283\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11620, Loss_data: 0.0116, Loss_ode: 0.2299\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11630, Loss_data: 0.0118, Loss_ode: 0.2266\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11640, Loss_data: 0.0116, Loss_ode: 0.2380\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11650, Loss_data: 0.0116, Loss_ode: 0.2248\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11660, Loss_data: 0.0119, Loss_ode: 0.2315\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11670, Loss_data: 0.0115, Loss_ode: 0.2280\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11680, Loss_data: 0.0117, Loss_ode: 0.2294\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11690, Loss_data: 0.0117, Loss_ode: 0.2300\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11700, Loss_data: 0.0120, Loss_ode: 0.2693\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11710, Loss_data: 0.0114, Loss_ode: 0.2438\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11720, Loss_data: 0.0117, Loss_ode: 0.2322\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11730, Loss_data: 0.0114, Loss_ode: 0.2290\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11740, Loss_data: 0.0115, Loss_ode: 0.2283\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11750, Loss_data: 0.0115, Loss_ode: 0.2274\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11760, Loss_data: 0.0114, Loss_ode: 0.2284\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11770, Loss_data: 0.0114, Loss_ode: 0.2329\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11780, Loss_data: 0.0114, Loss_ode: 0.2261\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11790, Loss_data: 0.0117, Loss_ode: 0.2335\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11800, Loss_data: 0.0113, Loss_ode: 0.2268\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11810, Loss_data: 0.0114, Loss_ode: 0.2349\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11820, Loss_data: 0.0115, Loss_ode: 0.2240\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11830, Loss_data: 0.0116, Loss_ode: 0.2367\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11840, Loss_data: 0.0113, Loss_ode: 0.2440\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11850, Loss_data: 0.0117, Loss_ode: 0.2390\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11860, Loss_data: 0.0114, Loss_ode: 0.2221\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11870, Loss_data: 0.0114, Loss_ode: 0.2257\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11880, Loss_data: 0.0115, Loss_ode: 0.2266\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11890, Loss_data: 0.0113, Loss_ode: 0.2257\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11900, Loss_data: 0.0113, Loss_ode: 0.2319\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11910, Loss_data: 0.0113, Loss_ode: 0.2281\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11920, Loss_data: 0.0115, Loss_ode: 0.2326\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11930, Loss_data: 0.0114, Loss_ode: 0.2265\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11940, Loss_data: 0.0111, Loss_ode: 0.2305\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11950, Loss_data: 0.0111, Loss_ode: 0.2337\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11960, Loss_data: 0.0113, Loss_ode: 0.2340\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11970, Loss_data: 0.0111, Loss_ode: 0.2234\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11980, Loss_data: 0.0116, Loss_ode: 0.2308\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11990, Loss_data: 0.0112, Loss_ode: 0.2253\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12000, Loss_data: 0.0111, Loss_ode: 0.2343\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12010, Loss_data: 0.0110, Loss_ode: 0.2370\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12020, Loss_data: 0.0114, Loss_ode: 0.2257\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12030, Loss_data: 0.0113, Loss_ode: 0.2247\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12040, Loss_data: 0.0111, Loss_ode: 0.2263\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12050, Loss_data: 0.0114, Loss_ode: 0.2383\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12060, Loss_data: 0.0112, Loss_ode: 0.2199\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12070, Loss_data: 0.0111, Loss_ode: 0.2212\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12080, Loss_data: 0.0111, Loss_ode: 0.2301\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12090, Loss_data: 0.0111, Loss_ode: 0.2224\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12100, Loss_data: 0.0112, Loss_ode: 0.2276\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12110, Loss_data: 0.0112, Loss_ode: 0.2218\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12120, Loss_data: 0.0113, Loss_ode: 0.2330\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12130, Loss_data: 0.0114, Loss_ode: 0.2337\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12140, Loss_data: 0.0111, Loss_ode: 0.2263\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12150, Loss_data: 0.0112, Loss_ode: 0.2264\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12160, Loss_data: 0.0110, Loss_ode: 0.2242\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12170, Loss_data: 0.0111, Loss_ode: 0.2261\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12180, Loss_data: 0.0109, Loss_ode: 0.2329\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12190, Loss_data: 0.0110, Loss_ode: 0.2224\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12200, Loss_data: 0.0110, Loss_ode: 0.2177\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12210, Loss_data: 0.0109, Loss_ode: 0.2204\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12220, Loss_data: 0.0111, Loss_ode: 0.2217\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12230, Loss_data: 0.0110, Loss_ode: 0.2247\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12240, Loss_data: 0.0110, Loss_ode: 0.2256\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12250, Loss_data: 0.0110, Loss_ode: 0.2259\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12260, Loss_data: 0.0110, Loss_ode: 0.2273\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12270, Loss_data: 0.0111, Loss_ode: 0.2280\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12280, Loss_data: 0.0111, Loss_ode: 0.2265\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12290, Loss_data: 0.0112, Loss_ode: 0.2521\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12300, Loss_data: 0.0108, Loss_ode: 0.2201\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12310, Loss_data: 0.0110, Loss_ode: 0.2217\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12320, Loss_data: 0.0110, Loss_ode: 0.2231\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12330, Loss_data: 0.0110, Loss_ode: 0.2221\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12340, Loss_data: 0.0107, Loss_ode: 0.2279\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12350, Loss_data: 0.0111, Loss_ode: 0.2180\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12360, Loss_data: 0.0111, Loss_ode: 0.2399\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12370, Loss_data: 0.0107, Loss_ode: 0.2256\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12380, Loss_data: 0.0110, Loss_ode: 0.2214\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12390, Loss_data: 0.0108, Loss_ode: 0.2235\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12400, Loss_data: 0.0108, Loss_ode: 0.2199\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12410, Loss_data: 0.0108, Loss_ode: 0.2221\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12420, Loss_data: 0.0108, Loss_ode: 0.2235\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12430, Loss_data: 0.0107, Loss_ode: 0.2178\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12440, Loss_data: 0.0110, Loss_ode: 0.2262\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12450, Loss_data: 0.0108, Loss_ode: 0.2186\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12460, Loss_data: 0.0106, Loss_ode: 0.2188\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12470, Loss_data: 0.0109, Loss_ode: 0.2195\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12480, Loss_data: 0.0108, Loss_ode: 0.2303\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12490, Loss_data: 0.0108, Loss_ode: 0.2240\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12500, Loss_data: 0.0106, Loss_ode: 0.2252\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12510, Loss_data: 0.0107, Loss_ode: 0.2211\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12520, Loss_data: 0.0108, Loss_ode: 0.2200\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12530, Loss_data: 0.0108, Loss_ode: 0.2198\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12540, Loss_data: 0.0106, Loss_ode: 0.2178\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12550, Loss_data: 0.0107, Loss_ode: 0.2171\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12560, Loss_data: 0.0107, Loss_ode: 0.2172\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12570, Loss_data: 0.0107, Loss_ode: 0.2153\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12580, Loss_data: 0.0107, Loss_ode: 0.2180\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12590, Loss_data: 0.0107, Loss_ode: 0.2220\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12600, Loss_data: 0.0107, Loss_ode: 0.2136\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12610, Loss_data: 0.0107, Loss_ode: 0.2160\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12620, Loss_data: 0.0105, Loss_ode: 0.2171\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12630, Loss_data: 0.0107, Loss_ode: 0.2168\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12640, Loss_data: 0.0105, Loss_ode: 0.2164\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12650, Loss_data: 0.0106, Loss_ode: 0.2132\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12660, Loss_data: 0.0106, Loss_ode: 0.2197\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12670, Loss_data: 0.0105, Loss_ode: 0.2249\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12680, Loss_data: 0.0106, Loss_ode: 0.2190\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12690, Loss_data: 0.0105, Loss_ode: 0.2151\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12700, Loss_data: 0.0106, Loss_ode: 0.2186\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12710, Loss_data: 0.0107, Loss_ode: 0.2206\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12720, Loss_data: 0.0105, Loss_ode: 0.2139\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12730, Loss_data: 0.0106, Loss_ode: 0.2197\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12740, Loss_data: 0.0106, Loss_ode: 0.2149\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12750, Loss_data: 0.0105, Loss_ode: 0.2165\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12760, Loss_data: 0.0105, Loss_ode: 0.2201\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12770, Loss_data: 0.0105, Loss_ode: 0.2147\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12780, Loss_data: 0.0106, Loss_ode: 0.2159\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12790, Loss_data: 0.0105, Loss_ode: 0.2189\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12800, Loss_data: 0.0105, Loss_ode: 0.2172\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12810, Loss_data: 0.0105, Loss_ode: 0.2203\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12820, Loss_data: 0.0104, Loss_ode: 0.2180\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12830, Loss_data: 0.0105, Loss_ode: 0.2157\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12840, Loss_data: 0.0105, Loss_ode: 0.2199\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12850, Loss_data: 0.0105, Loss_ode: 0.2148\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12860, Loss_data: 0.0104, Loss_ode: 0.2162\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12870, Loss_data: 0.0105, Loss_ode: 0.2153\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12880, Loss_data: 0.0104, Loss_ode: 0.2179\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12890, Loss_data: 0.0104, Loss_ode: 0.2157\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12900, Loss_data: 0.0104, Loss_ode: 0.2205\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12910, Loss_data: 0.0104, Loss_ode: 0.2147\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12920, Loss_data: 0.0105, Loss_ode: 0.2137\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12930, Loss_data: 0.0102, Loss_ode: 0.2153\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12940, Loss_data: 0.0104, Loss_ode: 0.2192\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12950, Loss_data: 0.0102, Loss_ode: 0.2166\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12960, Loss_data: 0.0104, Loss_ode: 0.2149\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12970, Loss_data: 0.0104, Loss_ode: 0.2142\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12980, Loss_data: 0.0105, Loss_ode: 0.2184\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12990, Loss_data: 0.0105, Loss_ode: 0.2133\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13000, Loss_data: 0.0104, Loss_ode: 0.2138\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13010, Loss_data: 0.0102, Loss_ode: 0.2154\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13020, Loss_data: 0.0104, Loss_ode: 0.2129\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13030, Loss_data: 0.0102, Loss_ode: 0.2146\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13040, Loss_data: 0.0104, Loss_ode: 0.2147\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13050, Loss_data: 0.0103, Loss_ode: 0.2169\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13060, Loss_data: 0.0104, Loss_ode: 0.2115\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13070, Loss_data: 0.0105, Loss_ode: 0.2203\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13080, Loss_data: 0.0102, Loss_ode: 0.2128\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13090, Loss_data: 0.0105, Loss_ode: 0.2159\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13100, Loss_data: 0.0102, Loss_ode: 0.2160\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13110, Loss_data: 0.0103, Loss_ode: 0.2168\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13120, Loss_data: 0.0104, Loss_ode: 0.2124\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13130, Loss_data: 0.0101, Loss_ode: 0.2147\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13140, Loss_data: 0.0103, Loss_ode: 0.2128\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13150, Loss_data: 0.0101, Loss_ode: 0.2156\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13160, Loss_data: 0.0102, Loss_ode: 0.2144\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13170, Loss_data: 0.0102, Loss_ode: 0.2181\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13180, Loss_data: 0.0102, Loss_ode: 0.2137\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13190, Loss_data: 0.0102, Loss_ode: 0.2126\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13200, Loss_data: 0.0101, Loss_ode: 0.2169\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13210, Loss_data: 0.0103, Loss_ode: 0.2182\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13220, Loss_data: 0.0102, Loss_ode: 0.2194\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13230, Loss_data: 0.0103, Loss_ode: 0.2186\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13240, Loss_data: 0.0101, Loss_ode: 0.2149\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13250, Loss_data: 0.0102, Loss_ode: 0.2142\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13260, Loss_data: 0.0103, Loss_ode: 0.2236\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13270, Loss_data: 0.0099, Loss_ode: 0.2252\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13280, Loss_data: 0.0103, Loss_ode: 0.2124\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13290, Loss_data: 0.0101, Loss_ode: 0.2101\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13300, Loss_data: 0.0101, Loss_ode: 0.2153\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13310, Loss_data: 0.0101, Loss_ode: 0.2150\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13320, Loss_data: 0.0101, Loss_ode: 0.2092\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13330, Loss_data: 0.0100, Loss_ode: 0.2104\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13340, Loss_data: 0.0102, Loss_ode: 0.2172\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13350, Loss_data: 0.0102, Loss_ode: 0.2132\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13360, Loss_data: 0.0100, Loss_ode: 0.2118\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13370, Loss_data: 0.0101, Loss_ode: 0.2155\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13380, Loss_data: 0.0102, Loss_ode: 0.2132\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13390, Loss_data: 0.0099, Loss_ode: 0.2139\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13400, Loss_data: 0.0099, Loss_ode: 0.2144\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13410, Loss_data: 0.0101, Loss_ode: 0.2134\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13420, Loss_data: 0.0099, Loss_ode: 0.2130\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13430, Loss_data: 0.0101, Loss_ode: 0.2131\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13440, Loss_data: 0.0102, Loss_ode: 0.2203\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13450, Loss_data: 0.0100, Loss_ode: 0.2129\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13460, Loss_data: 0.0099, Loss_ode: 0.2092\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13470, Loss_data: 0.0100, Loss_ode: 0.2216\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13480, Loss_data: 0.0098, Loss_ode: 0.2250\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13490, Loss_data: 0.0101, Loss_ode: 0.2193\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13500, Loss_data: 0.0100, Loss_ode: 0.2116\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13510, Loss_data: 0.0100, Loss_ode: 0.2104\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13520, Loss_data: 0.0099, Loss_ode: 0.2140\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13530, Loss_data: 0.0101, Loss_ode: 0.2131\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13540, Loss_data: 0.0099, Loss_ode: 0.2165\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13550, Loss_data: 0.0100, Loss_ode: 0.2163\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13560, Loss_data: 0.0102, Loss_ode: 0.2141\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13570, Loss_data: 0.0100, Loss_ode: 0.2172\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13580, Loss_data: 0.0098, Loss_ode: 0.2184\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13590, Loss_data: 0.0100, Loss_ode: 0.2147\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13600, Loss_data: 0.0101, Loss_ode: 0.2118\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13610, Loss_data: 0.0101, Loss_ode: 0.2147\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13620, Loss_data: 0.0099, Loss_ode: 0.2123\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13630, Loss_data: 0.0100, Loss_ode: 0.2142\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13640, Loss_data: 0.0099, Loss_ode: 0.2175\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13650, Loss_data: 0.0100, Loss_ode: 0.2142\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13660, Loss_data: 0.0099, Loss_ode: 0.2185\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13670, Loss_data: 0.0100, Loss_ode: 0.2101\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13680, Loss_data: 0.0101, Loss_ode: 0.2387\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13690, Loss_data: 0.0097, Loss_ode: 0.2119\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13700, Loss_data: 0.0100, Loss_ode: 0.2119\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13710, Loss_data: 0.0098, Loss_ode: 0.2123\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13720, Loss_data: 0.0098, Loss_ode: 0.2091\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13730, Loss_data: 0.0098, Loss_ode: 0.2129\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13740, Loss_data: 0.0097, Loss_ode: 0.2171\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13750, Loss_data: 0.0097, Loss_ode: 0.2147\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13760, Loss_data: 0.0098, Loss_ode: 0.2199\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13770, Loss_data: 0.0097, Loss_ode: 0.2120\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13780, Loss_data: 0.0099, Loss_ode: 0.2069\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13790, Loss_data: 0.0098, Loss_ode: 0.2185\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13800, Loss_data: 0.0097, Loss_ode: 0.2081\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13810, Loss_data: 0.0099, Loss_ode: 0.2088\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13820, Loss_data: 0.0101, Loss_ode: 0.2356\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13830, Loss_data: 0.0095, Loss_ode: 0.2135\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13840, Loss_data: 0.0098, Loss_ode: 0.2126\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13850, Loss_data: 0.0098, Loss_ode: 0.2144\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13860, Loss_data: 0.0098, Loss_ode: 0.2120\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13870, Loss_data: 0.0097, Loss_ode: 0.2123\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13880, Loss_data: 0.0098, Loss_ode: 0.2100\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13890, Loss_data: 0.0097, Loss_ode: 0.2135\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13900, Loss_data: 0.0097, Loss_ode: 0.2096\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13910, Loss_data: 0.0098, Loss_ode: 0.2095\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13920, Loss_data: 0.0098, Loss_ode: 0.2098\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13930, Loss_data: 0.0096, Loss_ode: 0.2105\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13940, Loss_data: 0.0097, Loss_ode: 0.2191\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13950, Loss_data: 0.0096, Loss_ode: 0.2111\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13960, Loss_data: 0.0098, Loss_ode: 0.2091\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13970, Loss_data: 0.0096, Loss_ode: 0.2152\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13980, Loss_data: 0.0094, Loss_ode: 0.2152\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13990, Loss_data: 0.0098, Loss_ode: 0.2046\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14000, Loss_data: 0.0097, Loss_ode: 0.2132\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14010, Loss_data: 0.0096, Loss_ode: 0.2105\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14020, Loss_data: 0.0096, Loss_ode: 0.2116\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14030, Loss_data: 0.0096, Loss_ode: 0.2073\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14040, Loss_data: 0.0097, Loss_ode: 0.2087\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14050, Loss_data: 0.0096, Loss_ode: 0.2078\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14060, Loss_data: 0.0093, Loss_ode: 0.2224\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14070, Loss_data: 0.0097, Loss_ode: 0.2165\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14080, Loss_data: 0.0095, Loss_ode: 0.2116\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14090, Loss_data: 0.0096, Loss_ode: 0.2071\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14100, Loss_data: 0.0096, Loss_ode: 0.2056\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14110, Loss_data: 0.0095, Loss_ode: 0.2095\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14120, Loss_data: 0.0097, Loss_ode: 0.2129\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14130, Loss_data: 0.0097, Loss_ode: 0.2204\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14140, Loss_data: 0.0093, Loss_ode: 0.2189\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14150, Loss_data: 0.0097, Loss_ode: 0.2149\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14160, Loss_data: 0.0094, Loss_ode: 0.2133\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14170, Loss_data: 0.0095, Loss_ode: 0.2080\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14180, Loss_data: 0.0095, Loss_ode: 0.2122\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14190, Loss_data: 0.0095, Loss_ode: 0.2064\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14200, Loss_data: 0.0096, Loss_ode: 0.2079\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14210, Loss_data: 0.0094, Loss_ode: 0.2066\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14220, Loss_data: 0.0095, Loss_ode: 0.2047\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14230, Loss_data: 0.0095, Loss_ode: 0.2095\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14240, Loss_data: 0.0094, Loss_ode: 0.2130\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14250, Loss_data: 0.0095, Loss_ode: 0.2078\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14260, Loss_data: 0.0095, Loss_ode: 0.2060\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14270, Loss_data: 0.0096, Loss_ode: 0.2181\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14280, Loss_data: 0.0094, Loss_ode: 0.2116\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14290, Loss_data: 0.0096, Loss_ode: 0.2110\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14300, Loss_data: 0.0095, Loss_ode: 0.2096\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14310, Loss_data: 0.0094, Loss_ode: 0.2065\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14320, Loss_data: 0.0094, Loss_ode: 0.2077\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14330, Loss_data: 0.0094, Loss_ode: 0.2051\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14340, Loss_data: 0.0093, Loss_ode: 0.2071\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14350, Loss_data: 0.0094, Loss_ode: 0.2054\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14360, Loss_data: 0.0094, Loss_ode: 0.2141\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14370, Loss_data: 0.0095, Loss_ode: 0.2006\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14380, Loss_data: 0.0094, Loss_ode: 0.2065\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14390, Loss_data: 0.0091, Loss_ode: 0.2280\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14400, Loss_data: 0.0096, Loss_ode: 0.2114\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14410, Loss_data: 0.0093, Loss_ode: 0.2124\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14420, Loss_data: 0.0094, Loss_ode: 0.2087\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14430, Loss_data: 0.0094, Loss_ode: 0.2049\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14440, Loss_data: 0.0093, Loss_ode: 0.2012\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14450, Loss_data: 0.0094, Loss_ode: 0.2051\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14460, Loss_data: 0.0094, Loss_ode: 0.2037\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14470, Loss_data: 0.0093, Loss_ode: 0.2046\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14480, Loss_data: 0.0094, Loss_ode: 0.2095\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14490, Loss_data: 0.0091, Loss_ode: 0.2048\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14500, Loss_data: 0.0094, Loss_ode: 0.2069\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14510, Loss_data: 0.0096, Loss_ode: 0.2101\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14520, Loss_data: 0.0093, Loss_ode: 0.2030\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14530, Loss_data: 0.0094, Loss_ode: 0.2028\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14540, Loss_data: 0.0094, Loss_ode: 0.2044\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14550, Loss_data: 0.0095, Loss_ode: 0.2140\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14560, Loss_data: 0.0092, Loss_ode: 0.2038\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14570, Loss_data: 0.0094, Loss_ode: 0.2100\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14580, Loss_data: 0.0094, Loss_ode: 0.2005\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14590, Loss_data: 0.0094, Loss_ode: 0.2025\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14600, Loss_data: 0.0092, Loss_ode: 0.1974\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14610, Loss_data: 0.0092, Loss_ode: 0.2053\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14620, Loss_data: 0.0093, Loss_ode: 0.2101\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14630, Loss_data: 0.0093, Loss_ode: 0.2138\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14640, Loss_data: 0.0091, Loss_ode: 0.2119\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14650, Loss_data: 0.0091, Loss_ode: 0.2014\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14660, Loss_data: 0.0094, Loss_ode: 0.2047\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14670, Loss_data: 0.0092, Loss_ode: 0.1991\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14680, Loss_data: 0.0092, Loss_ode: 0.2035\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14690, Loss_data: 0.0093, Loss_ode: 0.2059\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14700, Loss_data: 0.0092, Loss_ode: 0.2064\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14710, Loss_data: 0.0093, Loss_ode: 0.1999\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14720, Loss_data: 0.0093, Loss_ode: 0.2177\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14730, Loss_data: 0.0091, Loss_ode: 0.2027\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14740, Loss_data: 0.0093, Loss_ode: 0.2106\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14750, Loss_data: 0.0091, Loss_ode: 0.2028\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14760, Loss_data: 0.0091, Loss_ode: 0.2031\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14770, Loss_data: 0.0092, Loss_ode: 0.2031\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14780, Loss_data: 0.0092, Loss_ode: 0.2021\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14790, Loss_data: 0.0092, Loss_ode: 0.2041\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14800, Loss_data: 0.0091, Loss_ode: 0.2097\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14810, Loss_data: 0.0092, Loss_ode: 0.2078\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14820, Loss_data: 0.0091, Loss_ode: 0.2042\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14830, Loss_data: 0.0091, Loss_ode: 0.2036\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14840, Loss_data: 0.0092, Loss_ode: 0.2019\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14850, Loss_data: 0.0091, Loss_ode: 0.2015\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14860, Loss_data: 0.0093, Loss_ode: 0.2074\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14870, Loss_data: 0.0091, Loss_ode: 0.2025\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14880, Loss_data: 0.0090, Loss_ode: 0.2118\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14890, Loss_data: 0.0090, Loss_ode: 0.2036\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14900, Loss_data: 0.0089, Loss_ode: 0.2026\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14910, Loss_data: 0.0092, Loss_ode: 0.2028\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14920, Loss_data: 0.0090, Loss_ode: 0.2047\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14930, Loss_data: 0.0090, Loss_ode: 0.2031\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14940, Loss_data: 0.0091, Loss_ode: 0.2007\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14950, Loss_data: 0.0091, Loss_ode: 0.2048\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14960, Loss_data: 0.0091, Loss_ode: 0.2066\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14970, Loss_data: 0.0090, Loss_ode: 0.2023\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14980, Loss_data: 0.0090, Loss_ode: 0.2002\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14990, Loss_data: 0.0091, Loss_ode: 0.1998\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 15000, Loss_data: 0.0091, Loss_ode: 0.2033\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15010, Loss_data: 0.0090, Loss_ode: 0.2000\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15020, Loss_data: 0.0090, Loss_ode: 0.2007\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15030, Loss_data: 0.0089, Loss_ode: 0.2011\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15040, Loss_data: 0.0090, Loss_ode: 0.1990\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15050, Loss_data: 0.0090, Loss_ode: 0.2017\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15060, Loss_data: 0.0091, Loss_ode: 0.2056\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15070, Loss_data: 0.0090, Loss_ode: 0.2062\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15080, Loss_data: 0.0091, Loss_ode: 0.2026\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15090, Loss_data: 0.0089, Loss_ode: 0.2013\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15100, Loss_data: 0.0091, Loss_ode: 0.2026\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15110, Loss_data: 0.0091, Loss_ode: 0.2006\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15120, Loss_data: 0.0090, Loss_ode: 0.1994\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15130, Loss_data: 0.0090, Loss_ode: 0.1988\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15140, Loss_data: 0.0090, Loss_ode: 0.2058\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15150, Loss_data: 0.0090, Loss_ode: 0.2023\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15160, Loss_data: 0.0089, Loss_ode: 0.2009\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15170, Loss_data: 0.0090, Loss_ode: 0.2001\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15180, Loss_data: 0.0088, Loss_ode: 0.2018\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15190, Loss_data: 0.0090, Loss_ode: 0.1983\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15200, Loss_data: 0.0090, Loss_ode: 0.1987\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15210, Loss_data: 0.0088, Loss_ode: 0.2013\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15220, Loss_data: 0.0090, Loss_ode: 0.1966\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15230, Loss_data: 0.0089, Loss_ode: 0.2004\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15240, Loss_data: 0.0089, Loss_ode: 0.2007\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15250, Loss_data: 0.0089, Loss_ode: 0.2040\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15260, Loss_data: 0.0090, Loss_ode: 0.1996\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15270, Loss_data: 0.0088, Loss_ode: 0.1966\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15280, Loss_data: 0.0090, Loss_ode: 0.2008\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15290, Loss_data: 0.0088, Loss_ode: 0.2036\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15300, Loss_data: 0.0089, Loss_ode: 0.2008\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15310, Loss_data: 0.0090, Loss_ode: 0.1971\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15320, Loss_data: 0.0089, Loss_ode: 0.1996\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15330, Loss_data: 0.0089, Loss_ode: 0.1974\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15340, Loss_data: 0.0089, Loss_ode: 0.1994\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15350, Loss_data: 0.0089, Loss_ode: 0.1993\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15360, Loss_data: 0.0088, Loss_ode: 0.1992\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15370, Loss_data: 0.0089, Loss_ode: 0.1976\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15380, Loss_data: 0.0089, Loss_ode: 0.1987\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15390, Loss_data: 0.0089, Loss_ode: 0.2036\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15400, Loss_data: 0.0089, Loss_ode: 0.2023\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15410, Loss_data: 0.0088, Loss_ode: 0.1987\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15420, Loss_data: 0.0088, Loss_ode: 0.1964\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15430, Loss_data: 0.0088, Loss_ode: 0.1996\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15440, Loss_data: 0.0089, Loss_ode: 0.2001\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15450, Loss_data: 0.0088, Loss_ode: 0.1975\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15460, Loss_data: 0.0088, Loss_ode: 0.1984\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15470, Loss_data: 0.0088, Loss_ode: 0.2040\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15480, Loss_data: 0.0089, Loss_ode: 0.1958\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15490, Loss_data: 0.0089, Loss_ode: 0.1970\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15500, Loss_data: 0.0088, Loss_ode: 0.1992\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15510, Loss_data: 0.0089, Loss_ode: 0.2007\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15520, Loss_data: 0.0088, Loss_ode: 0.1972\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15530, Loss_data: 0.0088, Loss_ode: 0.2005\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15540, Loss_data: 0.0089, Loss_ode: 0.1958\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15550, Loss_data: 0.0089, Loss_ode: 0.1976\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15560, Loss_data: 0.0089, Loss_ode: 0.1980\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15570, Loss_data: 0.0087, Loss_ode: 0.1995\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15580, Loss_data: 0.0088, Loss_ode: 0.1956\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15590, Loss_data: 0.0089, Loss_ode: 0.1966\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15600, Loss_data: 0.0088, Loss_ode: 0.1975\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15610, Loss_data: 0.0088, Loss_ode: 0.1999\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15620, Loss_data: 0.0088, Loss_ode: 0.1991\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15630, Loss_data: 0.0088, Loss_ode: 0.1994\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15640, Loss_data: 0.0089, Loss_ode: 0.1991\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15650, Loss_data: 0.0088, Loss_ode: 0.1960\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15660, Loss_data: 0.0087, Loss_ode: 0.2004\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15670, Loss_data: 0.0088, Loss_ode: 0.1992\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15680, Loss_data: 0.0088, Loss_ode: 0.1968\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15690, Loss_data: 0.0086, Loss_ode: 0.2030\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15700, Loss_data: 0.0087, Loss_ode: 0.2025\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15710, Loss_data: 0.0089, Loss_ode: 0.1953\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15720, Loss_data: 0.0087, Loss_ode: 0.1991\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15730, Loss_data: 0.0087, Loss_ode: 0.2048\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15740, Loss_data: 0.0087, Loss_ode: 0.1960\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15750, Loss_data: 0.0087, Loss_ode: 0.1990\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15760, Loss_data: 0.0088, Loss_ode: 0.2003\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15770, Loss_data: 0.0086, Loss_ode: 0.2007\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15780, Loss_data: 0.0087, Loss_ode: 0.1990\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15790, Loss_data: 0.0087, Loss_ode: 0.1985\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15800, Loss_data: 0.0086, Loss_ode: 0.1994\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15810, Loss_data: 0.0088, Loss_ode: 0.2000\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15820, Loss_data: 0.0087, Loss_ode: 0.1961\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15830, Loss_data: 0.0086, Loss_ode: 0.2004\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15840, Loss_data: 0.0086, Loss_ode: 0.1942\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15850, Loss_data: 0.0088, Loss_ode: 0.1950\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15860, Loss_data: 0.0087, Loss_ode: 0.2017\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15870, Loss_data: 0.0088, Loss_ode: 0.1965\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15880, Loss_data: 0.0086, Loss_ode: 0.1987\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15890, Loss_data: 0.0088, Loss_ode: 0.1985\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15900, Loss_data: 0.0086, Loss_ode: 0.1970\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15910, Loss_data: 0.0087, Loss_ode: 0.2001\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15920, Loss_data: 0.0086, Loss_ode: 0.1993\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15930, Loss_data: 0.0087, Loss_ode: 0.2003\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15940, Loss_data: 0.0087, Loss_ode: 0.1954\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15950, Loss_data: 0.0088, Loss_ode: 0.1991\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15960, Loss_data: 0.0086, Loss_ode: 0.1983\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15970, Loss_data: 0.0087, Loss_ode: 0.1960\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15980, Loss_data: 0.0086, Loss_ode: 0.1951\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15990, Loss_data: 0.0086, Loss_ode: 0.1967\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16000, Loss_data: 0.0087, Loss_ode: 0.1972\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16010, Loss_data: 0.0086, Loss_ode: 0.1977\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16020, Loss_data: 0.0086, Loss_ode: 0.1944\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16030, Loss_data: 0.0088, Loss_ode: 0.1976\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16040, Loss_data: 0.0087, Loss_ode: 0.1959\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16050, Loss_data: 0.0087, Loss_ode: 0.1939\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16060, Loss_data: 0.0086, Loss_ode: 0.1981\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16070, Loss_data: 0.0086, Loss_ode: 0.1962\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16080, Loss_data: 0.0086, Loss_ode: 0.1964\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16090, Loss_data: 0.0086, Loss_ode: 0.1975\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16100, Loss_data: 0.0087, Loss_ode: 0.1909\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16110, Loss_data: 0.0086, Loss_ode: 0.1984\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16120, Loss_data: 0.0087, Loss_ode: 0.2047\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16130, Loss_data: 0.0085, Loss_ode: 0.1922\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16140, Loss_data: 0.0086, Loss_ode: 0.1925\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16150, Loss_data: 0.0086, Loss_ode: 0.1960\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16160, Loss_data: 0.0085, Loss_ode: 0.1975\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16170, Loss_data: 0.0086, Loss_ode: 0.1954\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16180, Loss_data: 0.0086, Loss_ode: 0.1946\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16190, Loss_data: 0.0086, Loss_ode: 0.1995\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16200, Loss_data: 0.0086, Loss_ode: 0.2015\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16210, Loss_data: 0.0085, Loss_ode: 0.1988\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16220, Loss_data: 0.0084, Loss_ode: 0.1957\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16230, Loss_data: 0.0085, Loss_ode: 0.1967\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16240, Loss_data: 0.0086, Loss_ode: 0.1989\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16250, Loss_data: 0.0085, Loss_ode: 0.1952\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16260, Loss_data: 0.0085, Loss_ode: 0.1951\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16270, Loss_data: 0.0086, Loss_ode: 0.1936\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16280, Loss_data: 0.0084, Loss_ode: 0.1951\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16290, Loss_data: 0.0087, Loss_ode: 0.1959\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16300, Loss_data: 0.0083, Loss_ode: 0.1968\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16310, Loss_data: 0.0085, Loss_ode: 0.1953\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16320, Loss_data: 0.0085, Loss_ode: 0.1969\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16330, Loss_data: 0.0085, Loss_ode: 0.1940\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16340, Loss_data: 0.0085, Loss_ode: 0.1928\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16350, Loss_data: 0.0085, Loss_ode: 0.1957\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16360, Loss_data: 0.0085, Loss_ode: 0.1949\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16370, Loss_data: 0.0084, Loss_ode: 0.1962\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16380, Loss_data: 0.0085, Loss_ode: 0.1988\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16390, Loss_data: 0.0084, Loss_ode: 0.1937\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16400, Loss_data: 0.0085, Loss_ode: 0.1966\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16410, Loss_data: 0.0085, Loss_ode: 0.1941\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16420, Loss_data: 0.0084, Loss_ode: 0.1980\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16430, Loss_data: 0.0086, Loss_ode: 0.1956\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16440, Loss_data: 0.0084, Loss_ode: 0.1926\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16450, Loss_data: 0.0085, Loss_ode: 0.1958\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16460, Loss_data: 0.0084, Loss_ode: 0.2006\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16470, Loss_data: 0.0084, Loss_ode: 0.1955\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16480, Loss_data: 0.0086, Loss_ode: 0.1978\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16490, Loss_data: 0.0084, Loss_ode: 0.1974\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16500, Loss_data: 0.0084, Loss_ode: 0.1964\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16510, Loss_data: 0.0084, Loss_ode: 0.1957\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16520, Loss_data: 0.0084, Loss_ode: 0.1957\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16530, Loss_data: 0.0084, Loss_ode: 0.1912\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16540, Loss_data: 0.0084, Loss_ode: 0.1898\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16550, Loss_data: 0.0084, Loss_ode: 0.1944\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16560, Loss_data: 0.0084, Loss_ode: 0.1927\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16570, Loss_data: 0.0085, Loss_ode: 0.1986\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16580, Loss_data: 0.0082, Loss_ode: 0.1983\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16590, Loss_data: 0.0085, Loss_ode: 0.1949\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16600, Loss_data: 0.0085, Loss_ode: 0.1907\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16610, Loss_data: 0.0084, Loss_ode: 0.1965\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16620, Loss_data: 0.0084, Loss_ode: 0.1896\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16630, Loss_data: 0.0083, Loss_ode: 0.1950\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16640, Loss_data: 0.0084, Loss_ode: 0.1901\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16650, Loss_data: 0.0085, Loss_ode: 0.1954\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16660, Loss_data: 0.0084, Loss_ode: 0.1927\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16670, Loss_data: 0.0084, Loss_ode: 0.1887\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16680, Loss_data: 0.0083, Loss_ode: 0.1960\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16690, Loss_data: 0.0085, Loss_ode: 0.1943\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16700, Loss_data: 0.0083, Loss_ode: 0.1915\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16710, Loss_data: 0.0084, Loss_ode: 0.1902\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16720, Loss_data: 0.0085, Loss_ode: 0.1940\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16730, Loss_data: 0.0083, Loss_ode: 0.1921\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16740, Loss_data: 0.0084, Loss_ode: 0.1942\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16750, Loss_data: 0.0082, Loss_ode: 0.1940\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16760, Loss_data: 0.0085, Loss_ode: 0.1946\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16770, Loss_data: 0.0083, Loss_ode: 0.1934\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16780, Loss_data: 0.0083, Loss_ode: 0.1954\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16790, Loss_data: 0.0083, Loss_ode: 0.1908\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16800, Loss_data: 0.0083, Loss_ode: 0.1924\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16810, Loss_data: 0.0085, Loss_ode: 0.1888\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16820, Loss_data: 0.0083, Loss_ode: 0.1921\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16830, Loss_data: 0.0084, Loss_ode: 0.1883\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16840, Loss_data: 0.0084, Loss_ode: 0.1934\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16850, Loss_data: 0.0083, Loss_ode: 0.1899\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16860, Loss_data: 0.0082, Loss_ode: 0.1875\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16870, Loss_data: 0.0083, Loss_ode: 0.1942\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16880, Loss_data: 0.0082, Loss_ode: 0.1973\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16890, Loss_data: 0.0082, Loss_ode: 0.1892\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16900, Loss_data: 0.0084, Loss_ode: 0.1923\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16910, Loss_data: 0.0083, Loss_ode: 0.1914\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16920, Loss_data: 0.0083, Loss_ode: 0.1912\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16930, Loss_data: 0.0083, Loss_ode: 0.1904\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16940, Loss_data: 0.0086, Loss_ode: 0.1949\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16950, Loss_data: 0.0083, Loss_ode: 0.1893\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16960, Loss_data: 0.0084, Loss_ode: 0.1926\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16970, Loss_data: 0.0083, Loss_ode: 0.1954\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16980, Loss_data: 0.0083, Loss_ode: 0.1913\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16990, Loss_data: 0.0084, Loss_ode: 0.1930\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17000, Loss_data: 0.0082, Loss_ode: 0.1910\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17010, Loss_data: 0.0082, Loss_ode: 0.1965\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17020, Loss_data: 0.0082, Loss_ode: 0.1984\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17030, Loss_data: 0.0082, Loss_ode: 0.1902\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17040, Loss_data: 0.0084, Loss_ode: 0.1923\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17050, Loss_data: 0.0083, Loss_ode: 0.1874\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17060, Loss_data: 0.0083, Loss_ode: 0.1904\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17070, Loss_data: 0.0083, Loss_ode: 0.1913\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17080, Loss_data: 0.0083, Loss_ode: 0.1911\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17090, Loss_data: 0.0083, Loss_ode: 0.1896\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17100, Loss_data: 0.0083, Loss_ode: 0.1954\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17110, Loss_data: 0.0085, Loss_ode: 0.1983\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17120, Loss_data: 0.0082, Loss_ode: 0.1926\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17130, Loss_data: 0.0082, Loss_ode: 0.1933\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17140, Loss_data: 0.0083, Loss_ode: 0.1907\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17150, Loss_data: 0.0082, Loss_ode: 0.1900\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17160, Loss_data: 0.0083, Loss_ode: 0.1906\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17170, Loss_data: 0.0083, Loss_ode: 0.1965\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17180, Loss_data: 0.0082, Loss_ode: 0.1887\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17190, Loss_data: 0.0083, Loss_ode: 0.1883\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17200, Loss_data: 0.0081, Loss_ode: 0.1888\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17210, Loss_data: 0.0082, Loss_ode: 0.1875\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17220, Loss_data: 0.0084, Loss_ode: 0.1895\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17230, Loss_data: 0.0081, Loss_ode: 0.1937\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17240, Loss_data: 0.0083, Loss_ode: 0.1896\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17250, Loss_data: 0.0083, Loss_ode: 0.1882\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17260, Loss_data: 0.0082, Loss_ode: 0.1909\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17270, Loss_data: 0.0083, Loss_ode: 0.1883\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17280, Loss_data: 0.0082, Loss_ode: 0.1874\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17290, Loss_data: 0.0082, Loss_ode: 0.1870\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17300, Loss_data: 0.0082, Loss_ode: 0.1874\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17310, Loss_data: 0.0083, Loss_ode: 0.1913\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17320, Loss_data: 0.0080, Loss_ode: 0.1914\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17330, Loss_data: 0.0084, Loss_ode: 0.1899\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17340, Loss_data: 0.0081, Loss_ode: 0.1881\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17350, Loss_data: 0.0082, Loss_ode: 0.1903\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17360, Loss_data: 0.0081, Loss_ode: 0.1897\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17370, Loss_data: 0.0084, Loss_ode: 0.1895\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17380, Loss_data: 0.0082, Loss_ode: 0.1896\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17390, Loss_data: 0.0082, Loss_ode: 0.1879\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17400, Loss_data: 0.0081, Loss_ode: 0.1865\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17410, Loss_data: 0.0082, Loss_ode: 0.1874\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17420, Loss_data: 0.0082, Loss_ode: 0.1834\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17430, Loss_data: 0.0081, Loss_ode: 0.1900\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17440, Loss_data: 0.0082, Loss_ode: 0.1916\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17450, Loss_data: 0.0081, Loss_ode: 0.1952\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17460, Loss_data: 0.0083, Loss_ode: 0.1900\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17470, Loss_data: 0.0081, Loss_ode: 0.1899\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17480, Loss_data: 0.0083, Loss_ode: 0.1926\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17490, Loss_data: 0.0082, Loss_ode: 0.1861\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17500, Loss_data: 0.0081, Loss_ode: 0.1877\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17510, Loss_data: 0.0081, Loss_ode: 0.1861\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17520, Loss_data: 0.0081, Loss_ode: 0.1872\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17530, Loss_data: 0.0082, Loss_ode: 0.1903\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17540, Loss_data: 0.0083, Loss_ode: 0.1839\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17550, Loss_data: 0.0082, Loss_ode: 0.1853\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17560, Loss_data: 0.0083, Loss_ode: 0.1876\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17570, Loss_data: 0.0081, Loss_ode: 0.1842\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17580, Loss_data: 0.0081, Loss_ode: 0.1868\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17590, Loss_data: 0.0082, Loss_ode: 0.1864\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17600, Loss_data: 0.0081, Loss_ode: 0.1882\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17610, Loss_data: 0.0082, Loss_ode: 0.1827\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17620, Loss_data: 0.0081, Loss_ode: 0.1876\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17630, Loss_data: 0.0081, Loss_ode: 0.1837\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17640, Loss_data: 0.0081, Loss_ode: 0.1886\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17650, Loss_data: 0.0082, Loss_ode: 0.1879\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17660, Loss_data: 0.0082, Loss_ode: 0.1833\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17670, Loss_data: 0.0082, Loss_ode: 0.1853\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17680, Loss_data: 0.0081, Loss_ode: 0.1854\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17690, Loss_data: 0.0081, Loss_ode: 0.1841\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17700, Loss_data: 0.0081, Loss_ode: 0.1891\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17710, Loss_data: 0.0081, Loss_ode: 0.1868\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17720, Loss_data: 0.0082, Loss_ode: 0.1844\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17730, Loss_data: 0.0082, Loss_ode: 0.1840\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17740, Loss_data: 0.0081, Loss_ode: 0.1859\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17750, Loss_data: 0.0081, Loss_ode: 0.1857\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17760, Loss_data: 0.0081, Loss_ode: 0.1830\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17770, Loss_data: 0.0082, Loss_ode: 0.1837\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17780, Loss_data: 0.0081, Loss_ode: 0.1852\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17790, Loss_data: 0.0081, Loss_ode: 0.1855\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17800, Loss_data: 0.0081, Loss_ode: 0.1813\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17810, Loss_data: 0.0081, Loss_ode: 0.1859\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17820, Loss_data: 0.0082, Loss_ode: 0.1852\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17830, Loss_data: 0.0082, Loss_ode: 0.1855\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17840, Loss_data: 0.0082, Loss_ode: 0.1815\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17850, Loss_data: 0.0081, Loss_ode: 0.1848\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17860, Loss_data: 0.0082, Loss_ode: 0.1848\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17870, Loss_data: 0.0080, Loss_ode: 0.1892\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17880, Loss_data: 0.0082, Loss_ode: 0.1846\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17890, Loss_data: 0.0082, Loss_ode: 0.1876\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17900, Loss_data: 0.0081, Loss_ode: 0.1857\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17910, Loss_data: 0.0081, Loss_ode: 0.1819\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17920, Loss_data: 0.0081, Loss_ode: 0.1881\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17930, Loss_data: 0.0080, Loss_ode: 0.1851\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17940, Loss_data: 0.0082, Loss_ode: 0.1819\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17950, Loss_data: 0.0081, Loss_ode: 0.1844\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17960, Loss_data: 0.0081, Loss_ode: 0.1855\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17970, Loss_data: 0.0081, Loss_ode: 0.1845\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17980, Loss_data: 0.0081, Loss_ode: 0.1845\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17990, Loss_data: 0.0080, Loss_ode: 0.1870\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18000, Loss_data: 0.0081, Loss_ode: 0.1849\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18010, Loss_data: 0.0081, Loss_ode: 0.1844\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18020, Loss_data: 0.0081, Loss_ode: 0.1904\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18030, Loss_data: 0.0081, Loss_ode: 0.1860\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18040, Loss_data: 0.0081, Loss_ode: 0.1811\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18050, Loss_data: 0.0081, Loss_ode: 0.1842\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18060, Loss_data: 0.0081, Loss_ode: 0.1802\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18070, Loss_data: 0.0080, Loss_ode: 0.1834\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18080, Loss_data: 0.0082, Loss_ode: 0.1846\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18090, Loss_data: 0.0081, Loss_ode: 0.1853\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18100, Loss_data: 0.0080, Loss_ode: 0.1843\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18110, Loss_data: 0.0081, Loss_ode: 0.1821\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18120, Loss_data: 0.0080, Loss_ode: 0.1811\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18130, Loss_data: 0.0080, Loss_ode: 0.1876\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18140, Loss_data: 0.0081, Loss_ode: 0.1816\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18150, Loss_data: 0.0080, Loss_ode: 0.1840\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18160, Loss_data: 0.0081, Loss_ode: 0.1830\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18170, Loss_data: 0.0080, Loss_ode: 0.1824\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18180, Loss_data: 0.0080, Loss_ode: 0.1835\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18190, Loss_data: 0.0081, Loss_ode: 0.1833\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18200, Loss_data: 0.0080, Loss_ode: 0.1786\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18210, Loss_data: 0.0081, Loss_ode: 0.1833\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18220, Loss_data: 0.0081, Loss_ode: 0.1814\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18230, Loss_data: 0.0081, Loss_ode: 0.1871\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18240, Loss_data: 0.0081, Loss_ode: 0.1773\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18250, Loss_data: 0.0082, Loss_ode: 0.1822\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18260, Loss_data: 0.0081, Loss_ode: 0.1872\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18270, Loss_data: 0.0080, Loss_ode: 0.1796\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18280, Loss_data: 0.0081, Loss_ode: 0.1842\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18290, Loss_data: 0.0080, Loss_ode: 0.1858\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18300, Loss_data: 0.0080, Loss_ode: 0.1802\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18310, Loss_data: 0.0081, Loss_ode: 0.1852\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18320, Loss_data: 0.0080, Loss_ode: 0.1831\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18330, Loss_data: 0.0080, Loss_ode: 0.1825\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18340, Loss_data: 0.0081, Loss_ode: 0.1807\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18350, Loss_data: 0.0080, Loss_ode: 0.1825\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18360, Loss_data: 0.0080, Loss_ode: 0.1846\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18370, Loss_data: 0.0080, Loss_ode: 0.1839\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18380, Loss_data: 0.0081, Loss_ode: 0.1822\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18390, Loss_data: 0.0079, Loss_ode: 0.1815\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18400, Loss_data: 0.0080, Loss_ode: 0.1833\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18410, Loss_data: 0.0081, Loss_ode: 0.1795\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18420, Loss_data: 0.0081, Loss_ode: 0.1777\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18430, Loss_data: 0.0081, Loss_ode: 0.1817\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18440, Loss_data: 0.0080, Loss_ode: 0.1818\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18450, Loss_data: 0.0080, Loss_ode: 0.1790\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18460, Loss_data: 0.0081, Loss_ode: 0.1800\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18470, Loss_data: 0.0080, Loss_ode: 0.1836\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18480, Loss_data: 0.0081, Loss_ode: 0.1818\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18490, Loss_data: 0.0080, Loss_ode: 0.1836\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18500, Loss_data: 0.0080, Loss_ode: 0.1834\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18510, Loss_data: 0.0080, Loss_ode: 0.1813\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18520, Loss_data: 0.0081, Loss_ode: 0.1818\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18530, Loss_data: 0.0079, Loss_ode: 0.1832\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18540, Loss_data: 0.0081, Loss_ode: 0.1845\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18550, Loss_data: 0.0080, Loss_ode: 0.1802\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18560, Loss_data: 0.0080, Loss_ode: 0.1792\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18570, Loss_data: 0.0079, Loss_ode: 0.1816\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18580, Loss_data: 0.0080, Loss_ode: 0.1785\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18590, Loss_data: 0.0081, Loss_ode: 0.1803\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18600, Loss_data: 0.0081, Loss_ode: 0.1810\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18610, Loss_data: 0.0080, Loss_ode: 0.1790\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18620, Loss_data: 0.0080, Loss_ode: 0.1826\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18630, Loss_data: 0.0080, Loss_ode: 0.1799\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18640, Loss_data: 0.0080, Loss_ode: 0.1763\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18650, Loss_data: 0.0079, Loss_ode: 0.1818\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18660, Loss_data: 0.0079, Loss_ode: 0.1839\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18670, Loss_data: 0.0079, Loss_ode: 0.1816\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18680, Loss_data: 0.0080, Loss_ode: 0.1800\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18690, Loss_data: 0.0080, Loss_ode: 0.1796\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18700, Loss_data: 0.0079, Loss_ode: 0.1801\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18710, Loss_data: 0.0080, Loss_ode: 0.1823\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18720, Loss_data: 0.0079, Loss_ode: 0.1780\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18730, Loss_data: 0.0079, Loss_ode: 0.1779\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18740, Loss_data: 0.0081, Loss_ode: 0.1768\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18750, Loss_data: 0.0080, Loss_ode: 0.1803\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18760, Loss_data: 0.0080, Loss_ode: 0.1794\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18770, Loss_data: 0.0080, Loss_ode: 0.1780\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18780, Loss_data: 0.0080, Loss_ode: 0.1832\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18790, Loss_data: 0.0079, Loss_ode: 0.1791\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18800, Loss_data: 0.0080, Loss_ode: 0.1786\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18810, Loss_data: 0.0079, Loss_ode: 0.1798\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18820, Loss_data: 0.0081, Loss_ode: 0.1790\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18830, Loss_data: 0.0080, Loss_ode: 0.1834\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18840, Loss_data: 0.0080, Loss_ode: 0.1778\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18850, Loss_data: 0.0080, Loss_ode: 0.1778\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18860, Loss_data: 0.0080, Loss_ode: 0.1804\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18870, Loss_data: 0.0079, Loss_ode: 0.1792\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18880, Loss_data: 0.0082, Loss_ode: 0.1801\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18890, Loss_data: 0.0078, Loss_ode: 0.1783\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18900, Loss_data: 0.0079, Loss_ode: 0.1777\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18910, Loss_data: 0.0079, Loss_ode: 0.1773\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18920, Loss_data: 0.0079, Loss_ode: 0.1773\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18930, Loss_data: 0.0080, Loss_ode: 0.1774\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18940, Loss_data: 0.0079, Loss_ode: 0.1770\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18950, Loss_data: 0.0079, Loss_ode: 0.1807\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18960, Loss_data: 0.0080, Loss_ode: 0.1782\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18970, Loss_data: 0.0080, Loss_ode: 0.1816\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18980, Loss_data: 0.0080, Loss_ode: 0.1797\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18990, Loss_data: 0.0080, Loss_ode: 0.1768\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19000, Loss_data: 0.0080, Loss_ode: 0.1794\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19010, Loss_data: 0.0079, Loss_ode: 0.1778\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19020, Loss_data: 0.0080, Loss_ode: 0.1782\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19030, Loss_data: 0.0079, Loss_ode: 0.1802\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19040, Loss_data: 0.0079, Loss_ode: 0.1756\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19050, Loss_data: 0.0079, Loss_ode: 0.1786\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19060, Loss_data: 0.0079, Loss_ode: 0.1774\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19070, Loss_data: 0.0082, Loss_ode: 0.1795\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19080, Loss_data: 0.0079, Loss_ode: 0.1756\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19090, Loss_data: 0.0079, Loss_ode: 0.1763\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19100, Loss_data: 0.0079, Loss_ode: 0.1753\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19110, Loss_data: 0.0079, Loss_ode: 0.1754\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19120, Loss_data: 0.0079, Loss_ode: 0.1812\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19130, Loss_data: 0.0079, Loss_ode: 0.1745\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19140, Loss_data: 0.0079, Loss_ode: 0.1760\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19150, Loss_data: 0.0080, Loss_ode: 0.1770\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19160, Loss_data: 0.0080, Loss_ode: 0.1758\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19170, Loss_data: 0.0078, Loss_ode: 0.1753\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19180, Loss_data: 0.0079, Loss_ode: 0.1761\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19190, Loss_data: 0.0080, Loss_ode: 0.1797\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19200, Loss_data: 0.0080, Loss_ode: 0.1759\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19210, Loss_data: 0.0080, Loss_ode: 0.1779\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19220, Loss_data: 0.0078, Loss_ode: 0.1780\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19230, Loss_data: 0.0078, Loss_ode: 0.1736\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19240, Loss_data: 0.0080, Loss_ode: 0.1745\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19250, Loss_data: 0.0079, Loss_ode: 0.1811\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19260, Loss_data: 0.0079, Loss_ode: 0.1786\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19270, Loss_data: 0.0079, Loss_ode: 0.1750\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19280, Loss_data: 0.0079, Loss_ode: 0.1728\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19290, Loss_data: 0.0080, Loss_ode: 0.1752\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19300, Loss_data: 0.0079, Loss_ode: 0.1751\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19310, Loss_data: 0.0078, Loss_ode: 0.1787\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19320, Loss_data: 0.0079, Loss_ode: 0.1747\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19330, Loss_data: 0.0079, Loss_ode: 0.1750\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19340, Loss_data: 0.0078, Loss_ode: 0.1781\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19350, Loss_data: 0.0079, Loss_ode: 0.1742\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19360, Loss_data: 0.0079, Loss_ode: 0.1756\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19370, Loss_data: 0.0078, Loss_ode: 0.1800\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19380, Loss_data: 0.0080, Loss_ode: 0.1717\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19390, Loss_data: 0.0079, Loss_ode: 0.1738\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19400, Loss_data: 0.0077, Loss_ode: 0.1783\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19410, Loss_data: 0.0080, Loss_ode: 0.1738\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19420, Loss_data: 0.0079, Loss_ode: 0.1774\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19430, Loss_data: 0.0078, Loss_ode: 0.1793\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19440, Loss_data: 0.0081, Loss_ode: 0.1733\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19450, Loss_data: 0.0079, Loss_ode: 0.1748\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19460, Loss_data: 0.0079, Loss_ode: 0.1752\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19470, Loss_data: 0.0080, Loss_ode: 0.1755\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19480, Loss_data: 0.0077, Loss_ode: 0.1769\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19490, Loss_data: 0.0080, Loss_ode: 0.1727\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19500, Loss_data: 0.0078, Loss_ode: 0.1740\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19510, Loss_data: 0.0079, Loss_ode: 0.1737\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19520, Loss_data: 0.0079, Loss_ode: 0.1730\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19530, Loss_data: 0.0079, Loss_ode: 0.1773\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19540, Loss_data: 0.0079, Loss_ode: 0.1739\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19550, Loss_data: 0.0079, Loss_ode: 0.1726\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19560, Loss_data: 0.0080, Loss_ode: 0.1708\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19570, Loss_data: 0.0078, Loss_ode: 0.1704\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19580, Loss_data: 0.0078, Loss_ode: 0.1741\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19590, Loss_data: 0.0079, Loss_ode: 0.1748\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19600, Loss_data: 0.0078, Loss_ode: 0.1725\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19610, Loss_data: 0.0079, Loss_ode: 0.1796\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19620, Loss_data: 0.0080, Loss_ode: 0.1737\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19630, Loss_data: 0.0079, Loss_ode: 0.1708\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19640, Loss_data: 0.0078, Loss_ode: 0.1703\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19650, Loss_data: 0.0079, Loss_ode: 0.1719\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19660, Loss_data: 0.0079, Loss_ode: 0.1735\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19670, Loss_data: 0.0078, Loss_ode: 0.1759\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19680, Loss_data: 0.0079, Loss_ode: 0.1694\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19690, Loss_data: 0.0080, Loss_ode: 0.1690\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19700, Loss_data: 0.0079, Loss_ode: 0.1731\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19710, Loss_data: 0.0079, Loss_ode: 0.1745\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19720, Loss_data: 0.0078, Loss_ode: 0.1713\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19730, Loss_data: 0.0078, Loss_ode: 0.1699\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19740, Loss_data: 0.0079, Loss_ode: 0.1706\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19750, Loss_data: 0.0078, Loss_ode: 0.1736\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19760, Loss_data: 0.0079, Loss_ode: 0.1742\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19770, Loss_data: 0.0078, Loss_ode: 0.1725\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19780, Loss_data: 0.0079, Loss_ode: 0.1701\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19790, Loss_data: 0.0078, Loss_ode: 0.1709\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19800, Loss_data: 0.0078, Loss_ode: 0.1714\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19810, Loss_data: 0.0079, Loss_ode: 0.1704\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19820, Loss_data: 0.0079, Loss_ode: 0.1713\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19830, Loss_data: 0.0078, Loss_ode: 0.1720\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19840, Loss_data: 0.0078, Loss_ode: 0.1700\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19850, Loss_data: 0.0080, Loss_ode: 0.1686\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19860, Loss_data: 0.0079, Loss_ode: 0.1725\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19870, Loss_data: 0.0079, Loss_ode: 0.1703\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19880, Loss_data: 0.0079, Loss_ode: 0.1701\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19890, Loss_data: 0.0079, Loss_ode: 0.1725\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19900, Loss_data: 0.0078, Loss_ode: 0.1735\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19910, Loss_data: 0.0079, Loss_ode: 0.1708\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19920, Loss_data: 0.0078, Loss_ode: 0.1717\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19930, Loss_data: 0.0078, Loss_ode: 0.1743\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19940, Loss_data: 0.0078, Loss_ode: 0.1720\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19950, Loss_data: 0.0078, Loss_ode: 0.1692\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19960, Loss_data: 0.0078, Loss_ode: 0.1682\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19970, Loss_data: 0.0078, Loss_ode: 0.1712\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19980, Loss_data: 0.0078, Loss_ode: 0.1711\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19990, Loss_data: 0.0078, Loss_ode: 0.1691\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 20000, Loss_data: 0.0078, Loss_ode: 0.1689\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20010, Loss_data: 0.0079, Loss_ode: 0.1708\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20020, Loss_data: 0.0079, Loss_ode: 0.1690\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20030, Loss_data: 0.0079, Loss_ode: 0.1685\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20040, Loss_data: 0.0079, Loss_ode: 0.1700\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20050, Loss_data: 0.0078, Loss_ode: 0.1691\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20060, Loss_data: 0.0079, Loss_ode: 0.1692\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20070, Loss_data: 0.0078, Loss_ode: 0.1686\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20080, Loss_data: 0.0078, Loss_ode: 0.1663\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20090, Loss_data: 0.0078, Loss_ode: 0.1648\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20100, Loss_data: 0.0078, Loss_ode: 0.1660\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20110, Loss_data: 0.0079, Loss_ode: 0.1709\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20120, Loss_data: 0.0078, Loss_ode: 0.1698\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20130, Loss_data: 0.0078, Loss_ode: 0.1670\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20140, Loss_data: 0.0079, Loss_ode: 0.1714\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20150, Loss_data: 0.0079, Loss_ode: 0.1669\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20160, Loss_data: 0.0078, Loss_ode: 0.1678\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20170, Loss_data: 0.0078, Loss_ode: 0.1641\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20180, Loss_data: 0.0078, Loss_ode: 0.1644\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20190, Loss_data: 0.0078, Loss_ode: 0.1669\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20200, Loss_data: 0.0078, Loss_ode: 0.1698\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20210, Loss_data: 0.0079, Loss_ode: 0.1684\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20220, Loss_data: 0.0078, Loss_ode: 0.1700\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20230, Loss_data: 0.0078, Loss_ode: 0.1700\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20240, Loss_data: 0.0079, Loss_ode: 0.1679\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20250, Loss_data: 0.0078, Loss_ode: 0.1697\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20260, Loss_data: 0.0079, Loss_ode: 0.1668\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20270, Loss_data: 0.0079, Loss_ode: 0.1659\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20280, Loss_data: 0.0079, Loss_ode: 0.1670\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20290, Loss_data: 0.0078, Loss_ode: 0.1672\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20300, Loss_data: 0.0077, Loss_ode: 0.1650\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20310, Loss_data: 0.0078, Loss_ode: 0.1679\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20320, Loss_data: 0.0078, Loss_ode: 0.1672\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20330, Loss_data: 0.0078, Loss_ode: 0.1679\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20340, Loss_data: 0.0079, Loss_ode: 0.1682\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20350, Loss_data: 0.0079, Loss_ode: 0.1693\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20360, Loss_data: 0.0078, Loss_ode: 0.1698\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20370, Loss_data: 0.0078, Loss_ode: 0.1691\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20380, Loss_data: 0.0079, Loss_ode: 0.1656\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20390, Loss_data: 0.0078, Loss_ode: 0.1660\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20400, Loss_data: 0.0077, Loss_ode: 0.1646\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20410, Loss_data: 0.0079, Loss_ode: 0.1639\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20420, Loss_data: 0.0078, Loss_ode: 0.1638\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20430, Loss_data: 0.0078, Loss_ode: 0.1627\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20440, Loss_data: 0.0078, Loss_ode: 0.1656\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20450, Loss_data: 0.0078, Loss_ode: 0.1689\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20460, Loss_data: 0.0078, Loss_ode: 0.1685\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20470, Loss_data: 0.0078, Loss_ode: 0.1674\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20480, Loss_data: 0.0078, Loss_ode: 0.1657\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20490, Loss_data: 0.0079, Loss_ode: 0.1662\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20500, Loss_data: 0.0079, Loss_ode: 0.1636\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20510, Loss_data: 0.0078, Loss_ode: 0.1610\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20520, Loss_data: 0.0079, Loss_ode: 0.1644\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20530, Loss_data: 0.0078, Loss_ode: 0.1642\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20540, Loss_data: 0.0078, Loss_ode: 0.1660\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20550, Loss_data: 0.0079, Loss_ode: 0.1665\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20560, Loss_data: 0.0078, Loss_ode: 0.1687\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20570, Loss_data: 0.0078, Loss_ode: 0.1663\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20580, Loss_data: 0.0078, Loss_ode: 0.1657\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20590, Loss_data: 0.0078, Loss_ode: 0.1666\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20600, Loss_data: 0.0078, Loss_ode: 0.1679\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20610, Loss_data: 0.0078, Loss_ode: 0.1618\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20620, Loss_data: 0.0078, Loss_ode: 0.1661\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20630, Loss_data: 0.0078, Loss_ode: 0.1633\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20640, Loss_data: 0.0078, Loss_ode: 0.1668\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20650, Loss_data: 0.0079, Loss_ode: 0.1652\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20660, Loss_data: 0.0078, Loss_ode: 0.1655\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20670, Loss_data: 0.0078, Loss_ode: 0.1636\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20680, Loss_data: 0.0078, Loss_ode: 0.1631\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20690, Loss_data: 0.0077, Loss_ode: 0.1643\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20700, Loss_data: 0.0079, Loss_ode: 0.1691\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20710, Loss_data: 0.0079, Loss_ode: 0.1638\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20720, Loss_data: 0.0078, Loss_ode: 0.1652\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20730, Loss_data: 0.0079, Loss_ode: 0.1645\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20740, Loss_data: 0.0079, Loss_ode: 0.1638\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20750, Loss_data: 0.0079, Loss_ode: 0.1643\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20760, Loss_data: 0.0078, Loss_ode: 0.1662\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20770, Loss_data: 0.0079, Loss_ode: 0.1648\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20780, Loss_data: 0.0079, Loss_ode: 0.1652\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20790, Loss_data: 0.0078, Loss_ode: 0.1643\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20800, Loss_data: 0.0079, Loss_ode: 0.1649\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20810, Loss_data: 0.0079, Loss_ode: 0.1690\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20820, Loss_data: 0.0079, Loss_ode: 0.1659\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20830, Loss_data: 0.0078, Loss_ode: 0.1670\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20840, Loss_data: 0.0079, Loss_ode: 0.1596\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20850, Loss_data: 0.0078, Loss_ode: 0.1646\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20860, Loss_data: 0.0078, Loss_ode: 0.1619\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20870, Loss_data: 0.0078, Loss_ode: 0.1619\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20880, Loss_data: 0.0079, Loss_ode: 0.1644\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20890, Loss_data: 0.0078, Loss_ode: 0.1637\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20900, Loss_data: 0.0078, Loss_ode: 0.1600\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20910, Loss_data: 0.0078, Loss_ode: 0.1631\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20920, Loss_data: 0.0079, Loss_ode: 0.1625\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20930, Loss_data: 0.0078, Loss_ode: 0.1625\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20940, Loss_data: 0.0079, Loss_ode: 0.1622\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20950, Loss_data: 0.0079, Loss_ode: 0.1581\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20960, Loss_data: 0.0079, Loss_ode: 0.1649\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20970, Loss_data: 0.0078, Loss_ode: 0.1623\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20980, Loss_data: 0.0079, Loss_ode: 0.1597\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20990, Loss_data: 0.0078, Loss_ode: 0.1612\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21000, Loss_data: 0.0078, Loss_ode: 0.1615\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21010, Loss_data: 0.0079, Loss_ode: 0.1610\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21020, Loss_data: 0.0078, Loss_ode: 0.1657\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21030, Loss_data: 0.0078, Loss_ode: 0.1617\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21040, Loss_data: 0.0078, Loss_ode: 0.1590\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21050, Loss_data: 0.0079, Loss_ode: 0.1627\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21060, Loss_data: 0.0078, Loss_ode: 0.1627\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21070, Loss_data: 0.0079, Loss_ode: 0.1610\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21080, Loss_data: 0.0078, Loss_ode: 0.1642\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21090, Loss_data: 0.0078, Loss_ode: 0.1643\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21100, Loss_data: 0.0078, Loss_ode: 0.1606\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21110, Loss_data: 0.0079, Loss_ode: 0.1606\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21120, Loss_data: 0.0079, Loss_ode: 0.1615\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21130, Loss_data: 0.0079, Loss_ode: 0.1589\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21140, Loss_data: 0.0077, Loss_ode: 0.1601\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21150, Loss_data: 0.0079, Loss_ode: 0.1619\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21160, Loss_data: 0.0078, Loss_ode: 0.1610\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21170, Loss_data: 0.0079, Loss_ode: 0.1600\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21180, Loss_data: 0.0078, Loss_ode: 0.1616\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21190, Loss_data: 0.0079, Loss_ode: 0.1611\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21200, Loss_data: 0.0079, Loss_ode: 0.1605\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21210, Loss_data: 0.0079, Loss_ode: 0.1589\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21220, Loss_data: 0.0078, Loss_ode: 0.1617\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21230, Loss_data: 0.0079, Loss_ode: 0.1585\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21240, Loss_data: 0.0079, Loss_ode: 0.1641\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21250, Loss_data: 0.0079, Loss_ode: 0.1596\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21260, Loss_data: 0.0078, Loss_ode: 0.1599\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21270, Loss_data: 0.0078, Loss_ode: 0.1606\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21280, Loss_data: 0.0078, Loss_ode: 0.1619\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21290, Loss_data: 0.0079, Loss_ode: 0.1576\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21300, Loss_data: 0.0078, Loss_ode: 0.1624\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21310, Loss_data: 0.0078, Loss_ode: 0.1611\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21320, Loss_data: 0.0078, Loss_ode: 0.1602\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21330, Loss_data: 0.0079, Loss_ode: 0.1601\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21340, Loss_data: 0.0078, Loss_ode: 0.1621\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21350, Loss_data: 0.0079, Loss_ode: 0.1605\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21360, Loss_data: 0.0078, Loss_ode: 0.1573\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21370, Loss_data: 0.0078, Loss_ode: 0.1607\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21380, Loss_data: 0.0078, Loss_ode: 0.1570\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21390, Loss_data: 0.0078, Loss_ode: 0.1598\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21400, Loss_data: 0.0079, Loss_ode: 0.1591\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21410, Loss_data: 0.0078, Loss_ode: 0.1605\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21420, Loss_data: 0.0078, Loss_ode: 0.1617\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21430, Loss_data: 0.0079, Loss_ode: 0.1580\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21440, Loss_data: 0.0079, Loss_ode: 0.1616\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21450, Loss_data: 0.0078, Loss_ode: 0.1586\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21460, Loss_data: 0.0078, Loss_ode: 0.1575\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21470, Loss_data: 0.0079, Loss_ode: 0.1602\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21480, Loss_data: 0.0078, Loss_ode: 0.1565\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21490, Loss_data: 0.0079, Loss_ode: 0.1580\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21500, Loss_data: 0.0078, Loss_ode: 0.1613\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21510, Loss_data: 0.0080, Loss_ode: 0.1599\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21520, Loss_data: 0.0078, Loss_ode: 0.1607\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21530, Loss_data: 0.0078, Loss_ode: 0.1560\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21540, Loss_data: 0.0079, Loss_ode: 0.1607\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21550, Loss_data: 0.0078, Loss_ode: 0.1594\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21560, Loss_data: 0.0079, Loss_ode: 0.1590\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21570, Loss_data: 0.0078, Loss_ode: 0.1568\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21580, Loss_data: 0.0079, Loss_ode: 0.1574\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21590, Loss_data: 0.0079, Loss_ode: 0.1594\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21600, Loss_data: 0.0079, Loss_ode: 0.1579\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21610, Loss_data: 0.0078, Loss_ode: 0.1561\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21620, Loss_data: 0.0080, Loss_ode: 0.1554\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21630, Loss_data: 0.0079, Loss_ode: 0.1543\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21640, Loss_data: 0.0079, Loss_ode: 0.1583\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21650, Loss_data: 0.0079, Loss_ode: 0.1574\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21660, Loss_data: 0.0079, Loss_ode: 0.1601\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21670, Loss_data: 0.0079, Loss_ode: 0.1545\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21680, Loss_data: 0.0078, Loss_ode: 0.1568\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21690, Loss_data: 0.0079, Loss_ode: 0.1575\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21700, Loss_data: 0.0079, Loss_ode: 0.1552\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21710, Loss_data: 0.0078, Loss_ode: 0.1585\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21720, Loss_data: 0.0079, Loss_ode: 0.1540\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21730, Loss_data: 0.0080, Loss_ode: 0.1541\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21740, Loss_data: 0.0079, Loss_ode: 0.1552\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21750, Loss_data: 0.0079, Loss_ode: 0.1544\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21760, Loss_data: 0.0079, Loss_ode: 0.1562\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21770, Loss_data: 0.0078, Loss_ode: 0.1545\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21780, Loss_data: 0.0078, Loss_ode: 0.1580\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21790, Loss_data: 0.0079, Loss_ode: 0.1516\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21800, Loss_data: 0.0079, Loss_ode: 0.1546\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21810, Loss_data: 0.0079, Loss_ode: 0.1591\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21820, Loss_data: 0.0079, Loss_ode: 0.1525\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21830, Loss_data: 0.0078, Loss_ode: 0.1561\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21840, Loss_data: 0.0080, Loss_ode: 0.1555\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21850, Loss_data: 0.0079, Loss_ode: 0.1559\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21860, Loss_data: 0.0079, Loss_ode: 0.1567\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21870, Loss_data: 0.0079, Loss_ode: 0.1526\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21880, Loss_data: 0.0078, Loss_ode: 0.1568\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21890, Loss_data: 0.0079, Loss_ode: 0.1562\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21900, Loss_data: 0.0079, Loss_ode: 0.1566\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21910, Loss_data: 0.0080, Loss_ode: 0.1574\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21920, Loss_data: 0.0079, Loss_ode: 0.1535\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21930, Loss_data: 0.0080, Loss_ode: 0.1561\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21940, Loss_data: 0.0079, Loss_ode: 0.1550\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21950, Loss_data: 0.0079, Loss_ode: 0.1507\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21960, Loss_data: 0.0079, Loss_ode: 0.1538\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21970, Loss_data: 0.0078, Loss_ode: 0.1489\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21980, Loss_data: 0.0079, Loss_ode: 0.1548\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21990, Loss_data: 0.0079, Loss_ode: 0.1579\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22000, Loss_data: 0.0078, Loss_ode: 0.1513\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22010, Loss_data: 0.0080, Loss_ode: 0.1541\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22020, Loss_data: 0.0080, Loss_ode: 0.1547\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22030, Loss_data: 0.0078, Loss_ode: 0.1556\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22040, Loss_data: 0.0079, Loss_ode: 0.1579\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22050, Loss_data: 0.0080, Loss_ode: 0.1551\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22060, Loss_data: 0.0079, Loss_ode: 0.1528\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22070, Loss_data: 0.0078, Loss_ode: 0.1559\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22080, Loss_data: 0.0079, Loss_ode: 0.1515\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22090, Loss_data: 0.0079, Loss_ode: 0.1548\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22100, Loss_data: 0.0079, Loss_ode: 0.1545\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22110, Loss_data: 0.0079, Loss_ode: 0.1589\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22120, Loss_data: 0.0080, Loss_ode: 0.1530\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22130, Loss_data: 0.0078, Loss_ode: 0.1535\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22140, Loss_data: 0.0079, Loss_ode: 0.1484\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22150, Loss_data: 0.0078, Loss_ode: 0.1525\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22160, Loss_data: 0.0079, Loss_ode: 0.1580\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22170, Loss_data: 0.0080, Loss_ode: 0.1516\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22180, Loss_data: 0.0079, Loss_ode: 0.1540\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22190, Loss_data: 0.0079, Loss_ode: 0.1497\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22200, Loss_data: 0.0079, Loss_ode: 0.1522\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22210, Loss_data: 0.0080, Loss_ode: 0.1522\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22220, Loss_data: 0.0080, Loss_ode: 0.1538\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22230, Loss_data: 0.0079, Loss_ode: 0.1527\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22240, Loss_data: 0.0079, Loss_ode: 0.1516\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22250, Loss_data: 0.0078, Loss_ode: 0.1517\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22260, Loss_data: 0.0080, Loss_ode: 0.1498\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22270, Loss_data: 0.0079, Loss_ode: 0.1512\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22280, Loss_data: 0.0080, Loss_ode: 0.1517\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22290, Loss_data: 0.0078, Loss_ode: 0.1523\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22300, Loss_data: 0.0079, Loss_ode: 0.1483\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22310, Loss_data: 0.0079, Loss_ode: 0.1501\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22320, Loss_data: 0.0079, Loss_ode: 0.1538\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22330, Loss_data: 0.0079, Loss_ode: 0.1521\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22340, Loss_data: 0.0079, Loss_ode: 0.1514\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22350, Loss_data: 0.0080, Loss_ode: 0.1506\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22360, Loss_data: 0.0079, Loss_ode: 0.1514\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22370, Loss_data: 0.0078, Loss_ode: 0.1483\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22380, Loss_data: 0.0079, Loss_ode: 0.1513\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22390, Loss_data: 0.0079, Loss_ode: 0.1516\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22400, Loss_data: 0.0078, Loss_ode: 0.1526\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22410, Loss_data: 0.0080, Loss_ode: 0.1500\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22420, Loss_data: 0.0080, Loss_ode: 0.1491\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22430, Loss_data: 0.0079, Loss_ode: 0.1527\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22440, Loss_data: 0.0079, Loss_ode: 0.1456\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22450, Loss_data: 0.0080, Loss_ode: 0.1502\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22460, Loss_data: 0.0078, Loss_ode: 0.1490\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22470, Loss_data: 0.0079, Loss_ode: 0.1468\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22480, Loss_data: 0.0079, Loss_ode: 0.1501\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22490, Loss_data: 0.0080, Loss_ode: 0.1481\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22500, Loss_data: 0.0079, Loss_ode: 0.1509\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22510, Loss_data: 0.0079, Loss_ode: 0.1494\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22520, Loss_data: 0.0080, Loss_ode: 0.1484\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22530, Loss_data: 0.0080, Loss_ode: 0.1459\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22540, Loss_data: 0.0079, Loss_ode: 0.1515\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22550, Loss_data: 0.0079, Loss_ode: 0.1509\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22560, Loss_data: 0.0080, Loss_ode: 0.1473\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22570, Loss_data: 0.0079, Loss_ode: 0.1498\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22580, Loss_data: 0.0079, Loss_ode: 0.1485\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22590, Loss_data: 0.0080, Loss_ode: 0.1457\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22600, Loss_data: 0.0080, Loss_ode: 0.1482\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22610, Loss_data: 0.0080, Loss_ode: 0.1520\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22620, Loss_data: 0.0079, Loss_ode: 0.1485\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22630, Loss_data: 0.0079, Loss_ode: 0.1472\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22640, Loss_data: 0.0079, Loss_ode: 0.1504\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22650, Loss_data: 0.0080, Loss_ode: 0.1486\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22660, Loss_data: 0.0079, Loss_ode: 0.1436\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22670, Loss_data: 0.0078, Loss_ode: 0.1463\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22680, Loss_data: 0.0079, Loss_ode: 0.1473\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22690, Loss_data: 0.0080, Loss_ode: 0.1480\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22700, Loss_data: 0.0080, Loss_ode: 0.1475\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22710, Loss_data: 0.0079, Loss_ode: 0.1478\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22720, Loss_data: 0.0080, Loss_ode: 0.1481\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22730, Loss_data: 0.0079, Loss_ode: 0.1467\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22740, Loss_data: 0.0080, Loss_ode: 0.1468\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22750, Loss_data: 0.0080, Loss_ode: 0.1498\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22760, Loss_data: 0.0079, Loss_ode: 0.1490\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22770, Loss_data: 0.0080, Loss_ode: 0.1471\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22780, Loss_data: 0.0079, Loss_ode: 0.1480\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22790, Loss_data: 0.0079, Loss_ode: 0.1447\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22800, Loss_data: 0.0079, Loss_ode: 0.1478\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22810, Loss_data: 0.0080, Loss_ode: 0.1503\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22820, Loss_data: 0.0079, Loss_ode: 0.1468\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22830, Loss_data: 0.0079, Loss_ode: 0.1516\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22840, Loss_data: 0.0080, Loss_ode: 0.1435\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22850, Loss_data: 0.0079, Loss_ode: 0.1466\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22860, Loss_data: 0.0081, Loss_ode: 0.1491\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22870, Loss_data: 0.0079, Loss_ode: 0.1499\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22880, Loss_data: 0.0079, Loss_ode: 0.1450\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22890, Loss_data: 0.0079, Loss_ode: 0.1480\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22900, Loss_data: 0.0080, Loss_ode: 0.1471\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22910, Loss_data: 0.0079, Loss_ode: 0.1471\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22920, Loss_data: 0.0079, Loss_ode: 0.1459\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22930, Loss_data: 0.0079, Loss_ode: 0.1464\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22940, Loss_data: 0.0080, Loss_ode: 0.1468\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22950, Loss_data: 0.0080, Loss_ode: 0.1442\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22960, Loss_data: 0.0080, Loss_ode: 0.1454\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22970, Loss_data: 0.0080, Loss_ode: 0.1483\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22980, Loss_data: 0.0080, Loss_ode: 0.1457\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22990, Loss_data: 0.0080, Loss_ode: 0.1436\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23000, Loss_data: 0.0080, Loss_ode: 0.1482\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23010, Loss_data: 0.0079, Loss_ode: 0.1474\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23020, Loss_data: 0.0080, Loss_ode: 0.1426\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23030, Loss_data: 0.0080, Loss_ode: 0.1493\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23040, Loss_data: 0.0080, Loss_ode: 0.1455\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23050, Loss_data: 0.0080, Loss_ode: 0.1433\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23060, Loss_data: 0.0080, Loss_ode: 0.1458\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23070, Loss_data: 0.0080, Loss_ode: 0.1457\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23080, Loss_data: 0.0080, Loss_ode: 0.1478\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23090, Loss_data: 0.0080, Loss_ode: 0.1455\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23100, Loss_data: 0.0079, Loss_ode: 0.1462\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23110, Loss_data: 0.0080, Loss_ode: 0.1414\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23120, Loss_data: 0.0080, Loss_ode: 0.1428\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23130, Loss_data: 0.0080, Loss_ode: 0.1448\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23140, Loss_data: 0.0080, Loss_ode: 0.1485\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23150, Loss_data: 0.0080, Loss_ode: 0.1472\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23160, Loss_data: 0.0079, Loss_ode: 0.1455\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23170, Loss_data: 0.0080, Loss_ode: 0.1456\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23180, Loss_data: 0.0080, Loss_ode: 0.1426\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23190, Loss_data: 0.0080, Loss_ode: 0.1475\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23200, Loss_data: 0.0079, Loss_ode: 0.1449\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23210, Loss_data: 0.0080, Loss_ode: 0.1473\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23220, Loss_data: 0.0080, Loss_ode: 0.1428\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23230, Loss_data: 0.0080, Loss_ode: 0.1452\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23240, Loss_data: 0.0080, Loss_ode: 0.1441\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23250, Loss_data: 0.0081, Loss_ode: 0.1474\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23260, Loss_data: 0.0079, Loss_ode: 0.1404\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23270, Loss_data: 0.0080, Loss_ode: 0.1465\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23280, Loss_data: 0.0081, Loss_ode: 0.1396\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23290, Loss_data: 0.0079, Loss_ode: 0.1458\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23300, Loss_data: 0.0081, Loss_ode: 0.1412\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23310, Loss_data: 0.0081, Loss_ode: 0.1444\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23320, Loss_data: 0.0081, Loss_ode: 0.1430\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23330, Loss_data: 0.0081, Loss_ode: 0.1457\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23340, Loss_data: 0.0080, Loss_ode: 0.1418\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23350, Loss_data: 0.0080, Loss_ode: 0.1426\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23360, Loss_data: 0.0080, Loss_ode: 0.1430\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23370, Loss_data: 0.0081, Loss_ode: 0.1477\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23380, Loss_data: 0.0080, Loss_ode: 0.1432\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23390, Loss_data: 0.0079, Loss_ode: 0.1425\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23400, Loss_data: 0.0080, Loss_ode: 0.1462\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23410, Loss_data: 0.0080, Loss_ode: 0.1443\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23420, Loss_data: 0.0080, Loss_ode: 0.1407\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23430, Loss_data: 0.0080, Loss_ode: 0.1430\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23440, Loss_data: 0.0080, Loss_ode: 0.1388\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23450, Loss_data: 0.0080, Loss_ode: 0.1384\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23460, Loss_data: 0.0080, Loss_ode: 0.1404\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23470, Loss_data: 0.0081, Loss_ode: 0.1395\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23480, Loss_data: 0.0080, Loss_ode: 0.1418\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23490, Loss_data: 0.0080, Loss_ode: 0.1437\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23500, Loss_data: 0.0081, Loss_ode: 0.1420\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23510, Loss_data: 0.0079, Loss_ode: 0.1407\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23520, Loss_data: 0.0080, Loss_ode: 0.1408\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23530, Loss_data: 0.0080, Loss_ode: 0.1408\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23540, Loss_data: 0.0081, Loss_ode: 0.1397\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23550, Loss_data: 0.0081, Loss_ode: 0.1383\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23560, Loss_data: 0.0080, Loss_ode: 0.1435\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23570, Loss_data: 0.0080, Loss_ode: 0.1421\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23580, Loss_data: 0.0080, Loss_ode: 0.1410\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23590, Loss_data: 0.0080, Loss_ode: 0.1408\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23600, Loss_data: 0.0080, Loss_ode: 0.1423\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23610, Loss_data: 0.0080, Loss_ode: 0.1412\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23620, Loss_data: 0.0080, Loss_ode: 0.1429\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23630, Loss_data: 0.0081, Loss_ode: 0.1392\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23640, Loss_data: 0.0081, Loss_ode: 0.1397\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23650, Loss_data: 0.0080, Loss_ode: 0.1398\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23660, Loss_data: 0.0080, Loss_ode: 0.1394\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23670, Loss_data: 0.0081, Loss_ode: 0.1388\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23680, Loss_data: 0.0080, Loss_ode: 0.1388\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23690, Loss_data: 0.0080, Loss_ode: 0.1430\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23700, Loss_data: 0.0080, Loss_ode: 0.1390\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23710, Loss_data: 0.0080, Loss_ode: 0.1359\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23720, Loss_data: 0.0080, Loss_ode: 0.1376\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23730, Loss_data: 0.0080, Loss_ode: 0.1378\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23740, Loss_data: 0.0081, Loss_ode: 0.1389\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23750, Loss_data: 0.0080, Loss_ode: 0.1386\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23760, Loss_data: 0.0080, Loss_ode: 0.1399\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23770, Loss_data: 0.0080, Loss_ode: 0.1382\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23780, Loss_data: 0.0080, Loss_ode: 0.1387\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23790, Loss_data: 0.0082, Loss_ode: 0.1394\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23800, Loss_data: 0.0080, Loss_ode: 0.1360\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23810, Loss_data: 0.0080, Loss_ode: 0.1366\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23820, Loss_data: 0.0080, Loss_ode: 0.1365\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23830, Loss_data: 0.0080, Loss_ode: 0.1396\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23840, Loss_data: 0.0081, Loss_ode: 0.1414\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23850, Loss_data: 0.0081, Loss_ode: 0.1401\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23860, Loss_data: 0.0081, Loss_ode: 0.1411\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23870, Loss_data: 0.0081, Loss_ode: 0.1389\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23880, Loss_data: 0.0080, Loss_ode: 0.1417\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23890, Loss_data: 0.0081, Loss_ode: 0.1349\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23900, Loss_data: 0.0081, Loss_ode: 0.1377\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23910, Loss_data: 0.0080, Loss_ode: 0.1350\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23920, Loss_data: 0.0080, Loss_ode: 0.1370\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23930, Loss_data: 0.0081, Loss_ode: 0.1367\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23940, Loss_data: 0.0080, Loss_ode: 0.1373\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23950, Loss_data: 0.0080, Loss_ode: 0.1395\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23960, Loss_data: 0.0081, Loss_ode: 0.1374\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23970, Loss_data: 0.0081, Loss_ode: 0.1369\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23980, Loss_data: 0.0081, Loss_ode: 0.1381\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23990, Loss_data: 0.0081, Loss_ode: 0.1383\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24000, Loss_data: 0.0080, Loss_ode: 0.1387\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24010, Loss_data: 0.0082, Loss_ode: 0.1397\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24020, Loss_data: 0.0081, Loss_ode: 0.1349\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24030, Loss_data: 0.0080, Loss_ode: 0.1375\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24040, Loss_data: 0.0081, Loss_ode: 0.1387\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24050, Loss_data: 0.0080, Loss_ode: 0.1355\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24060, Loss_data: 0.0081, Loss_ode: 0.1405\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24070, Loss_data: 0.0082, Loss_ode: 0.1359\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24080, Loss_data: 0.0080, Loss_ode: 0.1388\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24090, Loss_data: 0.0081, Loss_ode: 0.1381\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24100, Loss_data: 0.0080, Loss_ode: 0.1351\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24110, Loss_data: 0.0081, Loss_ode: 0.1350\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24120, Loss_data: 0.0081, Loss_ode: 0.1378\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24130, Loss_data: 0.0081, Loss_ode: 0.1398\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24140, Loss_data: 0.0081, Loss_ode: 0.1356\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24150, Loss_data: 0.0081, Loss_ode: 0.1353\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24160, Loss_data: 0.0080, Loss_ode: 0.1358\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24170, Loss_data: 0.0080, Loss_ode: 0.1345\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24180, Loss_data: 0.0082, Loss_ode: 0.1356\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24190, Loss_data: 0.0081, Loss_ode: 0.1357\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24200, Loss_data: 0.0081, Loss_ode: 0.1325\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24210, Loss_data: 0.0081, Loss_ode: 0.1334\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24220, Loss_data: 0.0080, Loss_ode: 0.1385\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24230, Loss_data: 0.0082, Loss_ode: 0.1383\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24240, Loss_data: 0.0081, Loss_ode: 0.1344\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24250, Loss_data: 0.0080, Loss_ode: 0.1353\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24260, Loss_data: 0.0080, Loss_ode: 0.1375\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24270, Loss_data: 0.0080, Loss_ode: 0.1340\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24280, Loss_data: 0.0081, Loss_ode: 0.1368\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24290, Loss_data: 0.0081, Loss_ode: 0.1345\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24300, Loss_data: 0.0081, Loss_ode: 0.1352\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24310, Loss_data: 0.0082, Loss_ode: 0.1380\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24320, Loss_data: 0.0082, Loss_ode: 0.1366\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24330, Loss_data: 0.0081, Loss_ode: 0.1340\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24340, Loss_data: 0.0081, Loss_ode: 0.1334\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24350, Loss_data: 0.0081, Loss_ode: 0.1321\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24360, Loss_data: 0.0081, Loss_ode: 0.1345\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24370, Loss_data: 0.0081, Loss_ode: 0.1373\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24380, Loss_data: 0.0082, Loss_ode: 0.1320\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24390, Loss_data: 0.0081, Loss_ode: 0.1354\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24400, Loss_data: 0.0082, Loss_ode: 0.1340\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24410, Loss_data: 0.0081, Loss_ode: 0.1327\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24420, Loss_data: 0.0081, Loss_ode: 0.1308\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24430, Loss_data: 0.0082, Loss_ode: 0.1357\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24440, Loss_data: 0.0081, Loss_ode: 0.1318\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24450, Loss_data: 0.0081, Loss_ode: 0.1325\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24460, Loss_data: 0.0081, Loss_ode: 0.1328\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24470, Loss_data: 0.0081, Loss_ode: 0.1297\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24480, Loss_data: 0.0082, Loss_ode: 0.1358\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24490, Loss_data: 0.0081, Loss_ode: 0.1296\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24500, Loss_data: 0.0081, Loss_ode: 0.1338\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24510, Loss_data: 0.0081, Loss_ode: 0.1338\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24520, Loss_data: 0.0081, Loss_ode: 0.1325\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24530, Loss_data: 0.0082, Loss_ode: 0.1284\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24540, Loss_data: 0.0081, Loss_ode: 0.1325\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24550, Loss_data: 0.0082, Loss_ode: 0.1332\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24560, Loss_data: 0.0081, Loss_ode: 0.1319\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24570, Loss_data: 0.0081, Loss_ode: 0.1322\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24580, Loss_data: 0.0081, Loss_ode: 0.1338\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24590, Loss_data: 0.0081, Loss_ode: 0.1322\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24600, Loss_data: 0.0081, Loss_ode: 0.1308\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24610, Loss_data: 0.0081, Loss_ode: 0.1340\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24620, Loss_data: 0.0081, Loss_ode: 0.1337\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24630, Loss_data: 0.0082, Loss_ode: 0.1282\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24640, Loss_data: 0.0080, Loss_ode: 0.1276\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24650, Loss_data: 0.0081, Loss_ode: 0.1300\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24660, Loss_data: 0.0082, Loss_ode: 0.1320\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24670, Loss_data: 0.0081, Loss_ode: 0.1322\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24680, Loss_data: 0.0082, Loss_ode: 0.1307\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24690, Loss_data: 0.0081, Loss_ode: 0.1300\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24700, Loss_data: 0.0082, Loss_ode: 0.1305\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24710, Loss_data: 0.0081, Loss_ode: 0.1332\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24720, Loss_data: 0.0081, Loss_ode: 0.1324\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24730, Loss_data: 0.0081, Loss_ode: 0.1336\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24740, Loss_data: 0.0081, Loss_ode: 0.1286\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24750, Loss_data: 0.0082, Loss_ode: 0.1308\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24760, Loss_data: 0.0081, Loss_ode: 0.1281\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24770, Loss_data: 0.0081, Loss_ode: 0.1309\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24780, Loss_data: 0.0082, Loss_ode: 0.1318\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24790, Loss_data: 0.0081, Loss_ode: 0.1333\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24800, Loss_data: 0.0081, Loss_ode: 0.1316\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24810, Loss_data: 0.0081, Loss_ode: 0.1289\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24820, Loss_data: 0.0082, Loss_ode: 0.1261\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24830, Loss_data: 0.0081, Loss_ode: 0.1308\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24840, Loss_data: 0.0081, Loss_ode: 0.1290\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24850, Loss_data: 0.0082, Loss_ode: 0.1263\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24860, Loss_data: 0.0082, Loss_ode: 0.1322\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24870, Loss_data: 0.0081, Loss_ode: 0.1314\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24880, Loss_data: 0.0082, Loss_ode: 0.1303\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24890, Loss_data: 0.0081, Loss_ode: 0.1296\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24900, Loss_data: 0.0081, Loss_ode: 0.1290\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24910, Loss_data: 0.0081, Loss_ode: 0.1287\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24920, Loss_data: 0.0082, Loss_ode: 0.1276\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24930, Loss_data: 0.0081, Loss_ode: 0.1344\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24940, Loss_data: 0.0082, Loss_ode: 0.1284\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24950, Loss_data: 0.0081, Loss_ode: 0.1281\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24960, Loss_data: 0.0081, Loss_ode: 0.1277\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24970, Loss_data: 0.0081, Loss_ode: 0.1279\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24980, Loss_data: 0.0082, Loss_ode: 0.1292\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24990, Loss_data: 0.0082, Loss_ode: 0.1264\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 25000, Loss_data: 0.0081, Loss_ode: 0.1269\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25010, Loss_data: 0.0081, Loss_ode: 0.1293\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25020, Loss_data: 0.0081, Loss_ode: 0.1284\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25030, Loss_data: 0.0081, Loss_ode: 0.1276\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25040, Loss_data: 0.0082, Loss_ode: 0.1276\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25050, Loss_data: 0.0081, Loss_ode: 0.1277\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25060, Loss_data: 0.0081, Loss_ode: 0.1265\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25070, Loss_data: 0.0081, Loss_ode: 0.1268\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25080, Loss_data: 0.0082, Loss_ode: 0.1263\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25090, Loss_data: 0.0082, Loss_ode: 0.1286\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25100, Loss_data: 0.0081, Loss_ode: 0.1271\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25110, Loss_data: 0.0081, Loss_ode: 0.1285\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25120, Loss_data: 0.0081, Loss_ode: 0.1282\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25130, Loss_data: 0.0082, Loss_ode: 0.1271\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25140, Loss_data: 0.0081, Loss_ode: 0.1274\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25150, Loss_data: 0.0082, Loss_ode: 0.1238\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25160, Loss_data: 0.0081, Loss_ode: 0.1255\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25170, Loss_data: 0.0081, Loss_ode: 0.1280\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25180, Loss_data: 0.0081, Loss_ode: 0.1276\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25190, Loss_data: 0.0081, Loss_ode: 0.1292\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25200, Loss_data: 0.0082, Loss_ode: 0.1278\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25210, Loss_data: 0.0082, Loss_ode: 0.1295\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25220, Loss_data: 0.0081, Loss_ode: 0.1266\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25230, Loss_data: 0.0082, Loss_ode: 0.1259\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25240, Loss_data: 0.0081, Loss_ode: 0.1274\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25250, Loss_data: 0.0081, Loss_ode: 0.1270\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25260, Loss_data: 0.0081, Loss_ode: 0.1261\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25270, Loss_data: 0.0082, Loss_ode: 0.1249\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25280, Loss_data: 0.0082, Loss_ode: 0.1258\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25290, Loss_data: 0.0082, Loss_ode: 0.1253\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25300, Loss_data: 0.0082, Loss_ode: 0.1258\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25310, Loss_data: 0.0082, Loss_ode: 0.1273\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25320, Loss_data: 0.0081, Loss_ode: 0.1273\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25330, Loss_data: 0.0082, Loss_ode: 0.1261\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25340, Loss_data: 0.0082, Loss_ode: 0.1248\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25350, Loss_data: 0.0081, Loss_ode: 0.1238\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25360, Loss_data: 0.0082, Loss_ode: 0.1242\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25370, Loss_data: 0.0083, Loss_ode: 0.1256\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25380, Loss_data: 0.0081, Loss_ode: 0.1215\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25390, Loss_data: 0.0082, Loss_ode: 0.1247\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25400, Loss_data: 0.0081, Loss_ode: 0.1292\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25410, Loss_data: 0.0082, Loss_ode: 0.1231\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25420, Loss_data: 0.0081, Loss_ode: 0.1244\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25430, Loss_data: 0.0082, Loss_ode: 0.1263\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25440, Loss_data: 0.0082, Loss_ode: 0.1224\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25450, Loss_data: 0.0081, Loss_ode: 0.1220\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25460, Loss_data: 0.0081, Loss_ode: 0.1212\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25470, Loss_data: 0.0082, Loss_ode: 0.1233\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25480, Loss_data: 0.0082, Loss_ode: 0.1243\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25490, Loss_data: 0.0081, Loss_ode: 0.1253\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25500, Loss_data: 0.0082, Loss_ode: 0.1261\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25510, Loss_data: 0.0081, Loss_ode: 0.1224\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25520, Loss_data: 0.0081, Loss_ode: 0.1210\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25530, Loss_data: 0.0081, Loss_ode: 0.1222\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25540, Loss_data: 0.0081, Loss_ode: 0.1242\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25550, Loss_data: 0.0081, Loss_ode: 0.1251\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25560, Loss_data: 0.0081, Loss_ode: 0.1214\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25570, Loss_data: 0.0081, Loss_ode: 0.1220\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25580, Loss_data: 0.0081, Loss_ode: 0.1242\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25590, Loss_data: 0.0082, Loss_ode: 0.1237\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25600, Loss_data: 0.0081, Loss_ode: 0.1236\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25610, Loss_data: 0.0082, Loss_ode: 0.1221\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25620, Loss_data: 0.0081, Loss_ode: 0.1242\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25630, Loss_data: 0.0082, Loss_ode: 0.1237\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25640, Loss_data: 0.0082, Loss_ode: 0.1236\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25650, Loss_data: 0.0082, Loss_ode: 0.1230\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25660, Loss_data: 0.0082, Loss_ode: 0.1228\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25670, Loss_data: 0.0081, Loss_ode: 0.1220\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25680, Loss_data: 0.0081, Loss_ode: 0.1204\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25690, Loss_data: 0.0081, Loss_ode: 0.1212\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25700, Loss_data: 0.0081, Loss_ode: 0.1247\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25710, Loss_data: 0.0082, Loss_ode: 0.1214\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25720, Loss_data: 0.0082, Loss_ode: 0.1198\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25730, Loss_data: 0.0081, Loss_ode: 0.1232\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25740, Loss_data: 0.0082, Loss_ode: 0.1228\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25750, Loss_data: 0.0081, Loss_ode: 0.1252\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25760, Loss_data: 0.0082, Loss_ode: 0.1202\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25770, Loss_data: 0.0082, Loss_ode: 0.1233\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25780, Loss_data: 0.0081, Loss_ode: 0.1221\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25790, Loss_data: 0.0082, Loss_ode: 0.1235\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25800, Loss_data: 0.0082, Loss_ode: 0.1215\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25810, Loss_data: 0.0082, Loss_ode: 0.1226\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25820, Loss_data: 0.0082, Loss_ode: 0.1254\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25830, Loss_data: 0.0083, Loss_ode: 0.1220\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25840, Loss_data: 0.0081, Loss_ode: 0.1216\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25850, Loss_data: 0.0082, Loss_ode: 0.1217\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25860, Loss_data: 0.0082, Loss_ode: 0.1220\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25870, Loss_data: 0.0082, Loss_ode: 0.1240\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25880, Loss_data: 0.0082, Loss_ode: 0.1216\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25890, Loss_data: 0.0083, Loss_ode: 0.1209\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25900, Loss_data: 0.0081, Loss_ode: 0.1244\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25910, Loss_data: 0.0082, Loss_ode: 0.1209\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25920, Loss_data: 0.0082, Loss_ode: 0.1190\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25930, Loss_data: 0.0082, Loss_ode: 0.1220\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25940, Loss_data: 0.0081, Loss_ode: 0.1231\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25950, Loss_data: 0.0082, Loss_ode: 0.1191\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25960, Loss_data: 0.0082, Loss_ode: 0.1214\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25970, Loss_data: 0.0081, Loss_ode: 0.1222\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25980, Loss_data: 0.0082, Loss_ode: 0.1205\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25990, Loss_data: 0.0081, Loss_ode: 0.1212\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26000, Loss_data: 0.0081, Loss_ode: 0.1184\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26010, Loss_data: 0.0082, Loss_ode: 0.1180\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26020, Loss_data: 0.0082, Loss_ode: 0.1168\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26030, Loss_data: 0.0082, Loss_ode: 0.1202\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26040, Loss_data: 0.0082, Loss_ode: 0.1179\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26050, Loss_data: 0.0082, Loss_ode: 0.1222\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26060, Loss_data: 0.0082, Loss_ode: 0.1193\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26070, Loss_data: 0.0081, Loss_ode: 0.1178\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26080, Loss_data: 0.0082, Loss_ode: 0.1192\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26090, Loss_data: 0.0081, Loss_ode: 0.1215\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26100, Loss_data: 0.0081, Loss_ode: 0.1189\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26110, Loss_data: 0.0081, Loss_ode: 0.1180\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26120, Loss_data: 0.0082, Loss_ode: 0.1203\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26130, Loss_data: 0.0082, Loss_ode: 0.1181\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26140, Loss_data: 0.0081, Loss_ode: 0.1208\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26150, Loss_data: 0.0082, Loss_ode: 0.1200\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26160, Loss_data: 0.0082, Loss_ode: 0.1210\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26170, Loss_data: 0.0082, Loss_ode: 0.1209\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26180, Loss_data: 0.0082, Loss_ode: 0.1213\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26190, Loss_data: 0.0082, Loss_ode: 0.1186\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26200, Loss_data: 0.0082, Loss_ode: 0.1201\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26210, Loss_data: 0.0081, Loss_ode: 0.1199\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26220, Loss_data: 0.0082, Loss_ode: 0.1211\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26230, Loss_data: 0.0083, Loss_ode: 0.1177\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26240, Loss_data: 0.0081, Loss_ode: 0.1184\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26250, Loss_data: 0.0082, Loss_ode: 0.1185\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26260, Loss_data: 0.0081, Loss_ode: 0.1176\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26270, Loss_data: 0.0081, Loss_ode: 0.1189\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26280, Loss_data: 0.0082, Loss_ode: 0.1171\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26290, Loss_data: 0.0082, Loss_ode: 0.1191\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26300, Loss_data: 0.0081, Loss_ode: 0.1197\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26310, Loss_data: 0.0082, Loss_ode: 0.1199\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26320, Loss_data: 0.0083, Loss_ode: 0.1191\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26330, Loss_data: 0.0081, Loss_ode: 0.1163\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26340, Loss_data: 0.0082, Loss_ode: 0.1160\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26350, Loss_data: 0.0082, Loss_ode: 0.1171\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26360, Loss_data: 0.0082, Loss_ode: 0.1180\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26370, Loss_data: 0.0082, Loss_ode: 0.1194\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26380, Loss_data: 0.0083, Loss_ode: 0.1185\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26390, Loss_data: 0.0082, Loss_ode: 0.1175\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26400, Loss_data: 0.0082, Loss_ode: 0.1176\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26410, Loss_data: 0.0082, Loss_ode: 0.1171\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26420, Loss_data: 0.0082, Loss_ode: 0.1188\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26430, Loss_data: 0.0082, Loss_ode: 0.1159\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26440, Loss_data: 0.0082, Loss_ode: 0.1175\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26450, Loss_data: 0.0082, Loss_ode: 0.1156\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26460, Loss_data: 0.0082, Loss_ode: 0.1181\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26470, Loss_data: 0.0082, Loss_ode: 0.1173\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26480, Loss_data: 0.0082, Loss_ode: 0.1168\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26490, Loss_data: 0.0082, Loss_ode: 0.1145\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26500, Loss_data: 0.0082, Loss_ode: 0.1191\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26510, Loss_data: 0.0082, Loss_ode: 0.1181\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26520, Loss_data: 0.0082, Loss_ode: 0.1167\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26530, Loss_data: 0.0082, Loss_ode: 0.1166\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26540, Loss_data: 0.0082, Loss_ode: 0.1166\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26550, Loss_data: 0.0082, Loss_ode: 0.1166\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26560, Loss_data: 0.0082, Loss_ode: 0.1172\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26570, Loss_data: 0.0082, Loss_ode: 0.1143\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26580, Loss_data: 0.0082, Loss_ode: 0.1160\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26590, Loss_data: 0.0082, Loss_ode: 0.1156\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26600, Loss_data: 0.0081, Loss_ode: 0.1160\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26610, Loss_data: 0.0081, Loss_ode: 0.1157\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26620, Loss_data: 0.0082, Loss_ode: 0.1172\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26630, Loss_data: 0.0082, Loss_ode: 0.1176\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26640, Loss_data: 0.0082, Loss_ode: 0.1190\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26650, Loss_data: 0.0083, Loss_ode: 0.1165\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26660, Loss_data: 0.0082, Loss_ode: 0.1173\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26670, Loss_data: 0.0082, Loss_ode: 0.1175\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26680, Loss_data: 0.0083, Loss_ode: 0.1125\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26690, Loss_data: 0.0082, Loss_ode: 0.1163\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26700, Loss_data: 0.0082, Loss_ode: 0.1158\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26710, Loss_data: 0.0083, Loss_ode: 0.1127\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26720, Loss_data: 0.0083, Loss_ode: 0.1141\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26730, Loss_data: 0.0082, Loss_ode: 0.1164\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26740, Loss_data: 0.0082, Loss_ode: 0.1120\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26750, Loss_data: 0.0082, Loss_ode: 0.1142\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26760, Loss_data: 0.0082, Loss_ode: 0.1132\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26770, Loss_data: 0.0082, Loss_ode: 0.1187\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26780, Loss_data: 0.0083, Loss_ode: 0.1154\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26790, Loss_data: 0.0081, Loss_ode: 0.1150\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26800, Loss_data: 0.0082, Loss_ode: 0.1145\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26810, Loss_data: 0.0082, Loss_ode: 0.1162\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26820, Loss_data: 0.0082, Loss_ode: 0.1130\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26830, Loss_data: 0.0082, Loss_ode: 0.1112\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26840, Loss_data: 0.0082, Loss_ode: 0.1144\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26850, Loss_data: 0.0083, Loss_ode: 0.1155\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26860, Loss_data: 0.0081, Loss_ode: 0.1175\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26870, Loss_data: 0.0082, Loss_ode: 0.1146\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26880, Loss_data: 0.0082, Loss_ode: 0.1143\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26890, Loss_data: 0.0082, Loss_ode: 0.1162\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26900, Loss_data: 0.0083, Loss_ode: 0.1145\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26910, Loss_data: 0.0082, Loss_ode: 0.1131\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26920, Loss_data: 0.0082, Loss_ode: 0.1116\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26930, Loss_data: 0.0081, Loss_ode: 0.1129\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26940, Loss_data: 0.0082, Loss_ode: 0.1117\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26950, Loss_data: 0.0082, Loss_ode: 0.1142\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26960, Loss_data: 0.0082, Loss_ode: 0.1129\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26970, Loss_data: 0.0082, Loss_ode: 0.1124\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26980, Loss_data: 0.0083, Loss_ode: 0.1113\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26990, Loss_data: 0.0082, Loss_ode: 0.1141\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27000, Loss_data: 0.0082, Loss_ode: 0.1154\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27010, Loss_data: 0.0082, Loss_ode: 0.1154\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27020, Loss_data: 0.0082, Loss_ode: 0.1146\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27030, Loss_data: 0.0082, Loss_ode: 0.1139\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27040, Loss_data: 0.0082, Loss_ode: 0.1153\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27050, Loss_data: 0.0082, Loss_ode: 0.1121\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27060, Loss_data: 0.0082, Loss_ode: 0.1137\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27070, Loss_data: 0.0083, Loss_ode: 0.1131\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27080, Loss_data: 0.0082, Loss_ode: 0.1121\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27090, Loss_data: 0.0082, Loss_ode: 0.1139\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27100, Loss_data: 0.0082, Loss_ode: 0.1089\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27110, Loss_data: 0.0082, Loss_ode: 0.1144\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27120, Loss_data: 0.0082, Loss_ode: 0.1129\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27130, Loss_data: 0.0082, Loss_ode: 0.1118\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27140, Loss_data: 0.0082, Loss_ode: 0.1127\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27150, Loss_data: 0.0082, Loss_ode: 0.1139\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27160, Loss_data: 0.0082, Loss_ode: 0.1155\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27170, Loss_data: 0.0082, Loss_ode: 0.1095\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27180, Loss_data: 0.0082, Loss_ode: 0.1108\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27190, Loss_data: 0.0082, Loss_ode: 0.1083\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27200, Loss_data: 0.0083, Loss_ode: 0.1130\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27210, Loss_data: 0.0082, Loss_ode: 0.1100\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27220, Loss_data: 0.0082, Loss_ode: 0.1125\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27230, Loss_data: 0.0082, Loss_ode: 0.1112\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27240, Loss_data: 0.0083, Loss_ode: 0.1118\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27250, Loss_data: 0.0081, Loss_ode: 0.1127\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27260, Loss_data: 0.0082, Loss_ode: 0.1144\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27270, Loss_data: 0.0082, Loss_ode: 0.1128\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27280, Loss_data: 0.0082, Loss_ode: 0.1132\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27290, Loss_data: 0.0082, Loss_ode: 0.1093\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27300, Loss_data: 0.0082, Loss_ode: 0.1142\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27310, Loss_data: 0.0082, Loss_ode: 0.1101\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27320, Loss_data: 0.0082, Loss_ode: 0.1089\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27330, Loss_data: 0.0082, Loss_ode: 0.1087\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27340, Loss_data: 0.0082, Loss_ode: 0.1124\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27350, Loss_data: 0.0082, Loss_ode: 0.1121\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27360, Loss_data: 0.0082, Loss_ode: 0.1107\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27370, Loss_data: 0.0082, Loss_ode: 0.1097\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27380, Loss_data: 0.0082, Loss_ode: 0.1093\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27390, Loss_data: 0.0083, Loss_ode: 0.1088\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27400, Loss_data: 0.0082, Loss_ode: 0.1088\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27410, Loss_data: 0.0082, Loss_ode: 0.1106\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27420, Loss_data: 0.0082, Loss_ode: 0.1089\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27430, Loss_data: 0.0082, Loss_ode: 0.1069\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27440, Loss_data: 0.0083, Loss_ode: 0.1095\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27450, Loss_data: 0.0082, Loss_ode: 0.1093\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27460, Loss_data: 0.0082, Loss_ode: 0.1098\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27470, Loss_data: 0.0082, Loss_ode: 0.1036\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27480, Loss_data: 0.0083, Loss_ode: 0.1108\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27490, Loss_data: 0.0082, Loss_ode: 0.1093\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27500, Loss_data: 0.0082, Loss_ode: 0.1091\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27510, Loss_data: 0.0082, Loss_ode: 0.1083\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27520, Loss_data: 0.0082, Loss_ode: 0.1071\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27530, Loss_data: 0.0083, Loss_ode: 0.1088\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27540, Loss_data: 0.0082, Loss_ode: 0.1088\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27550, Loss_data: 0.0082, Loss_ode: 0.1078\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27560, Loss_data: 0.0082, Loss_ode: 0.1083\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27570, Loss_data: 0.0082, Loss_ode: 0.1093\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27580, Loss_data: 0.0082, Loss_ode: 0.1111\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27590, Loss_data: 0.0082, Loss_ode: 0.1083\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27600, Loss_data: 0.0082, Loss_ode: 0.1109\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27610, Loss_data: 0.0082, Loss_ode: 0.1058\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27620, Loss_data: 0.0082, Loss_ode: 0.1069\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27630, Loss_data: 0.0082, Loss_ode: 0.1093\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27640, Loss_data: 0.0082, Loss_ode: 0.1105\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27650, Loss_data: 0.0082, Loss_ode: 0.1086\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27660, Loss_data: 0.0082, Loss_ode: 0.1109\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27670, Loss_data: 0.0082, Loss_ode: 0.1060\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27680, Loss_data: 0.0082, Loss_ode: 0.1076\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27690, Loss_data: 0.0082, Loss_ode: 0.1061\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27700, Loss_data: 0.0082, Loss_ode: 0.1065\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27710, Loss_data: 0.0082, Loss_ode: 0.1084\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27720, Loss_data: 0.0083, Loss_ode: 0.1076\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27730, Loss_data: 0.0082, Loss_ode: 0.1061\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27740, Loss_data: 0.0082, Loss_ode: 0.1065\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27750, Loss_data: 0.0082, Loss_ode: 0.1052\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27760, Loss_data: 0.0082, Loss_ode: 0.1032\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27770, Loss_data: 0.0082, Loss_ode: 0.1080\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27780, Loss_data: 0.0082, Loss_ode: 0.1091\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27790, Loss_data: 0.0082, Loss_ode: 0.1085\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27800, Loss_data: 0.0082, Loss_ode: 0.1067\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27810, Loss_data: 0.0083, Loss_ode: 0.1075\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27820, Loss_data: 0.0082, Loss_ode: 0.1068\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27830, Loss_data: 0.0082, Loss_ode: 0.1091\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27840, Loss_data: 0.0082, Loss_ode: 0.1074\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27850, Loss_data: 0.0082, Loss_ode: 0.1072\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27860, Loss_data: 0.0082, Loss_ode: 0.1056\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27870, Loss_data: 0.0083, Loss_ode: 0.1084\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27880, Loss_data: 0.0082, Loss_ode: 0.1096\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27890, Loss_data: 0.0082, Loss_ode: 0.1052\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27900, Loss_data: 0.0082, Loss_ode: 0.1054\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27910, Loss_data: 0.0083, Loss_ode: 0.1082\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27920, Loss_data: 0.0082, Loss_ode: 0.1063\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27930, Loss_data: 0.0082, Loss_ode: 0.1076\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27940, Loss_data: 0.0082, Loss_ode: 0.1087\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27950, Loss_data: 0.0082, Loss_ode: 0.1053\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27960, Loss_data: 0.0082, Loss_ode: 0.1042\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27970, Loss_data: 0.0081, Loss_ode: 0.1059\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27980, Loss_data: 0.0082, Loss_ode: 0.1064\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27990, Loss_data: 0.0083, Loss_ode: 0.1022\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28000, Loss_data: 0.0082, Loss_ode: 0.1044\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28010, Loss_data: 0.0082, Loss_ode: 0.1060\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28020, Loss_data: 0.0082, Loss_ode: 0.1070\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28030, Loss_data: 0.0082, Loss_ode: 0.1066\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28040, Loss_data: 0.0082, Loss_ode: 0.1047\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28050, Loss_data: 0.0082, Loss_ode: 0.1069\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28060, Loss_data: 0.0082, Loss_ode: 0.1038\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28070, Loss_data: 0.0082, Loss_ode: 0.1064\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28080, Loss_data: 0.0082, Loss_ode: 0.1055\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28090, Loss_data: 0.0082, Loss_ode: 0.1050\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28100, Loss_data: 0.0082, Loss_ode: 0.1067\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28110, Loss_data: 0.0082, Loss_ode: 0.1046\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28120, Loss_data: 0.0082, Loss_ode: 0.1090\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28130, Loss_data: 0.0082, Loss_ode: 0.1039\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28140, Loss_data: 0.0083, Loss_ode: 0.1053\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28150, Loss_data: 0.0082, Loss_ode: 0.1056\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28160, Loss_data: 0.0082, Loss_ode: 0.1053\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28170, Loss_data: 0.0082, Loss_ode: 0.1079\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28180, Loss_data: 0.0082, Loss_ode: 0.1040\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28190, Loss_data: 0.0082, Loss_ode: 0.1066\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28200, Loss_data: 0.0082, Loss_ode: 0.1012\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28210, Loss_data: 0.0082, Loss_ode: 0.1049\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28220, Loss_data: 0.0082, Loss_ode: 0.1037\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28230, Loss_data: 0.0083, Loss_ode: 0.1054\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28240, Loss_data: 0.0082, Loss_ode: 0.1085\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28250, Loss_data: 0.0082, Loss_ode: 0.1055\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28260, Loss_data: 0.0082, Loss_ode: 0.1064\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28270, Loss_data: 0.0082, Loss_ode: 0.1035\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28280, Loss_data: 0.0083, Loss_ode: 0.1067\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28290, Loss_data: 0.0082, Loss_ode: 0.1024\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28300, Loss_data: 0.0082, Loss_ode: 0.1073\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28310, Loss_data: 0.0082, Loss_ode: 0.1027\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28320, Loss_data: 0.0082, Loss_ode: 0.1067\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28330, Loss_data: 0.0082, Loss_ode: 0.1050\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28340, Loss_data: 0.0082, Loss_ode: 0.1053\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28350, Loss_data: 0.0082, Loss_ode: 0.1082\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28360, Loss_data: 0.0082, Loss_ode: 0.1050\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28370, Loss_data: 0.0083, Loss_ode: 0.1008\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28380, Loss_data: 0.0082, Loss_ode: 0.1049\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28390, Loss_data: 0.0082, Loss_ode: 0.1048\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28400, Loss_data: 0.0082, Loss_ode: 0.1043\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28410, Loss_data: 0.0082, Loss_ode: 0.1024\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28420, Loss_data: 0.0082, Loss_ode: 0.1025\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28430, Loss_data: 0.0082, Loss_ode: 0.1036\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28440, Loss_data: 0.0082, Loss_ode: 0.1068\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28450, Loss_data: 0.0083, Loss_ode: 0.1031\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28460, Loss_data: 0.0082, Loss_ode: 0.1028\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28470, Loss_data: 0.0083, Loss_ode: 0.1043\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28480, Loss_data: 0.0083, Loss_ode: 0.1058\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28490, Loss_data: 0.0082, Loss_ode: 0.1034\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28500, Loss_data: 0.0082, Loss_ode: 0.1034\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28510, Loss_data: 0.0082, Loss_ode: 0.1047\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28520, Loss_data: 0.0082, Loss_ode: 0.1017\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28530, Loss_data: 0.0082, Loss_ode: 0.1007\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28540, Loss_data: 0.0083, Loss_ode: 0.1029\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28550, Loss_data: 0.0083, Loss_ode: 0.1023\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28560, Loss_data: 0.0083, Loss_ode: 0.1002\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28570, Loss_data: 0.0082, Loss_ode: 0.1020\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28580, Loss_data: 0.0082, Loss_ode: 0.1043\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28590, Loss_data: 0.0083, Loss_ode: 0.1013\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28600, Loss_data: 0.0082, Loss_ode: 0.1054\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28610, Loss_data: 0.0082, Loss_ode: 0.1032\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28620, Loss_data: 0.0083, Loss_ode: 0.1041\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28630, Loss_data: 0.0083, Loss_ode: 0.0996\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28640, Loss_data: 0.0082, Loss_ode: 0.1019\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28650, Loss_data: 0.0082, Loss_ode: 0.1019\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28660, Loss_data: 0.0082, Loss_ode: 0.1018\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28670, Loss_data: 0.0082, Loss_ode: 0.1006\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28680, Loss_data: 0.0082, Loss_ode: 0.1009\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28690, Loss_data: 0.0083, Loss_ode: 0.1022\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28700, Loss_data: 0.0082, Loss_ode: 0.1038\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28710, Loss_data: 0.0082, Loss_ode: 0.0987\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28720, Loss_data: 0.0082, Loss_ode: 0.1023\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28730, Loss_data: 0.0083, Loss_ode: 0.1035\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28740, Loss_data: 0.0082, Loss_ode: 0.1009\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28750, Loss_data: 0.0082, Loss_ode: 0.1014\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28760, Loss_data: 0.0082, Loss_ode: 0.1015\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28770, Loss_data: 0.0082, Loss_ode: 0.1028\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28780, Loss_data: 0.0082, Loss_ode: 0.1029\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28790, Loss_data: 0.0082, Loss_ode: 0.1012\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28800, Loss_data: 0.0082, Loss_ode: 0.1021\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28810, Loss_data: 0.0083, Loss_ode: 0.1018\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28820, Loss_data: 0.0082, Loss_ode: 0.1030\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28830, Loss_data: 0.0082, Loss_ode: 0.1016\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28840, Loss_data: 0.0082, Loss_ode: 0.1003\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28850, Loss_data: 0.0082, Loss_ode: 0.0976\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28860, Loss_data: 0.0082, Loss_ode: 0.1049\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28870, Loss_data: 0.0084, Loss_ode: 0.1012\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28880, Loss_data: 0.0083, Loss_ode: 0.1018\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28890, Loss_data: 0.0083, Loss_ode: 0.1000\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28900, Loss_data: 0.0082, Loss_ode: 0.1011\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28910, Loss_data: 0.0082, Loss_ode: 0.0979\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28920, Loss_data: 0.0082, Loss_ode: 0.0998\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28930, Loss_data: 0.0082, Loss_ode: 0.0999\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28940, Loss_data: 0.0082, Loss_ode: 0.0992\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28950, Loss_data: 0.0082, Loss_ode: 0.0983\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28960, Loss_data: 0.0083, Loss_ode: 0.1012\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28970, Loss_data: 0.0083, Loss_ode: 0.1002\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28980, Loss_data: 0.0082, Loss_ode: 0.0997\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28990, Loss_data: 0.0082, Loss_ode: 0.0983\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29000, Loss_data: 0.0082, Loss_ode: 0.1010\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29010, Loss_data: 0.0083, Loss_ode: 0.1006\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29020, Loss_data: 0.0082, Loss_ode: 0.1014\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29030, Loss_data: 0.0082, Loss_ode: 0.0984\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29040, Loss_data: 0.0082, Loss_ode: 0.1017\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29050, Loss_data: 0.0083, Loss_ode: 0.1013\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29060, Loss_data: 0.0082, Loss_ode: 0.1005\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29070, Loss_data: 0.0083, Loss_ode: 0.0994\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29080, Loss_data: 0.0083, Loss_ode: 0.0994\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29090, Loss_data: 0.0082, Loss_ode: 0.0995\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29100, Loss_data: 0.0083, Loss_ode: 0.0987\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29110, Loss_data: 0.0083, Loss_ode: 0.0984\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29120, Loss_data: 0.0082, Loss_ode: 0.0988\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29130, Loss_data: 0.0082, Loss_ode: 0.1007\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29140, Loss_data: 0.0082, Loss_ode: 0.1036\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29150, Loss_data: 0.0083, Loss_ode: 0.1008\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29160, Loss_data: 0.0083, Loss_ode: 0.0966\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29170, Loss_data: 0.0082, Loss_ode: 0.0994\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29180, Loss_data: 0.0082, Loss_ode: 0.1024\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29190, Loss_data: 0.0082, Loss_ode: 0.0998\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29200, Loss_data: 0.0083, Loss_ode: 0.0997\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29210, Loss_data: 0.0083, Loss_ode: 0.1002\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29220, Loss_data: 0.0083, Loss_ode: 0.1002\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29230, Loss_data: 0.0083, Loss_ode: 0.1008\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29240, Loss_data: 0.0082, Loss_ode: 0.0984\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29250, Loss_data: 0.0082, Loss_ode: 0.0989\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29260, Loss_data: 0.0082, Loss_ode: 0.0993\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29270, Loss_data: 0.0082, Loss_ode: 0.0984\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29280, Loss_data: 0.0083, Loss_ode: 0.0991\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29290, Loss_data: 0.0082, Loss_ode: 0.0985\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29300, Loss_data: 0.0083, Loss_ode: 0.0980\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29310, Loss_data: 0.0083, Loss_ode: 0.0974\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29320, Loss_data: 0.0083, Loss_ode: 0.0986\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29330, Loss_data: 0.0083, Loss_ode: 0.0945\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29340, Loss_data: 0.0082, Loss_ode: 0.0995\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29350, Loss_data: 0.0083, Loss_ode: 0.1009\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29360, Loss_data: 0.0083, Loss_ode: 0.0962\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29370, Loss_data: 0.0083, Loss_ode: 0.0968\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29380, Loss_data: 0.0082, Loss_ode: 0.1007\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29390, Loss_data: 0.0082, Loss_ode: 0.0976\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29400, Loss_data: 0.0083, Loss_ode: 0.0977\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29410, Loss_data: 0.0082, Loss_ode: 0.0996\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29420, Loss_data: 0.0082, Loss_ode: 0.0971\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29430, Loss_data: 0.0082, Loss_ode: 0.0988\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29440, Loss_data: 0.0082, Loss_ode: 0.0986\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29450, Loss_data: 0.0082, Loss_ode: 0.0975\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29460, Loss_data: 0.0082, Loss_ode: 0.1013\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29470, Loss_data: 0.0082, Loss_ode: 0.0968\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29480, Loss_data: 0.0083, Loss_ode: 0.0977\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29490, Loss_data: 0.0082, Loss_ode: 0.0970\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29500, Loss_data: 0.0082, Loss_ode: 0.0970\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29510, Loss_data: 0.0082, Loss_ode: 0.0951\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29520, Loss_data: 0.0082, Loss_ode: 0.0938\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29530, Loss_data: 0.0082, Loss_ode: 0.0981\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29540, Loss_data: 0.0082, Loss_ode: 0.0961\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29550, Loss_data: 0.0083, Loss_ode: 0.0967\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29560, Loss_data: 0.0082, Loss_ode: 0.0980\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29570, Loss_data: 0.0082, Loss_ode: 0.0979\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29580, Loss_data: 0.0082, Loss_ode: 0.0944\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29590, Loss_data: 0.0082, Loss_ode: 0.0973\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29600, Loss_data: 0.0082, Loss_ode: 0.0941\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29610, Loss_data: 0.0083, Loss_ode: 0.0988\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29620, Loss_data: 0.0083, Loss_ode: 0.0946\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29630, Loss_data: 0.0082, Loss_ode: 0.0938\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29640, Loss_data: 0.0083, Loss_ode: 0.0973\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29650, Loss_data: 0.0083, Loss_ode: 0.0975\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29660, Loss_data: 0.0082, Loss_ode: 0.0935\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29670, Loss_data: 0.0082, Loss_ode: 0.0942\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29680, Loss_data: 0.0083, Loss_ode: 0.0958\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29690, Loss_data: 0.0082, Loss_ode: 0.0951\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29700, Loss_data: 0.0082, Loss_ode: 0.1003\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29710, Loss_data: 0.0083, Loss_ode: 0.0972\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29720, Loss_data: 0.0083, Loss_ode: 0.0928\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29730, Loss_data: 0.0082, Loss_ode: 0.0952\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29740, Loss_data: 0.0082, Loss_ode: 0.0974\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29750, Loss_data: 0.0083, Loss_ode: 0.0929\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29760, Loss_data: 0.0082, Loss_ode: 0.0932\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29770, Loss_data: 0.0082, Loss_ode: 0.0962\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29780, Loss_data: 0.0082, Loss_ode: 0.0955\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29790, Loss_data: 0.0082, Loss_ode: 0.0938\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29800, Loss_data: 0.0082, Loss_ode: 0.0939\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29810, Loss_data: 0.0083, Loss_ode: 0.0980\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29820, Loss_data: 0.0083, Loss_ode: 0.0957\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29830, Loss_data: 0.0082, Loss_ode: 0.0959\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29840, Loss_data: 0.0082, Loss_ode: 0.0957\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29850, Loss_data: 0.0082, Loss_ode: 0.0954\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29860, Loss_data: 0.0082, Loss_ode: 0.0936\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29870, Loss_data: 0.0083, Loss_ode: 0.0958\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29880, Loss_data: 0.0082, Loss_ode: 0.0952\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29890, Loss_data: 0.0082, Loss_ode: 0.0955\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29900, Loss_data: 0.0083, Loss_ode: 0.0950\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29910, Loss_data: 0.0083, Loss_ode: 0.0939\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29920, Loss_data: 0.0082, Loss_ode: 0.0925\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29930, Loss_data: 0.0083, Loss_ode: 0.0948\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29940, Loss_data: 0.0082, Loss_ode: 0.0960\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29950, Loss_data: 0.0082, Loss_ode: 0.0941\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29960, Loss_data: 0.0082, Loss_ode: 0.0971\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29970, Loss_data: 0.0082, Loss_ode: 0.0925\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29980, Loss_data: 0.0083, Loss_ode: 0.0948\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29990, Loss_data: 0.0082, Loss_ode: 0.0939\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 30000, Loss_data: 0.0082, Loss_ode: 0.0979\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30010, Loss_data: 0.0082, Loss_ode: 0.0932\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30020, Loss_data: 0.0083, Loss_ode: 0.0922\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30030, Loss_data: 0.0082, Loss_ode: 0.0980\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30040, Loss_data: 0.0082, Loss_ode: 0.0922\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30050, Loss_data: 0.0083, Loss_ode: 0.0932\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30060, Loss_data: 0.0083, Loss_ode: 0.0932\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30070, Loss_data: 0.0082, Loss_ode: 0.0954\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30080, Loss_data: 0.0082, Loss_ode: 0.0935\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30090, Loss_data: 0.0083, Loss_ode: 0.0919\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30100, Loss_data: 0.0083, Loss_ode: 0.0939\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30110, Loss_data: 0.0082, Loss_ode: 0.0939\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30120, Loss_data: 0.0082, Loss_ode: 0.0962\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30130, Loss_data: 0.0083, Loss_ode: 0.0929\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30140, Loss_data: 0.0082, Loss_ode: 0.0934\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30150, Loss_data: 0.0082, Loss_ode: 0.0925\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30160, Loss_data: 0.0082, Loss_ode: 0.0907\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30170, Loss_data: 0.0083, Loss_ode: 0.0921\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30180, Loss_data: 0.0083, Loss_ode: 0.0918\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30190, Loss_data: 0.0083, Loss_ode: 0.0945\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30200, Loss_data: 0.0082, Loss_ode: 0.0946\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30210, Loss_data: 0.0083, Loss_ode: 0.0938\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30220, Loss_data: 0.0082, Loss_ode: 0.0966\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30230, Loss_data: 0.0083, Loss_ode: 0.0913\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30240, Loss_data: 0.0083, Loss_ode: 0.0933\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30250, Loss_data: 0.0082, Loss_ode: 0.0930\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30260, Loss_data: 0.0083, Loss_ode: 0.0943\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30270, Loss_data: 0.0082, Loss_ode: 0.0915\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30280, Loss_data: 0.0083, Loss_ode: 0.0928\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30290, Loss_data: 0.0082, Loss_ode: 0.0943\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30300, Loss_data: 0.0082, Loss_ode: 0.0911\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30310, Loss_data: 0.0082, Loss_ode: 0.0946\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30320, Loss_data: 0.0083, Loss_ode: 0.0941\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30330, Loss_data: 0.0083, Loss_ode: 0.0899\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30340, Loss_data: 0.0082, Loss_ode: 0.0921\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30350, Loss_data: 0.0082, Loss_ode: 0.0943\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30360, Loss_data: 0.0083, Loss_ode: 0.0955\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30370, Loss_data: 0.0082, Loss_ode: 0.0916\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30380, Loss_data: 0.0083, Loss_ode: 0.0919\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30390, Loss_data: 0.0082, Loss_ode: 0.0917\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30400, Loss_data: 0.0083, Loss_ode: 0.0916\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30410, Loss_data: 0.0082, Loss_ode: 0.0932\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30420, Loss_data: 0.0081, Loss_ode: 0.0938\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30430, Loss_data: 0.0082, Loss_ode: 0.0948\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30440, Loss_data: 0.0083, Loss_ode: 0.0904\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30450, Loss_data: 0.0083, Loss_ode: 0.0927\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30460, Loss_data: 0.0083, Loss_ode: 0.0963\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30470, Loss_data: 0.0082, Loss_ode: 0.0911\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30480, Loss_data: 0.0082, Loss_ode: 0.0912\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30490, Loss_data: 0.0082, Loss_ode: 0.0923\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30500, Loss_data: 0.0083, Loss_ode: 0.0943\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30510, Loss_data: 0.0083, Loss_ode: 0.0917\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30520, Loss_data: 0.0083, Loss_ode: 0.0956\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30530, Loss_data: 0.0082, Loss_ode: 0.0935\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30540, Loss_data: 0.0083, Loss_ode: 0.0914\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30550, Loss_data: 0.0082, Loss_ode: 0.0901\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30560, Loss_data: 0.0082, Loss_ode: 0.0901\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30570, Loss_data: 0.0082, Loss_ode: 0.0917\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30580, Loss_data: 0.0083, Loss_ode: 0.0923\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30590, Loss_data: 0.0082, Loss_ode: 0.0925\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30600, Loss_data: 0.0082, Loss_ode: 0.0910\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30610, Loss_data: 0.0082, Loss_ode: 0.0919\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30620, Loss_data: 0.0082, Loss_ode: 0.0901\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30630, Loss_data: 0.0082, Loss_ode: 0.0923\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30640, Loss_data: 0.0082, Loss_ode: 0.0932\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30650, Loss_data: 0.0082, Loss_ode: 0.0905\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30660, Loss_data: 0.0083, Loss_ode: 0.0907\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30670, Loss_data: 0.0082, Loss_ode: 0.0926\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30680, Loss_data: 0.0082, Loss_ode: 0.0934\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30690, Loss_data: 0.0083, Loss_ode: 0.0932\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30700, Loss_data: 0.0082, Loss_ode: 0.0918\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30710, Loss_data: 0.0083, Loss_ode: 0.0934\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30720, Loss_data: 0.0083, Loss_ode: 0.0897\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30730, Loss_data: 0.0082, Loss_ode: 0.0924\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30740, Loss_data: 0.0083, Loss_ode: 0.0920\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30750, Loss_data: 0.0082, Loss_ode: 0.0911\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30760, Loss_data: 0.0082, Loss_ode: 0.0891\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30770, Loss_data: 0.0083, Loss_ode: 0.0921\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30780, Loss_data: 0.0082, Loss_ode: 0.0904\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30790, Loss_data: 0.0082, Loss_ode: 0.0905\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30800, Loss_data: 0.0083, Loss_ode: 0.0919\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30810, Loss_data: 0.0082, Loss_ode: 0.0901\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30820, Loss_data: 0.0082, Loss_ode: 0.0891\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30830, Loss_data: 0.0083, Loss_ode: 0.0904\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30840, Loss_data: 0.0082, Loss_ode: 0.0916\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30850, Loss_data: 0.0083, Loss_ode: 0.0918\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30860, Loss_data: 0.0082, Loss_ode: 0.0902\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30870, Loss_data: 0.0083, Loss_ode: 0.0893\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30880, Loss_data: 0.0083, Loss_ode: 0.0910\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30890, Loss_data: 0.0082, Loss_ode: 0.0890\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30900, Loss_data: 0.0083, Loss_ode: 0.0901\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30910, Loss_data: 0.0082, Loss_ode: 0.0901\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30920, Loss_data: 0.0083, Loss_ode: 0.0899\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30930, Loss_data: 0.0083, Loss_ode: 0.0907\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30940, Loss_data: 0.0083, Loss_ode: 0.0937\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30950, Loss_data: 0.0083, Loss_ode: 0.0878\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30960, Loss_data: 0.0082, Loss_ode: 0.0891\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30970, Loss_data: 0.0083, Loss_ode: 0.0900\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30980, Loss_data: 0.0082, Loss_ode: 0.0880\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30990, Loss_data: 0.0083, Loss_ode: 0.0909\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31000, Loss_data: 0.0083, Loss_ode: 0.0912\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31010, Loss_data: 0.0083, Loss_ode: 0.0879\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31020, Loss_data: 0.0082, Loss_ode: 0.0914\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31030, Loss_data: 0.0083, Loss_ode: 0.0898\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31040, Loss_data: 0.0082, Loss_ode: 0.0916\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31050, Loss_data: 0.0082, Loss_ode: 0.0947\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31060, Loss_data: 0.0083, Loss_ode: 0.0880\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31070, Loss_data: 0.0082, Loss_ode: 0.0904\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31080, Loss_data: 0.0082, Loss_ode: 0.0900\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31090, Loss_data: 0.0082, Loss_ode: 0.0867\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31100, Loss_data: 0.0083, Loss_ode: 0.0905\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31110, Loss_data: 0.0082, Loss_ode: 0.0872\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31120, Loss_data: 0.0082, Loss_ode: 0.0876\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31130, Loss_data: 0.0082, Loss_ode: 0.0880\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31140, Loss_data: 0.0082, Loss_ode: 0.0891\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31150, Loss_data: 0.0082, Loss_ode: 0.0903\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31160, Loss_data: 0.0083, Loss_ode: 0.0885\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31170, Loss_data: 0.0082, Loss_ode: 0.0877\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31180, Loss_data: 0.0082, Loss_ode: 0.0891\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31190, Loss_data: 0.0083, Loss_ode: 0.0883\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31200, Loss_data: 0.0083, Loss_ode: 0.0877\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31210, Loss_data: 0.0083, Loss_ode: 0.0885\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31220, Loss_data: 0.0082, Loss_ode: 0.0896\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31230, Loss_data: 0.0082, Loss_ode: 0.0891\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31240, Loss_data: 0.0082, Loss_ode: 0.0896\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31250, Loss_data: 0.0082, Loss_ode: 0.0900\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31260, Loss_data: 0.0083, Loss_ode: 0.0887\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31270, Loss_data: 0.0082, Loss_ode: 0.0871\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31280, Loss_data: 0.0082, Loss_ode: 0.0879\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31290, Loss_data: 0.0083, Loss_ode: 0.0882\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31300, Loss_data: 0.0083, Loss_ode: 0.0877\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31310, Loss_data: 0.0082, Loss_ode: 0.0897\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31320, Loss_data: 0.0083, Loss_ode: 0.0887\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31330, Loss_data: 0.0082, Loss_ode: 0.0879\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31340, Loss_data: 0.0082, Loss_ode: 0.0896\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31350, Loss_data: 0.0082, Loss_ode: 0.0899\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31360, Loss_data: 0.0082, Loss_ode: 0.0898\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31370, Loss_data: 0.0083, Loss_ode: 0.0901\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31380, Loss_data: 0.0083, Loss_ode: 0.0881\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31390, Loss_data: 0.0083, Loss_ode: 0.0875\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31400, Loss_data: 0.0082, Loss_ode: 0.0916\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31410, Loss_data: 0.0083, Loss_ode: 0.0882\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31420, Loss_data: 0.0083, Loss_ode: 0.0876\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31430, Loss_data: 0.0082, Loss_ode: 0.0862\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31440, Loss_data: 0.0082, Loss_ode: 0.0875\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31450, Loss_data: 0.0082, Loss_ode: 0.0869\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31460, Loss_data: 0.0083, Loss_ode: 0.0897\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31470, Loss_data: 0.0082, Loss_ode: 0.0884\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31480, Loss_data: 0.0082, Loss_ode: 0.0883\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31490, Loss_data: 0.0083, Loss_ode: 0.0876\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31500, Loss_data: 0.0083, Loss_ode: 0.0892\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31510, Loss_data: 0.0083, Loss_ode: 0.0906\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31520, Loss_data: 0.0083, Loss_ode: 0.0898\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31530, Loss_data: 0.0082, Loss_ode: 0.0881\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31540, Loss_data: 0.0083, Loss_ode: 0.0888\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31550, Loss_data: 0.0082, Loss_ode: 0.0877\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31560, Loss_data: 0.0083, Loss_ode: 0.0881\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31570, Loss_data: 0.0082, Loss_ode: 0.0850\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31580, Loss_data: 0.0083, Loss_ode: 0.0877\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31590, Loss_data: 0.0082, Loss_ode: 0.0837\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31600, Loss_data: 0.0082, Loss_ode: 0.0894\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31610, Loss_data: 0.0083, Loss_ode: 0.0885\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31620, Loss_data: 0.0083, Loss_ode: 0.0872\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31630, Loss_data: 0.0083, Loss_ode: 0.0860\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31640, Loss_data: 0.0082, Loss_ode: 0.0886\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31650, Loss_data: 0.0083, Loss_ode: 0.0850\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31660, Loss_data: 0.0082, Loss_ode: 0.0853\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31670, Loss_data: 0.0082, Loss_ode: 0.0863\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31680, Loss_data: 0.0082, Loss_ode: 0.0881\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31690, Loss_data: 0.0082, Loss_ode: 0.0868\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31700, Loss_data: 0.0083, Loss_ode: 0.0862\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31710, Loss_data: 0.0082, Loss_ode: 0.0849\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31720, Loss_data: 0.0082, Loss_ode: 0.0864\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31730, Loss_data: 0.0082, Loss_ode: 0.0863\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31740, Loss_data: 0.0083, Loss_ode: 0.0866\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31750, Loss_data: 0.0083, Loss_ode: 0.0863\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31760, Loss_data: 0.0083, Loss_ode: 0.0880\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31770, Loss_data: 0.0082, Loss_ode: 0.0867\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31780, Loss_data: 0.0082, Loss_ode: 0.0897\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31790, Loss_data: 0.0082, Loss_ode: 0.0893\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31800, Loss_data: 0.0083, Loss_ode: 0.0858\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31810, Loss_data: 0.0083, Loss_ode: 0.0825\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31820, Loss_data: 0.0082, Loss_ode: 0.0852\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31830, Loss_data: 0.0083, Loss_ode: 0.0844\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31840, Loss_data: 0.0083, Loss_ode: 0.0830\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31850, Loss_data: 0.0083, Loss_ode: 0.0855\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31860, Loss_data: 0.0083, Loss_ode: 0.0858\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31870, Loss_data: 0.0082, Loss_ode: 0.0849\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31880, Loss_data: 0.0082, Loss_ode: 0.0845\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31890, Loss_data: 0.0083, Loss_ode: 0.0855\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31900, Loss_data: 0.0082, Loss_ode: 0.0850\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31910, Loss_data: 0.0082, Loss_ode: 0.0839\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31920, Loss_data: 0.0083, Loss_ode: 0.0888\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31930, Loss_data: 0.0083, Loss_ode: 0.0871\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31940, Loss_data: 0.0083, Loss_ode: 0.0841\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31950, Loss_data: 0.0083, Loss_ode: 0.0875\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31960, Loss_data: 0.0082, Loss_ode: 0.0885\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31970, Loss_data: 0.0083, Loss_ode: 0.0851\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31980, Loss_data: 0.0082, Loss_ode: 0.0853\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31990, Loss_data: 0.0083, Loss_ode: 0.0856\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32000, Loss_data: 0.0082, Loss_ode: 0.0848\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32010, Loss_data: 0.0083, Loss_ode: 0.0833\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32020, Loss_data: 0.0082, Loss_ode: 0.0850\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32030, Loss_data: 0.0083, Loss_ode: 0.0849\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32040, Loss_data: 0.0083, Loss_ode: 0.0858\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32050, Loss_data: 0.0082, Loss_ode: 0.0842\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32060, Loss_data: 0.0083, Loss_ode: 0.0852\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32070, Loss_data: 0.0083, Loss_ode: 0.0850\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32080, Loss_data: 0.0083, Loss_ode: 0.0824\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32090, Loss_data: 0.0083, Loss_ode: 0.0838\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32100, Loss_data: 0.0083, Loss_ode: 0.0855\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32110, Loss_data: 0.0082, Loss_ode: 0.0864\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32120, Loss_data: 0.0083, Loss_ode: 0.0831\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32130, Loss_data: 0.0082, Loss_ode: 0.0852\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32140, Loss_data: 0.0083, Loss_ode: 0.0844\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32150, Loss_data: 0.0083, Loss_ode: 0.0853\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32160, Loss_data: 0.0083, Loss_ode: 0.0838\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32170, Loss_data: 0.0083, Loss_ode: 0.0832\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32180, Loss_data: 0.0082, Loss_ode: 0.0860\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32190, Loss_data: 0.0083, Loss_ode: 0.0837\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32200, Loss_data: 0.0082, Loss_ode: 0.0846\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32210, Loss_data: 0.0082, Loss_ode: 0.0858\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32220, Loss_data: 0.0082, Loss_ode: 0.0839\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32230, Loss_data: 0.0083, Loss_ode: 0.0852\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32240, Loss_data: 0.0082, Loss_ode: 0.0854\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32250, Loss_data: 0.0082, Loss_ode: 0.0870\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32260, Loss_data: 0.0082, Loss_ode: 0.0852\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32270, Loss_data: 0.0082, Loss_ode: 0.0831\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32280, Loss_data: 0.0083, Loss_ode: 0.0834\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32290, Loss_data: 0.0082, Loss_ode: 0.0831\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32300, Loss_data: 0.0082, Loss_ode: 0.0840\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32310, Loss_data: 0.0083, Loss_ode: 0.0840\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32320, Loss_data: 0.0082, Loss_ode: 0.0826\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32330, Loss_data: 0.0083, Loss_ode: 0.0830\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32340, Loss_data: 0.0082, Loss_ode: 0.0841\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32350, Loss_data: 0.0083, Loss_ode: 0.0836\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32360, Loss_data: 0.0083, Loss_ode: 0.0829\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32370, Loss_data: 0.0083, Loss_ode: 0.0802\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32380, Loss_data: 0.0083, Loss_ode: 0.0867\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32390, Loss_data: 0.0082, Loss_ode: 0.0859\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32400, Loss_data: 0.0083, Loss_ode: 0.0858\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32410, Loss_data: 0.0082, Loss_ode: 0.0843\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32420, Loss_data: 0.0083, Loss_ode: 0.0835\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32430, Loss_data: 0.0082, Loss_ode: 0.0814\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32440, Loss_data: 0.0082, Loss_ode: 0.0821\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32450, Loss_data: 0.0082, Loss_ode: 0.0858\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32460, Loss_data: 0.0082, Loss_ode: 0.0833\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32470, Loss_data: 0.0083, Loss_ode: 0.0810\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32480, Loss_data: 0.0083, Loss_ode: 0.0830\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32490, Loss_data: 0.0083, Loss_ode: 0.0821\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32500, Loss_data: 0.0083, Loss_ode: 0.0837\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32510, Loss_data: 0.0083, Loss_ode: 0.0816\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32520, Loss_data: 0.0082, Loss_ode: 0.0810\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32530, Loss_data: 0.0082, Loss_ode: 0.0833\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32540, Loss_data: 0.0083, Loss_ode: 0.0821\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32550, Loss_data: 0.0082, Loss_ode: 0.0846\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32560, Loss_data: 0.0082, Loss_ode: 0.0832\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32570, Loss_data: 0.0083, Loss_ode: 0.0850\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32580, Loss_data: 0.0082, Loss_ode: 0.0823\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32590, Loss_data: 0.0083, Loss_ode: 0.0819\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32600, Loss_data: 0.0083, Loss_ode: 0.0820\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32610, Loss_data: 0.0082, Loss_ode: 0.0834\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32620, Loss_data: 0.0082, Loss_ode: 0.0812\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32630, Loss_data: 0.0082, Loss_ode: 0.0846\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32640, Loss_data: 0.0083, Loss_ode: 0.0830\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32650, Loss_data: 0.0083, Loss_ode: 0.0829\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32660, Loss_data: 0.0083, Loss_ode: 0.0832\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32670, Loss_data: 0.0083, Loss_ode: 0.0816\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32680, Loss_data: 0.0083, Loss_ode: 0.0838\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32690, Loss_data: 0.0083, Loss_ode: 0.0804\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32700, Loss_data: 0.0082, Loss_ode: 0.0849\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32710, Loss_data: 0.0083, Loss_ode: 0.0851\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32720, Loss_data: 0.0083, Loss_ode: 0.0832\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32730, Loss_data: 0.0082, Loss_ode: 0.0824\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32740, Loss_data: 0.0083, Loss_ode: 0.0831\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32750, Loss_data: 0.0082, Loss_ode: 0.0807\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32760, Loss_data: 0.0082, Loss_ode: 0.0824\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32770, Loss_data: 0.0082, Loss_ode: 0.0802\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32780, Loss_data: 0.0082, Loss_ode: 0.0825\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32790, Loss_data: 0.0083, Loss_ode: 0.0817\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32800, Loss_data: 0.0083, Loss_ode: 0.0854\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32810, Loss_data: 0.0083, Loss_ode: 0.0824\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32820, Loss_data: 0.0082, Loss_ode: 0.0795\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32830, Loss_data: 0.0083, Loss_ode: 0.0814\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32840, Loss_data: 0.0082, Loss_ode: 0.0814\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32850, Loss_data: 0.0083, Loss_ode: 0.0815\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32860, Loss_data: 0.0083, Loss_ode: 0.0810\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32870, Loss_data: 0.0082, Loss_ode: 0.0808\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32880, Loss_data: 0.0083, Loss_ode: 0.0807\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32890, Loss_data: 0.0083, Loss_ode: 0.0822\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32900, Loss_data: 0.0082, Loss_ode: 0.0804\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32910, Loss_data: 0.0082, Loss_ode: 0.0791\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32920, Loss_data: 0.0083, Loss_ode: 0.0828\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32930, Loss_data: 0.0083, Loss_ode: 0.0794\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32940, Loss_data: 0.0082, Loss_ode: 0.0797\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32950, Loss_data: 0.0082, Loss_ode: 0.0811\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32960, Loss_data: 0.0083, Loss_ode: 0.0810\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32970, Loss_data: 0.0083, Loss_ode: 0.0802\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32980, Loss_data: 0.0083, Loss_ode: 0.0824\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32990, Loss_data: 0.0082, Loss_ode: 0.0827\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33000, Loss_data: 0.0083, Loss_ode: 0.0817\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33010, Loss_data: 0.0083, Loss_ode: 0.0829\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33020, Loss_data: 0.0083, Loss_ode: 0.0844\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33030, Loss_data: 0.0083, Loss_ode: 0.0793\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33040, Loss_data: 0.0082, Loss_ode: 0.0818\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33050, Loss_data: 0.0083, Loss_ode: 0.0798\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33060, Loss_data: 0.0082, Loss_ode: 0.0811\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33070, Loss_data: 0.0083, Loss_ode: 0.0820\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33080, Loss_data: 0.0083, Loss_ode: 0.0824\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33090, Loss_data: 0.0083, Loss_ode: 0.0817\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33100, Loss_data: 0.0083, Loss_ode: 0.0805\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33110, Loss_data: 0.0082, Loss_ode: 0.0813\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33120, Loss_data: 0.0082, Loss_ode: 0.0787\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33130, Loss_data: 0.0082, Loss_ode: 0.0819\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33140, Loss_data: 0.0083, Loss_ode: 0.0815\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33150, Loss_data: 0.0082, Loss_ode: 0.0813\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33160, Loss_data: 0.0082, Loss_ode: 0.0804\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33170, Loss_data: 0.0083, Loss_ode: 0.0823\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33180, Loss_data: 0.0083, Loss_ode: 0.0823\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33190, Loss_data: 0.0083, Loss_ode: 0.0822\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33200, Loss_data: 0.0082, Loss_ode: 0.0798\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33210, Loss_data: 0.0083, Loss_ode: 0.0810\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33220, Loss_data: 0.0083, Loss_ode: 0.0823\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33230, Loss_data: 0.0083, Loss_ode: 0.0815\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33240, Loss_data: 0.0082, Loss_ode: 0.0808\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33250, Loss_data: 0.0083, Loss_ode: 0.0789\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33260, Loss_data: 0.0082, Loss_ode: 0.0790\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33270, Loss_data: 0.0082, Loss_ode: 0.0790\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33280, Loss_data: 0.0083, Loss_ode: 0.0779\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33290, Loss_data: 0.0082, Loss_ode: 0.0790\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33300, Loss_data: 0.0082, Loss_ode: 0.0808\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33310, Loss_data: 0.0083, Loss_ode: 0.0822\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33320, Loss_data: 0.0082, Loss_ode: 0.0801\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33330, Loss_data: 0.0082, Loss_ode: 0.0797\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33340, Loss_data: 0.0083, Loss_ode: 0.0809\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33350, Loss_data: 0.0083, Loss_ode: 0.0786\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33360, Loss_data: 0.0082, Loss_ode: 0.0807\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33370, Loss_data: 0.0082, Loss_ode: 0.0798\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33380, Loss_data: 0.0083, Loss_ode: 0.0817\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33390, Loss_data: 0.0082, Loss_ode: 0.0797\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33400, Loss_data: 0.0082, Loss_ode: 0.0789\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33410, Loss_data: 0.0082, Loss_ode: 0.0800\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33420, Loss_data: 0.0083, Loss_ode: 0.0815\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33430, Loss_data: 0.0083, Loss_ode: 0.0788\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33440, Loss_data: 0.0083, Loss_ode: 0.0818\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33450, Loss_data: 0.0083, Loss_ode: 0.0794\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33460, Loss_data: 0.0082, Loss_ode: 0.0820\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33470, Loss_data: 0.0082, Loss_ode: 0.0803\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33480, Loss_data: 0.0083, Loss_ode: 0.0808\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33490, Loss_data: 0.0082, Loss_ode: 0.0788\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33500, Loss_data: 0.0082, Loss_ode: 0.0802\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33510, Loss_data: 0.0082, Loss_ode: 0.0781\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33520, Loss_data: 0.0083, Loss_ode: 0.0783\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33530, Loss_data: 0.0083, Loss_ode: 0.0784\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33540, Loss_data: 0.0082, Loss_ode: 0.0792\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33550, Loss_data: 0.0083, Loss_ode: 0.0798\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33560, Loss_data: 0.0082, Loss_ode: 0.0789\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33570, Loss_data: 0.0083, Loss_ode: 0.0802\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33580, Loss_data: 0.0082, Loss_ode: 0.0807\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33590, Loss_data: 0.0082, Loss_ode: 0.0805\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33600, Loss_data: 0.0082, Loss_ode: 0.0765\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33610, Loss_data: 0.0082, Loss_ode: 0.0791\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33620, Loss_data: 0.0082, Loss_ode: 0.0784\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33630, Loss_data: 0.0083, Loss_ode: 0.0791\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33640, Loss_data: 0.0082, Loss_ode: 0.0777\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33650, Loss_data: 0.0082, Loss_ode: 0.0805\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33660, Loss_data: 0.0082, Loss_ode: 0.0806\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33670, Loss_data: 0.0082, Loss_ode: 0.0786\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33680, Loss_data: 0.0082, Loss_ode: 0.0811\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33690, Loss_data: 0.0083, Loss_ode: 0.0797\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33700, Loss_data: 0.0082, Loss_ode: 0.0792\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33710, Loss_data: 0.0082, Loss_ode: 0.0772\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33720, Loss_data: 0.0082, Loss_ode: 0.0788\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33730, Loss_data: 0.0082, Loss_ode: 0.0793\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33740, Loss_data: 0.0082, Loss_ode: 0.0796\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33750, Loss_data: 0.0083, Loss_ode: 0.0769\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33760, Loss_data: 0.0082, Loss_ode: 0.0789\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33770, Loss_data: 0.0083, Loss_ode: 0.0771\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33780, Loss_data: 0.0082, Loss_ode: 0.0792\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33790, Loss_data: 0.0082, Loss_ode: 0.0789\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33800, Loss_data: 0.0082, Loss_ode: 0.0791\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33810, Loss_data: 0.0082, Loss_ode: 0.0793\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33820, Loss_data: 0.0082, Loss_ode: 0.0783\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33830, Loss_data: 0.0082, Loss_ode: 0.0781\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33840, Loss_data: 0.0082, Loss_ode: 0.0779\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33850, Loss_data: 0.0082, Loss_ode: 0.0811\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33860, Loss_data: 0.0083, Loss_ode: 0.0793\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33870, Loss_data: 0.0082, Loss_ode: 0.0789\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33880, Loss_data: 0.0082, Loss_ode: 0.0764\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33890, Loss_data: 0.0082, Loss_ode: 0.0794\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33900, Loss_data: 0.0083, Loss_ode: 0.0795\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33910, Loss_data: 0.0082, Loss_ode: 0.0795\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33920, Loss_data: 0.0082, Loss_ode: 0.0758\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33930, Loss_data: 0.0083, Loss_ode: 0.0777\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33940, Loss_data: 0.0083, Loss_ode: 0.0779\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33950, Loss_data: 0.0083, Loss_ode: 0.0783\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33960, Loss_data: 0.0083, Loss_ode: 0.0773\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33970, Loss_data: 0.0082, Loss_ode: 0.0784\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33980, Loss_data: 0.0083, Loss_ode: 0.0765\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33990, Loss_data: 0.0082, Loss_ode: 0.0787\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34000, Loss_data: 0.0082, Loss_ode: 0.0771\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34010, Loss_data: 0.0083, Loss_ode: 0.0797\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34020, Loss_data: 0.0082, Loss_ode: 0.0775\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34030, Loss_data: 0.0083, Loss_ode: 0.0811\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34040, Loss_data: 0.0082, Loss_ode: 0.0750\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34050, Loss_data: 0.0083, Loss_ode: 0.0787\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34060, Loss_data: 0.0083, Loss_ode: 0.0768\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34070, Loss_data: 0.0082, Loss_ode: 0.0783\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34080, Loss_data: 0.0082, Loss_ode: 0.0776\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34090, Loss_data: 0.0083, Loss_ode: 0.0769\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34100, Loss_data: 0.0083, Loss_ode: 0.0788\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34110, Loss_data: 0.0083, Loss_ode: 0.0777\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34120, Loss_data: 0.0082, Loss_ode: 0.0762\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34130, Loss_data: 0.0082, Loss_ode: 0.0774\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34140, Loss_data: 0.0083, Loss_ode: 0.0778\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34150, Loss_data: 0.0082, Loss_ode: 0.0766\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34160, Loss_data: 0.0082, Loss_ode: 0.0780\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34170, Loss_data: 0.0082, Loss_ode: 0.0790\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34180, Loss_data: 0.0083, Loss_ode: 0.0770\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34190, Loss_data: 0.0082, Loss_ode: 0.0804\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34200, Loss_data: 0.0082, Loss_ode: 0.0777\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34210, Loss_data: 0.0083, Loss_ode: 0.0752\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34220, Loss_data: 0.0082, Loss_ode: 0.0759\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34230, Loss_data: 0.0082, Loss_ode: 0.0785\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34240, Loss_data: 0.0082, Loss_ode: 0.0775\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34250, Loss_data: 0.0083, Loss_ode: 0.0762\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34260, Loss_data: 0.0083, Loss_ode: 0.0729\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34270, Loss_data: 0.0082, Loss_ode: 0.0770\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34280, Loss_data: 0.0083, Loss_ode: 0.0757\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34290, Loss_data: 0.0082, Loss_ode: 0.0736\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34300, Loss_data: 0.0083, Loss_ode: 0.0751\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34310, Loss_data: 0.0082, Loss_ode: 0.0766\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34320, Loss_data: 0.0083, Loss_ode: 0.0787\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34330, Loss_data: 0.0083, Loss_ode: 0.0773\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34340, Loss_data: 0.0082, Loss_ode: 0.0749\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34350, Loss_data: 0.0082, Loss_ode: 0.0755\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34360, Loss_data: 0.0082, Loss_ode: 0.0762\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34370, Loss_data: 0.0082, Loss_ode: 0.0757\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34380, Loss_data: 0.0082, Loss_ode: 0.0769\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34390, Loss_data: 0.0082, Loss_ode: 0.0757\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34400, Loss_data: 0.0082, Loss_ode: 0.0757\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34410, Loss_data: 0.0082, Loss_ode: 0.0763\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34420, Loss_data: 0.0082, Loss_ode: 0.0753\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34430, Loss_data: 0.0082, Loss_ode: 0.0762\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34440, Loss_data: 0.0082, Loss_ode: 0.0773\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34450, Loss_data: 0.0082, Loss_ode: 0.0765\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34460, Loss_data: 0.0082, Loss_ode: 0.0758\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34470, Loss_data: 0.0082, Loss_ode: 0.0774\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34480, Loss_data: 0.0083, Loss_ode: 0.0776\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34490, Loss_data: 0.0082, Loss_ode: 0.0760\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34500, Loss_data: 0.0083, Loss_ode: 0.0766\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34510, Loss_data: 0.0082, Loss_ode: 0.0767\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34520, Loss_data: 0.0082, Loss_ode: 0.0737\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34530, Loss_data: 0.0082, Loss_ode: 0.0735\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34540, Loss_data: 0.0082, Loss_ode: 0.0752\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34550, Loss_data: 0.0082, Loss_ode: 0.0781\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34560, Loss_data: 0.0083, Loss_ode: 0.0799\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34570, Loss_data: 0.0083, Loss_ode: 0.0727\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34580, Loss_data: 0.0082, Loss_ode: 0.0762\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34590, Loss_data: 0.0082, Loss_ode: 0.0767\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34600, Loss_data: 0.0082, Loss_ode: 0.0747\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34610, Loss_data: 0.0083, Loss_ode: 0.0767\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34620, Loss_data: 0.0083, Loss_ode: 0.0777\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34630, Loss_data: 0.0083, Loss_ode: 0.0768\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34640, Loss_data: 0.0083, Loss_ode: 0.0760\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34650, Loss_data: 0.0083, Loss_ode: 0.0758\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34660, Loss_data: 0.0082, Loss_ode: 0.0752\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34670, Loss_data: 0.0082, Loss_ode: 0.0759\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34680, Loss_data: 0.0082, Loss_ode: 0.0754\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34690, Loss_data: 0.0082, Loss_ode: 0.0735\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34700, Loss_data: 0.0082, Loss_ode: 0.0763\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34710, Loss_data: 0.0082, Loss_ode: 0.0749\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34720, Loss_data: 0.0082, Loss_ode: 0.0763\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34730, Loss_data: 0.0083, Loss_ode: 0.0726\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34740, Loss_data: 0.0082, Loss_ode: 0.0757\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34750, Loss_data: 0.0082, Loss_ode: 0.0754\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34760, Loss_data: 0.0083, Loss_ode: 0.0748\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34770, Loss_data: 0.0083, Loss_ode: 0.0756\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34780, Loss_data: 0.0082, Loss_ode: 0.0749\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34790, Loss_data: 0.0083, Loss_ode: 0.0721\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34800, Loss_data: 0.0083, Loss_ode: 0.0777\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34810, Loss_data: 0.0083, Loss_ode: 0.0756\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34820, Loss_data: 0.0082, Loss_ode: 0.0758\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34830, Loss_data: 0.0082, Loss_ode: 0.0764\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34840, Loss_data: 0.0082, Loss_ode: 0.0741\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34850, Loss_data: 0.0082, Loss_ode: 0.0752\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34860, Loss_data: 0.0082, Loss_ode: 0.0751\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34870, Loss_data: 0.0083, Loss_ode: 0.0746\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34880, Loss_data: 0.0082, Loss_ode: 0.0739\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34890, Loss_data: 0.0082, Loss_ode: 0.0761\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34900, Loss_data: 0.0082, Loss_ode: 0.0733\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34910, Loss_data: 0.0082, Loss_ode: 0.0736\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34920, Loss_data: 0.0082, Loss_ode: 0.0748\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34930, Loss_data: 0.0082, Loss_ode: 0.0747\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34940, Loss_data: 0.0083, Loss_ode: 0.0757\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34950, Loss_data: 0.0082, Loss_ode: 0.0738\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34960, Loss_data: 0.0083, Loss_ode: 0.0750\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34970, Loss_data: 0.0082, Loss_ode: 0.0765\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34980, Loss_data: 0.0082, Loss_ode: 0.0751\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34990, Loss_data: 0.0082, Loss_ode: 0.0760\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 35000, Loss_data: 0.0082, Loss_ode: 0.0745\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35010, Loss_data: 0.0082, Loss_ode: 0.0761\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35020, Loss_data: 0.0082, Loss_ode: 0.0752\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35030, Loss_data: 0.0083, Loss_ode: 0.0749\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35040, Loss_data: 0.0082, Loss_ode: 0.0728\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35050, Loss_data: 0.0082, Loss_ode: 0.0729\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35060, Loss_data: 0.0082, Loss_ode: 0.0739\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35070, Loss_data: 0.0082, Loss_ode: 0.0756\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35080, Loss_data: 0.0083, Loss_ode: 0.0747\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35090, Loss_data: 0.0082, Loss_ode: 0.0758\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35100, Loss_data: 0.0083, Loss_ode: 0.0732\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35110, Loss_data: 0.0082, Loss_ode: 0.0768\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35120, Loss_data: 0.0082, Loss_ode: 0.0749\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35130, Loss_data: 0.0082, Loss_ode: 0.0740\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35140, Loss_data: 0.0083, Loss_ode: 0.0739\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35150, Loss_data: 0.0082, Loss_ode: 0.0754\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35160, Loss_data: 0.0083, Loss_ode: 0.0720\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35170, Loss_data: 0.0082, Loss_ode: 0.0751\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35180, Loss_data: 0.0082, Loss_ode: 0.0734\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35190, Loss_data: 0.0083, Loss_ode: 0.0711\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35200, Loss_data: 0.0082, Loss_ode: 0.0752\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35210, Loss_data: 0.0082, Loss_ode: 0.0727\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35220, Loss_data: 0.0082, Loss_ode: 0.0735\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35230, Loss_data: 0.0082, Loss_ode: 0.0774\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35240, Loss_data: 0.0083, Loss_ode: 0.0753\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35250, Loss_data: 0.0082, Loss_ode: 0.0750\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35260, Loss_data: 0.0083, Loss_ode: 0.0759\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35270, Loss_data: 0.0083, Loss_ode: 0.0745\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35280, Loss_data: 0.0082, Loss_ode: 0.0724\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35290, Loss_data: 0.0082, Loss_ode: 0.0758\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35300, Loss_data: 0.0083, Loss_ode: 0.0749\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35310, Loss_data: 0.0082, Loss_ode: 0.0740\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35320, Loss_data: 0.0082, Loss_ode: 0.0767\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35330, Loss_data: 0.0082, Loss_ode: 0.0752\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35340, Loss_data: 0.0082, Loss_ode: 0.0731\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35350, Loss_data: 0.0082, Loss_ode: 0.0743\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35360, Loss_data: 0.0082, Loss_ode: 0.0731\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35370, Loss_data: 0.0082, Loss_ode: 0.0717\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35380, Loss_data: 0.0082, Loss_ode: 0.0774\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35390, Loss_data: 0.0082, Loss_ode: 0.0755\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35400, Loss_data: 0.0082, Loss_ode: 0.0736\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35410, Loss_data: 0.0082, Loss_ode: 0.0728\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35420, Loss_data: 0.0082, Loss_ode: 0.0719\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35430, Loss_data: 0.0082, Loss_ode: 0.0720\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35440, Loss_data: 0.0082, Loss_ode: 0.0752\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35450, Loss_data: 0.0083, Loss_ode: 0.0733\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35460, Loss_data: 0.0082, Loss_ode: 0.0735\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35470, Loss_data: 0.0082, Loss_ode: 0.0744\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35480, Loss_data: 0.0082, Loss_ode: 0.0726\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35490, Loss_data: 0.0082, Loss_ode: 0.0719\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35500, Loss_data: 0.0082, Loss_ode: 0.0716\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35510, Loss_data: 0.0082, Loss_ode: 0.0731\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35520, Loss_data: 0.0082, Loss_ode: 0.0735\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35530, Loss_data: 0.0082, Loss_ode: 0.0735\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35540, Loss_data: 0.0082, Loss_ode: 0.0745\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35550, Loss_data: 0.0082, Loss_ode: 0.0741\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35560, Loss_data: 0.0082, Loss_ode: 0.0763\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35570, Loss_data: 0.0082, Loss_ode: 0.0753\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35580, Loss_data: 0.0082, Loss_ode: 0.0729\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35590, Loss_data: 0.0082, Loss_ode: 0.0714\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35600, Loss_data: 0.0082, Loss_ode: 0.0706\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35610, Loss_data: 0.0082, Loss_ode: 0.0731\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35620, Loss_data: 0.0082, Loss_ode: 0.0737\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35630, Loss_data: 0.0082, Loss_ode: 0.0734\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35640, Loss_data: 0.0082, Loss_ode: 0.0715\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35650, Loss_data: 0.0083, Loss_ode: 0.0738\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35660, Loss_data: 0.0082, Loss_ode: 0.0705\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35670, Loss_data: 0.0082, Loss_ode: 0.0747\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35680, Loss_data: 0.0082, Loss_ode: 0.0755\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35690, Loss_data: 0.0082, Loss_ode: 0.0704\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35700, Loss_data: 0.0082, Loss_ode: 0.0733\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35710, Loss_data: 0.0082, Loss_ode: 0.0707\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35720, Loss_data: 0.0082, Loss_ode: 0.0731\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35730, Loss_data: 0.0082, Loss_ode: 0.0712\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35740, Loss_data: 0.0082, Loss_ode: 0.0733\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35750, Loss_data: 0.0082, Loss_ode: 0.0749\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35760, Loss_data: 0.0082, Loss_ode: 0.0722\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35770, Loss_data: 0.0082, Loss_ode: 0.0711\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35780, Loss_data: 0.0082, Loss_ode: 0.0724\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35790, Loss_data: 0.0082, Loss_ode: 0.0732\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35800, Loss_data: 0.0082, Loss_ode: 0.0744\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35810, Loss_data: 0.0082, Loss_ode: 0.0730\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35820, Loss_data: 0.0082, Loss_ode: 0.0724\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35830, Loss_data: 0.0083, Loss_ode: 0.0748\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35840, Loss_data: 0.0082, Loss_ode: 0.0722\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35850, Loss_data: 0.0082, Loss_ode: 0.0735\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35860, Loss_data: 0.0082, Loss_ode: 0.0726\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35870, Loss_data: 0.0082, Loss_ode: 0.0722\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35880, Loss_data: 0.0082, Loss_ode: 0.0724\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35890, Loss_data: 0.0082, Loss_ode: 0.0707\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35900, Loss_data: 0.0082, Loss_ode: 0.0697\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35910, Loss_data: 0.0082, Loss_ode: 0.0733\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35920, Loss_data: 0.0082, Loss_ode: 0.0689\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35930, Loss_data: 0.0082, Loss_ode: 0.0703\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35940, Loss_data: 0.0082, Loss_ode: 0.0699\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35950, Loss_data: 0.0082, Loss_ode: 0.0704\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35960, Loss_data: 0.0082, Loss_ode: 0.0714\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35970, Loss_data: 0.0082, Loss_ode: 0.0741\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35980, Loss_data: 0.0082, Loss_ode: 0.0696\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35990, Loss_data: 0.0082, Loss_ode: 0.0710\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36000, Loss_data: 0.0082, Loss_ode: 0.0731\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36010, Loss_data: 0.0083, Loss_ode: 0.0731\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36020, Loss_data: 0.0082, Loss_ode: 0.0742\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36030, Loss_data: 0.0082, Loss_ode: 0.0741\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36040, Loss_data: 0.0082, Loss_ode: 0.0713\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36050, Loss_data: 0.0082, Loss_ode: 0.0700\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36060, Loss_data: 0.0082, Loss_ode: 0.0729\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36070, Loss_data: 0.0082, Loss_ode: 0.0721\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36080, Loss_data: 0.0082, Loss_ode: 0.0728\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36090, Loss_data: 0.0082, Loss_ode: 0.0726\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36100, Loss_data: 0.0082, Loss_ode: 0.0717\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36110, Loss_data: 0.0082, Loss_ode: 0.0727\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36120, Loss_data: 0.0082, Loss_ode: 0.0729\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36130, Loss_data: 0.0082, Loss_ode: 0.0711\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36140, Loss_data: 0.0082, Loss_ode: 0.0718\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36150, Loss_data: 0.0082, Loss_ode: 0.0706\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36160, Loss_data: 0.0082, Loss_ode: 0.0694\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36170, Loss_data: 0.0082, Loss_ode: 0.0721\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36180, Loss_data: 0.0083, Loss_ode: 0.0738\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36190, Loss_data: 0.0082, Loss_ode: 0.0702\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36200, Loss_data: 0.0082, Loss_ode: 0.0711\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36210, Loss_data: 0.0082, Loss_ode: 0.0705\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36220, Loss_data: 0.0082, Loss_ode: 0.0687\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36230, Loss_data: 0.0082, Loss_ode: 0.0726\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36240, Loss_data: 0.0083, Loss_ode: 0.0730\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36250, Loss_data: 0.0082, Loss_ode: 0.0705\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36260, Loss_data: 0.0082, Loss_ode: 0.0720\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36270, Loss_data: 0.0082, Loss_ode: 0.0715\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36280, Loss_data: 0.0082, Loss_ode: 0.0711\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36290, Loss_data: 0.0082, Loss_ode: 0.0690\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36300, Loss_data: 0.0082, Loss_ode: 0.0700\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36310, Loss_data: 0.0083, Loss_ode: 0.0704\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36320, Loss_data: 0.0082, Loss_ode: 0.0743\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36330, Loss_data: 0.0082, Loss_ode: 0.0710\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36340, Loss_data: 0.0082, Loss_ode: 0.0706\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36350, Loss_data: 0.0082, Loss_ode: 0.0718\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36360, Loss_data: 0.0082, Loss_ode: 0.0692\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36370, Loss_data: 0.0082, Loss_ode: 0.0680\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36380, Loss_data: 0.0082, Loss_ode: 0.0726\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36390, Loss_data: 0.0082, Loss_ode: 0.0728\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36400, Loss_data: 0.0082, Loss_ode: 0.0708\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36410, Loss_data: 0.0082, Loss_ode: 0.0710\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36420, Loss_data: 0.0082, Loss_ode: 0.0697\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36430, Loss_data: 0.0082, Loss_ode: 0.0703\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36440, Loss_data: 0.0082, Loss_ode: 0.0720\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36450, Loss_data: 0.0082, Loss_ode: 0.0712\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36460, Loss_data: 0.0082, Loss_ode: 0.0689\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36470, Loss_data: 0.0082, Loss_ode: 0.0718\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36480, Loss_data: 0.0083, Loss_ode: 0.0691\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36490, Loss_data: 0.0082, Loss_ode: 0.0711\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36500, Loss_data: 0.0082, Loss_ode: 0.0721\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36510, Loss_data: 0.0082, Loss_ode: 0.0711\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36520, Loss_data: 0.0082, Loss_ode: 0.0696\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36530, Loss_data: 0.0082, Loss_ode: 0.0678\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36540, Loss_data: 0.0082, Loss_ode: 0.0709\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36550, Loss_data: 0.0082, Loss_ode: 0.0716\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36560, Loss_data: 0.0082, Loss_ode: 0.0727\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36570, Loss_data: 0.0082, Loss_ode: 0.0733\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36580, Loss_data: 0.0082, Loss_ode: 0.0706\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36590, Loss_data: 0.0082, Loss_ode: 0.0698\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36600, Loss_data: 0.0082, Loss_ode: 0.0692\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36610, Loss_data: 0.0082, Loss_ode: 0.0726\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36620, Loss_data: 0.0082, Loss_ode: 0.0682\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36630, Loss_data: 0.0082, Loss_ode: 0.0687\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36640, Loss_data: 0.0082, Loss_ode: 0.0677\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36650, Loss_data: 0.0082, Loss_ode: 0.0707\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36660, Loss_data: 0.0082, Loss_ode: 0.0693\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36670, Loss_data: 0.0082, Loss_ode: 0.0710\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36680, Loss_data: 0.0082, Loss_ode: 0.0689\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36690, Loss_data: 0.0082, Loss_ode: 0.0700\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36700, Loss_data: 0.0082, Loss_ode: 0.0717\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36710, Loss_data: 0.0082, Loss_ode: 0.0692\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36720, Loss_data: 0.0082, Loss_ode: 0.0709\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36730, Loss_data: 0.0082, Loss_ode: 0.0711\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36740, Loss_data: 0.0082, Loss_ode: 0.0728\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36750, Loss_data: 0.0082, Loss_ode: 0.0702\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36760, Loss_data: 0.0082, Loss_ode: 0.0697\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36770, Loss_data: 0.0082, Loss_ode: 0.0690\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36780, Loss_data: 0.0082, Loss_ode: 0.0705\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36790, Loss_data: 0.0082, Loss_ode: 0.0688\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36800, Loss_data: 0.0082, Loss_ode: 0.0701\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36810, Loss_data: 0.0082, Loss_ode: 0.0701\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36820, Loss_data: 0.0082, Loss_ode: 0.0686\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36830, Loss_data: 0.0082, Loss_ode: 0.0688\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36840, Loss_data: 0.0082, Loss_ode: 0.0712\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36850, Loss_data: 0.0082, Loss_ode: 0.0690\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36860, Loss_data: 0.0082, Loss_ode: 0.0682\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36870, Loss_data: 0.0082, Loss_ode: 0.0687\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36880, Loss_data: 0.0082, Loss_ode: 0.0687\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36890, Loss_data: 0.0082, Loss_ode: 0.0686\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36900, Loss_data: 0.0082, Loss_ode: 0.0695\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36910, Loss_data: 0.0082, Loss_ode: 0.0723\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36920, Loss_data: 0.0082, Loss_ode: 0.0690\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36930, Loss_data: 0.0082, Loss_ode: 0.0673\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36940, Loss_data: 0.0082, Loss_ode: 0.0710\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36950, Loss_data: 0.0082, Loss_ode: 0.0715\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36960, Loss_data: 0.0082, Loss_ode: 0.0676\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36970, Loss_data: 0.0082, Loss_ode: 0.0694\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36980, Loss_data: 0.0082, Loss_ode: 0.0692\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36990, Loss_data: 0.0082, Loss_ode: 0.0678\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37000, Loss_data: 0.0082, Loss_ode: 0.0704\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37010, Loss_data: 0.0082, Loss_ode: 0.0682\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37020, Loss_data: 0.0082, Loss_ode: 0.0692\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37030, Loss_data: 0.0082, Loss_ode: 0.0705\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37040, Loss_data: 0.0082, Loss_ode: 0.0705\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37050, Loss_data: 0.0082, Loss_ode: 0.0683\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37060, Loss_data: 0.0082, Loss_ode: 0.0711\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37070, Loss_data: 0.0082, Loss_ode: 0.0693\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37080, Loss_data: 0.0082, Loss_ode: 0.0696\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37090, Loss_data: 0.0082, Loss_ode: 0.0706\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37100, Loss_data: 0.0082, Loss_ode: 0.0715\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37110, Loss_data: 0.0082, Loss_ode: 0.0678\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37120, Loss_data: 0.0082, Loss_ode: 0.0697\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37130, Loss_data: 0.0082, Loss_ode: 0.0682\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37140, Loss_data: 0.0082, Loss_ode: 0.0698\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37150, Loss_data: 0.0082, Loss_ode: 0.0694\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37160, Loss_data: 0.0082, Loss_ode: 0.0670\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37170, Loss_data: 0.0082, Loss_ode: 0.0704\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37180, Loss_data: 0.0082, Loss_ode: 0.0670\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37190, Loss_data: 0.0082, Loss_ode: 0.0674\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37200, Loss_data: 0.0082, Loss_ode: 0.0687\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37210, Loss_data: 0.0082, Loss_ode: 0.0698\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37220, Loss_data: 0.0082, Loss_ode: 0.0664\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37230, Loss_data: 0.0082, Loss_ode: 0.0684\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37240, Loss_data: 0.0082, Loss_ode: 0.0682\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37250, Loss_data: 0.0082, Loss_ode: 0.0682\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37260, Loss_data: 0.0082, Loss_ode: 0.0714\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37270, Loss_data: 0.0083, Loss_ode: 0.0720\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37280, Loss_data: 0.0082, Loss_ode: 0.0674\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37290, Loss_data: 0.0082, Loss_ode: 0.0700\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37300, Loss_data: 0.0082, Loss_ode: 0.0686\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37310, Loss_data: 0.0082, Loss_ode: 0.0704\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37320, Loss_data: 0.0082, Loss_ode: 0.0711\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37330, Loss_data: 0.0082, Loss_ode: 0.0672\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37340, Loss_data: 0.0082, Loss_ode: 0.0686\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37350, Loss_data: 0.0082, Loss_ode: 0.0699\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37360, Loss_data: 0.0082, Loss_ode: 0.0683\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37370, Loss_data: 0.0082, Loss_ode: 0.0681\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37380, Loss_data: 0.0082, Loss_ode: 0.0668\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37390, Loss_data: 0.0082, Loss_ode: 0.0668\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37400, Loss_data: 0.0082, Loss_ode: 0.0680\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37410, Loss_data: 0.0082, Loss_ode: 0.0711\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37420, Loss_data: 0.0082, Loss_ode: 0.0664\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37430, Loss_data: 0.0082, Loss_ode: 0.0698\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37440, Loss_data: 0.0082, Loss_ode: 0.0688\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37450, Loss_data: 0.0082, Loss_ode: 0.0692\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37460, Loss_data: 0.0082, Loss_ode: 0.0689\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37470, Loss_data: 0.0082, Loss_ode: 0.0673\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37480, Loss_data: 0.0082, Loss_ode: 0.0685\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37490, Loss_data: 0.0082, Loss_ode: 0.0670\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 37500, Loss_data: 0.0082, Loss_ode: 0.0672\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37510, Loss_data: 0.0081, Loss_ode: 0.0697\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37520, Loss_data: 0.0082, Loss_ode: 0.0709\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37530, Loss_data: 0.0082, Loss_ode: 0.0682\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37540, Loss_data: 0.0082, Loss_ode: 0.0685\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37550, Loss_data: 0.0082, Loss_ode: 0.0684\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37560, Loss_data: 0.0082, Loss_ode: 0.0675\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37570, Loss_data: 0.0082, Loss_ode: 0.0670\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37580, Loss_data: 0.0082, Loss_ode: 0.0679\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37590, Loss_data: 0.0082, Loss_ode: 0.0680\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37600, Loss_data: 0.0082, Loss_ode: 0.0677\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37610, Loss_data: 0.0082, Loss_ode: 0.0676\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37620, Loss_data: 0.0082, Loss_ode: 0.0694\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37630, Loss_data: 0.0082, Loss_ode: 0.0676\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37640, Loss_data: 0.0082, Loss_ode: 0.0678\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37650, Loss_data: 0.0082, Loss_ode: 0.0675\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37660, Loss_data: 0.0082, Loss_ode: 0.0702\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37670, Loss_data: 0.0081, Loss_ode: 0.0682\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37680, Loss_data: 0.0082, Loss_ode: 0.0673\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37690, Loss_data: 0.0082, Loss_ode: 0.0654\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37700, Loss_data: 0.0082, Loss_ode: 0.0697\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37710, Loss_data: 0.0082, Loss_ode: 0.0674\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37720, Loss_data: 0.0082, Loss_ode: 0.0681\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37730, Loss_data: 0.0082, Loss_ode: 0.0682\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37740, Loss_data: 0.0082, Loss_ode: 0.0669\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37750, Loss_data: 0.0082, Loss_ode: 0.0669\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37760, Loss_data: 0.0082, Loss_ode: 0.0687\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37770, Loss_data: 0.0082, Loss_ode: 0.0668\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37780, Loss_data: 0.0082, Loss_ode: 0.0678\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37790, Loss_data: 0.0082, Loss_ode: 0.0683\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37800, Loss_data: 0.0082, Loss_ode: 0.0674\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37810, Loss_data: 0.0082, Loss_ode: 0.0687\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37820, Loss_data: 0.0082, Loss_ode: 0.0670\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37830, Loss_data: 0.0082, Loss_ode: 0.0680\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37840, Loss_data: 0.0082, Loss_ode: 0.0681\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37850, Loss_data: 0.0082, Loss_ode: 0.0671\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37860, Loss_data: 0.0082, Loss_ode: 0.0657\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37870, Loss_data: 0.0082, Loss_ode: 0.0668\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37880, Loss_data: 0.0082, Loss_ode: 0.0686\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37890, Loss_data: 0.0082, Loss_ode: 0.0658\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37900, Loss_data: 0.0081, Loss_ode: 0.0677\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37910, Loss_data: 0.0082, Loss_ode: 0.0660\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37920, Loss_data: 0.0082, Loss_ode: 0.0674\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37930, Loss_data: 0.0082, Loss_ode: 0.0676\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37940, Loss_data: 0.0082, Loss_ode: 0.0663\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37950, Loss_data: 0.0081, Loss_ode: 0.0689\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37960, Loss_data: 0.0082, Loss_ode: 0.0659\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37970, Loss_data: 0.0082, Loss_ode: 0.0688\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37980, Loss_data: 0.0082, Loss_ode: 0.0697\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 37990, Loss_data: 0.0082, Loss_ode: 0.0675\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38000, Loss_data: 0.0082, Loss_ode: 0.0666\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38010, Loss_data: 0.0082, Loss_ode: 0.0675\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38020, Loss_data: 0.0082, Loss_ode: 0.0675\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38030, Loss_data: 0.0082, Loss_ode: 0.0684\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38040, Loss_data: 0.0082, Loss_ode: 0.0670\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38050, Loss_data: 0.0082, Loss_ode: 0.0660\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38060, Loss_data: 0.0082, Loss_ode: 0.0664\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38070, Loss_data: 0.0082, Loss_ode: 0.0667\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38080, Loss_data: 0.0082, Loss_ode: 0.0689\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38090, Loss_data: 0.0082, Loss_ode: 0.0651\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38100, Loss_data: 0.0082, Loss_ode: 0.0620\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38110, Loss_data: 0.0082, Loss_ode: 0.0651\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38120, Loss_data: 0.0082, Loss_ode: 0.0662\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38130, Loss_data: 0.0082, Loss_ode: 0.0685\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38140, Loss_data: 0.0082, Loss_ode: 0.0662\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38150, Loss_data: 0.0082, Loss_ode: 0.0704\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38160, Loss_data: 0.0082, Loss_ode: 0.0669\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38170, Loss_data: 0.0082, Loss_ode: 0.0671\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38180, Loss_data: 0.0082, Loss_ode: 0.0669\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38190, Loss_data: 0.0082, Loss_ode: 0.0677\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38200, Loss_data: 0.0082, Loss_ode: 0.0655\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38210, Loss_data: 0.0082, Loss_ode: 0.0646\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38220, Loss_data: 0.0082, Loss_ode: 0.0689\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38230, Loss_data: 0.0082, Loss_ode: 0.0687\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38240, Loss_data: 0.0082, Loss_ode: 0.0660\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38250, Loss_data: 0.0082, Loss_ode: 0.0660\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38260, Loss_data: 0.0082, Loss_ode: 0.0666\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38270, Loss_data: 0.0082, Loss_ode: 0.0668\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38280, Loss_data: 0.0081, Loss_ode: 0.0645\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38290, Loss_data: 0.0082, Loss_ode: 0.0665\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38300, Loss_data: 0.0082, Loss_ode: 0.0689\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38310, Loss_data: 0.0082, Loss_ode: 0.0657\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38320, Loss_data: 0.0082, Loss_ode: 0.0705\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38330, Loss_data: 0.0082, Loss_ode: 0.0675\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38340, Loss_data: 0.0082, Loss_ode: 0.0659\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38350, Loss_data: 0.0082, Loss_ode: 0.0675\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38360, Loss_data: 0.0082, Loss_ode: 0.0689\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38370, Loss_data: 0.0082, Loss_ode: 0.0669\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38380, Loss_data: 0.0082, Loss_ode: 0.0691\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38390, Loss_data: 0.0082, Loss_ode: 0.0670\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38400, Loss_data: 0.0082, Loss_ode: 0.0674\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38410, Loss_data: 0.0082, Loss_ode: 0.0663\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38420, Loss_data: 0.0082, Loss_ode: 0.0667\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38430, Loss_data: 0.0082, Loss_ode: 0.0664\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38440, Loss_data: 0.0082, Loss_ode: 0.0676\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38450, Loss_data: 0.0082, Loss_ode: 0.0681\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38460, Loss_data: 0.0082, Loss_ode: 0.0696\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38470, Loss_data: 0.0082, Loss_ode: 0.0668\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38480, Loss_data: 0.0082, Loss_ode: 0.0647\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38490, Loss_data: 0.0082, Loss_ode: 0.0676\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38500, Loss_data: 0.0082, Loss_ode: 0.0653\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38510, Loss_data: 0.0082, Loss_ode: 0.0668\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38520, Loss_data: 0.0082, Loss_ode: 0.0668\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38530, Loss_data: 0.0082, Loss_ode: 0.0670\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38540, Loss_data: 0.0082, Loss_ode: 0.0660\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38550, Loss_data: 0.0082, Loss_ode: 0.0642\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38560, Loss_data: 0.0082, Loss_ode: 0.0668\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38570, Loss_data: 0.0082, Loss_ode: 0.0656\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38580, Loss_data: 0.0082, Loss_ode: 0.0679\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38590, Loss_data: 0.0082, Loss_ode: 0.0640\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38600, Loss_data: 0.0081, Loss_ode: 0.0676\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38610, Loss_data: 0.0082, Loss_ode: 0.0642\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38620, Loss_data: 0.0082, Loss_ode: 0.0663\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38630, Loss_data: 0.0082, Loss_ode: 0.0631\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38640, Loss_data: 0.0082, Loss_ode: 0.0675\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38650, Loss_data: 0.0082, Loss_ode: 0.0666\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38660, Loss_data: 0.0082, Loss_ode: 0.0645\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38670, Loss_data: 0.0081, Loss_ode: 0.0658\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38680, Loss_data: 0.0082, Loss_ode: 0.0657\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38690, Loss_data: 0.0082, Loss_ode: 0.0667\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38700, Loss_data: 0.0082, Loss_ode: 0.0663\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38710, Loss_data: 0.0082, Loss_ode: 0.0640\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38720, Loss_data: 0.0082, Loss_ode: 0.0667\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38730, Loss_data: 0.0082, Loss_ode: 0.0661\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38740, Loss_data: 0.0082, Loss_ode: 0.0670\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38750, Loss_data: 0.0082, Loss_ode: 0.0657\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38760, Loss_data: 0.0082, Loss_ode: 0.0651\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38770, Loss_data: 0.0082, Loss_ode: 0.0667\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38780, Loss_data: 0.0082, Loss_ode: 0.0641\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38790, Loss_data: 0.0082, Loss_ode: 0.0644\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38800, Loss_data: 0.0082, Loss_ode: 0.0651\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38810, Loss_data: 0.0082, Loss_ode: 0.0675\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38820, Loss_data: 0.0082, Loss_ode: 0.0648\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38830, Loss_data: 0.0082, Loss_ode: 0.0666\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38840, Loss_data: 0.0082, Loss_ode: 0.0652\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38850, Loss_data: 0.0082, Loss_ode: 0.0646\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38860, Loss_data: 0.0082, Loss_ode: 0.0674\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38870, Loss_data: 0.0082, Loss_ode: 0.0635\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38880, Loss_data: 0.0082, Loss_ode: 0.0652\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38890, Loss_data: 0.0082, Loss_ode: 0.0663\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38900, Loss_data: 0.0081, Loss_ode: 0.0665\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38910, Loss_data: 0.0082, Loss_ode: 0.0632\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38920, Loss_data: 0.0082, Loss_ode: 0.0645\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38930, Loss_data: 0.0082, Loss_ode: 0.0658\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38940, Loss_data: 0.0082, Loss_ode: 0.0641\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38950, Loss_data: 0.0082, Loss_ode: 0.0661\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38960, Loss_data: 0.0082, Loss_ode: 0.0658\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38970, Loss_data: 0.0082, Loss_ode: 0.0652\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38980, Loss_data: 0.0082, Loss_ode: 0.0636\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 38990, Loss_data: 0.0082, Loss_ode: 0.0656\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 39000, Loss_data: 0.0082, Loss_ode: 0.0647\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 39010, Loss_data: 0.0082, Loss_ode: 0.0625\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 39020, Loss_data: 0.0082, Loss_ode: 0.0664\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 39030, Loss_data: 0.0082, Loss_ode: 0.0645\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 39040, Loss_data: 0.0082, Loss_ode: 0.0657\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 39050, Loss_data: 0.0082, Loss_ode: 0.0668\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 39060, Loss_data: 0.0082, Loss_ode: 0.0676\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 39070, Loss_data: 0.0082, Loss_ode: 0.0659\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 39080, Loss_data: 0.0081, Loss_ode: 0.0652\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 39090, Loss_data: 0.0082, Loss_ode: 0.0661\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Epoch 39100, Loss_data: 0.0082, Loss_ode: 0.0663\n",
      "Current learning rate:  4.747561509942997e-07\n",
      "Early stopping at epoch 39100\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('pinc_trained_exp.pth'):\n",
    "    net = torch.load(\"pinc_trained_exp.pth\")\n",
    "    print('Model loaded')\n",
    "else:\n",
    "    # Train network\n",
    "    net = main(full_df, in_train, out_train, t_start, t_end, Sin, mumax, Ks, Yxs, verbose=10)\n",
    "    torch.save(net, \"pinc_trained_exp.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PINN(\n",
       "  (input): Linear(in_features=5, out_features=128, bias=True)\n",
       "  (fc1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (fc3): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (output): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained net\n",
    "net = torch.load(\"pinc_trained_exp_v1.pth\")\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from machinelearning_control_fedbatch import numpy_to_tensor\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "full_df['F'] = full_df['RTime'].apply(Fs)\n",
    "\n",
    "# T_s = full_df['RTime'].iloc[1]\n",
    "T_s = 0.5\n",
    "t_test = numpy_to_tensor(np.array([full_df[\"RTime\"].values]))\n",
    "X_test = numpy_to_tensor(np.array([full_df[\"Biomass\"].values]))\n",
    "S_test = numpy_to_tensor(np.array([full_df[\"Glucose\"].values]))\n",
    "V_test = numpy_to_tensor(np.array([full_df[\"V\"].values]))\n",
    "F_test = numpy_to_tensor(np.array([full_df[\"F\"].values]))\n",
    "u_test = torch.cat([t_test, X_test, S_test, F_test], dim=1)\n",
    "x_test = torch.cat([X_test, S_test], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = X_test[0]\n",
    "S_0 = S_test[0]\n",
    "V_0 = V_test[0]\n",
    "F_0 = F_test[0]\n",
    "\n",
    "X_preds = []\n",
    "S_preds = []\n",
    "V_preds = []\n",
    "\n",
    "for i in range(len(u_test)):\n",
    "    x_k = net.forward(torch.tensor([T_s, X_0, S_0, V_0, F_0], dtype=torch.float32).to(DEVICE))\n",
    "    X_0 = X_test[i]\n",
    "    S_0 = S_test[i]\n",
    "    V_0 = V_test[i]\n",
    "    F_0 = F_test[i]\n",
    "    X_preds.append(x_k[0].item())\n",
    "    S_preds.append(x_k[1].item())\n",
    "    V_preds.append(x_k[2].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test = t_test.detach().cpu().numpy()\n",
    "X_test = X_test.detach().cpu().numpy()\n",
    "S_test = S_test.detach().cpu().numpy()\n",
    "V_test = V_test.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(t_test, X_test, s=10, label=\"X\")\n",
    "plt.scatter(t_test, S_test, s=10, label=\"S\")\n",
    "\n",
    "plt.plot(t_test, X_preds, marker='x', label=\"X_pred\")\n",
    "plt.plot(t_test, S_preds, marker='x', label=\"S_pred\")\n",
    "\n",
    "# Add vertical lines for feed\n",
    "for i in range(len(feeds)):\n",
    "    plt.axvline(x=feeds[\"Time\"].iloc[i], color='b', alpha=0.2, linestyle='--')\n",
    "\n",
    "plt.xlabel(\"Time (h)\")\n",
    "plt.ylabel(\"Concentration (g/L)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
