{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from machinelearning_control_fedbatch import generate_dataset, main\n",
    "\n",
    "from src.utils import get_data_and_feed, plot_experiment\n",
    "\n",
    "FILENAME = '../data/data_processed.xlsx'\n",
    "EXPERIMENT = 'BR01'\n",
    "S_IN = 1.43 * 200\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (12, 8)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_df, feeds = get_data_and_feed(\n",
    "    file_name=FILENAME, experiment=EXPERIMENT, keep_only=\"FB\"\n",
    ")\n",
    "\n",
    "full_df['Biomass'].iloc[1] = 5.0\n",
    "# add new line to full_df\n",
    "new_row = pd.DataFrame([{\"Process\": \"FB\", \"RTime\": 5.85, \"V\": 1.56, \"Biomass\": 5.8, \"Glucose\": 0.013, \"Protein\": 0.0}])\n",
    "full_df = pd.concat([full_df, new_row], ignore_index=True)\n",
    "full_df.sort_values(by=\"RTime\", inplace=True)\n",
    "\n",
    "T_FB = full_df[\"RTime\"].iloc[0] # Time of fed-batch\n",
    "T_START = 0\n",
    "T_END = full_df[\"RTime\"].iloc[-1] - T_FB  # End of experiment\n",
    "\n",
    "# inlet flowrate\n",
    "def Fs(t):\n",
    "    if t <= 4.73 - T_FB:\n",
    "        return 0.017\n",
    "    elif t <= 7.33 - T_FB:\n",
    "        return 0.031\n",
    "    elif t <= 9.17 - T_FB:\n",
    "        return 0.060\n",
    "    elif t <= 9.78 - T_FB:\n",
    "        return 0.031\n",
    "    else:\n",
    "        return 0.017\n",
    "\n",
    "# Get initial volume\n",
    "V0 = full_df[\"V\"].iloc[0]\n",
    "\n",
    "# Normalize time\n",
    "full_df[\"RTime\"] = full_df[\"RTime\"] - T_FB\n",
    "feeds[\"Time\"] = feeds[\"Time\"] - T_FB\n",
    "\n",
    "print(f\"Dataset shape: {full_df.shape}\")\n",
    "\n",
    "plot_experiment(full_df, title='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RTime</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.270000</td>\n",
       "      <td>2.838333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biomass</th>\n",
       "      <td>4.163095</td>\n",
       "      <td>18.661905</td>\n",
       "      <td>11.069444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.009583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              min        max       mean\n",
       "RTime    0.000000   5.270000   2.838333\n",
       "Biomass  4.163095  18.661905  11.069444\n",
       "Glucose  0.000000   0.016000   0.009583"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df[['RTime', 'Biomass', 'Glucose']].describe().T[['min', 'max', 'mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (2500, 5)\n"
     ]
    }
   ],
   "source": [
    "# Get dataset (multiple initial conditions)\n",
    "in_train, out_train = generate_dataset(data=full_df, num_points=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_start = 0.0\n",
      "T_end = 5.27\n"
     ]
    }
   ],
   "source": [
    "# parameter values\n",
    "mumax = 0.7267     # 1/hour\n",
    "Ks = 0.1634          # g/liter\n",
    "Yxs = 0.3983         # g/g\n",
    "Sin = 1.43 * 200  # g/liter\n",
    "\n",
    "t_start = full_df['RTime'].iloc[0]\n",
    "t_end = full_df['RTime'].iloc[-1]\n",
    "T_s = 0.25 \n",
    "\n",
    "# initial conditions\n",
    "V0 = full_df['V'].iloc[0]\n",
    "S0 = full_df['Glucose'].iloc[0]\n",
    "X0 = full_df['Biomass'].iloc[0]\n",
    "\n",
    "print(f'T_start = {t_start}')\n",
    "print(f'T_end = {t_end}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss_data: 49.1045, Loss_ode: 17.5056\n",
      "Current learning rate:  0.0001\n",
      "Epoch 10, Loss_data: 28.7950, Loss_ode: 4.6480\n",
      "Current learning rate:  0.0001\n",
      "Epoch 20, Loss_data: 18.1722, Loss_ode: 5.0907\n",
      "Current learning rate:  0.0001\n",
      "Epoch 30, Loss_data: 15.5152, Loss_ode: 4.1854\n",
      "Current learning rate:  0.0001\n",
      "Epoch 40, Loss_data: 14.4584, Loss_ode: 4.0576\n",
      "Current learning rate:  0.0001\n",
      "Epoch 50, Loss_data: 13.7445, Loss_ode: 3.8812\n",
      "Current learning rate:  0.0001\n",
      "Epoch 60, Loss_data: 13.1865, Loss_ode: 3.8640\n",
      "Current learning rate:  0.0001\n",
      "Epoch 70, Loss_data: 12.7086, Loss_ode: 3.8655\n",
      "Current learning rate:  0.0001\n",
      "Epoch 80, Loss_data: 12.2761, Loss_ode: 3.8582\n",
      "Current learning rate:  0.0001\n",
      "Epoch 90, Loss_data: 11.8761, Loss_ode: 3.8804\n",
      "Current learning rate:  0.0001\n",
      "Epoch 100, Loss_data: 11.5034, Loss_ode: 3.8300\n",
      "Current learning rate:  0.0001\n",
      "Epoch 110, Loss_data: 11.1531, Loss_ode: 3.8271\n",
      "Current learning rate:  0.0001\n",
      "Epoch 120, Loss_data: 10.8234, Loss_ode: 3.8794\n",
      "Current learning rate:  0.0001\n",
      "Epoch 130, Loss_data: 10.5104, Loss_ode: 3.8230\n",
      "Current learning rate:  0.0001\n",
      "Epoch 140, Loss_data: 10.2139, Loss_ode: 3.8341\n",
      "Current learning rate:  0.0001\n",
      "Epoch 150, Loss_data: 9.9315, Loss_ode: 3.8583\n",
      "Current learning rate:  0.0001\n",
      "Epoch 160, Loss_data: 9.6647, Loss_ode: 3.8578\n",
      "Current learning rate:  0.0001\n",
      "Epoch 170, Loss_data: 9.4111, Loss_ode: 3.8432\n",
      "Current learning rate:  0.0001\n",
      "Epoch 180, Loss_data: 9.1707, Loss_ode: 3.8813\n",
      "Current learning rate:  0.0001\n",
      "Epoch 190, Loss_data: 8.9434, Loss_ode: 3.8671\n",
      "Current learning rate:  0.0001\n",
      "Epoch 200, Loss_data: 8.7288, Loss_ode: 3.8123\n",
      "Current learning rate:  0.0001\n",
      "Epoch 210, Loss_data: 8.5259, Loss_ode: 3.8315\n",
      "Current learning rate:  0.0001\n",
      "Epoch 220, Loss_data: 8.3346, Loss_ode: 3.7768\n",
      "Current learning rate:  0.0001\n",
      "Epoch 230, Loss_data: 8.1543, Loss_ode: 3.7727\n",
      "Current learning rate:  0.0001\n",
      "Epoch 240, Loss_data: 7.9847, Loss_ode: 3.7966\n",
      "Current learning rate:  0.0001\n",
      "Epoch 250, Loss_data: 7.8255, Loss_ode: 3.8212\n",
      "Current learning rate:  0.0001\n",
      "Epoch 260, Loss_data: 7.6761, Loss_ode: 3.7684\n",
      "Current learning rate:  0.0001\n",
      "Epoch 270, Loss_data: 7.5360, Loss_ode: 3.7695\n",
      "Current learning rate:  0.0001\n",
      "Epoch 280, Loss_data: 7.4046, Loss_ode: 3.8411\n",
      "Current learning rate:  0.0001\n",
      "Epoch 290, Loss_data: 7.2817, Loss_ode: 3.7617\n",
      "Current learning rate:  0.0001\n",
      "Epoch 300, Loss_data: 7.1666, Loss_ode: 3.7979\n",
      "Current learning rate:  0.0001\n",
      "Epoch 310, Loss_data: 7.0589, Loss_ode: 3.7642\n",
      "Current learning rate:  0.0001\n",
      "Epoch 320, Loss_data: 6.9583, Loss_ode: 3.7781\n",
      "Current learning rate:  0.0001\n",
      "Epoch 330, Loss_data: 6.8644, Loss_ode: 3.7677\n",
      "Current learning rate:  0.0001\n",
      "Epoch 340, Loss_data: 6.7769, Loss_ode: 3.7911\n",
      "Current learning rate:  0.0001\n",
      "Epoch 350, Loss_data: 6.6952, Loss_ode: 3.7802\n",
      "Current learning rate:  0.0001\n",
      "Epoch 360, Loss_data: 6.6192, Loss_ode: 3.7606\n",
      "Current learning rate:  0.0001\n",
      "Epoch 370, Loss_data: 6.5486, Loss_ode: 3.7547\n",
      "Current learning rate:  0.0001\n",
      "Epoch 380, Loss_data: 6.4829, Loss_ode: 3.7231\n",
      "Current learning rate:  0.0001\n",
      "Epoch 390, Loss_data: 6.4220, Loss_ode: 3.7758\n",
      "Current learning rate:  0.0001\n",
      "Epoch 400, Loss_data: 6.3656, Loss_ode: 3.7427\n",
      "Current learning rate:  0.0001\n",
      "Epoch 410, Loss_data: 6.3133, Loss_ode: 3.7432\n",
      "Current learning rate:  0.0001\n",
      "Epoch 420, Loss_data: 6.2650, Loss_ode: 3.7459\n",
      "Current learning rate:  0.0001\n",
      "Epoch 430, Loss_data: 6.2204, Loss_ode: 3.7405\n",
      "Current learning rate:  0.0001\n",
      "Epoch 440, Loss_data: 6.1792, Loss_ode: 3.7496\n",
      "Current learning rate:  0.0001\n",
      "Epoch 450, Loss_data: 6.1413, Loss_ode: 3.7761\n",
      "Current learning rate:  0.0001\n",
      "Epoch 460, Loss_data: 6.1064, Loss_ode: 3.7435\n",
      "Current learning rate:  0.0001\n",
      "Epoch 470, Loss_data: 6.0743, Loss_ode: 3.7831\n",
      "Current learning rate:  0.0001\n",
      "Epoch 480, Loss_data: 6.0449, Loss_ode: 3.6902\n",
      "Current learning rate:  0.0001\n",
      "Epoch 490, Loss_data: 6.0179, Loss_ode: 3.7273\n",
      "Current learning rate:  0.0001\n",
      "Epoch 500, Loss_data: 5.9931, Loss_ode: 3.7372\n",
      "Current learning rate:  0.0001\n",
      "Epoch 510, Loss_data: 5.9704, Loss_ode: 3.7572\n",
      "Current learning rate:  0.0001\n",
      "Epoch 520, Loss_data: 5.9497, Loss_ode: 3.7417\n",
      "Current learning rate:  0.0001\n",
      "Epoch 530, Loss_data: 5.9308, Loss_ode: 3.7256\n",
      "Current learning rate:  0.0001\n",
      "Epoch 540, Loss_data: 5.9136, Loss_ode: 3.7404\n",
      "Current learning rate:  0.0001\n",
      "Epoch 550, Loss_data: 5.8980, Loss_ode: 3.7073\n",
      "Current learning rate:  0.0001\n",
      "Epoch 560, Loss_data: 5.8836, Loss_ode: 3.7540\n",
      "Current learning rate:  0.0001\n",
      "Epoch 570, Loss_data: 5.8706, Loss_ode: 3.7147\n",
      "Current learning rate:  0.0001\n",
      "Epoch 580, Loss_data: 5.8589, Loss_ode: 3.7264\n",
      "Current learning rate:  0.0001\n",
      "Epoch 590, Loss_data: 5.8482, Loss_ode: 3.7161\n",
      "Current learning rate:  0.0001\n",
      "Epoch 600, Loss_data: 5.8384, Loss_ode: 3.7379\n",
      "Current learning rate:  0.0001\n",
      "Epoch 610, Loss_data: 5.8297, Loss_ode: 3.7283\n",
      "Current learning rate:  0.0001\n",
      "Epoch 620, Loss_data: 5.8216, Loss_ode: 3.7151\n",
      "Current learning rate:  0.0001\n",
      "Epoch 630, Loss_data: 5.8143, Loss_ode: 3.7354\n",
      "Current learning rate:  0.0001\n",
      "Epoch 640, Loss_data: 5.8076, Loss_ode: 3.7426\n",
      "Current learning rate:  0.0001\n",
      "Epoch 650, Loss_data: 5.8015, Loss_ode: 3.7288\n",
      "Current learning rate:  0.0001\n",
      "Epoch 660, Loss_data: 5.7957, Loss_ode: 3.7521\n",
      "Current learning rate:  0.0001\n",
      "Epoch 670, Loss_data: 5.7904, Loss_ode: 3.6933\n",
      "Current learning rate:  0.0001\n",
      "Epoch 680, Loss_data: 5.7854, Loss_ode: 3.7207\n",
      "Current learning rate:  0.0001\n",
      "Epoch 690, Loss_data: 5.7806, Loss_ode: 3.7402\n",
      "Current learning rate:  0.0001\n",
      "Epoch 700, Loss_data: 5.7760, Loss_ode: 3.7095\n",
      "Current learning rate:  0.0001\n",
      "Epoch 710, Loss_data: 5.7712, Loss_ode: 3.7098\n",
      "Current learning rate:  0.0001\n",
      "Epoch 720, Loss_data: 5.7663, Loss_ode: 3.7281\n",
      "Current learning rate:  0.0001\n",
      "Epoch 730, Loss_data: 5.7607, Loss_ode: 3.7598\n",
      "Current learning rate:  0.0001\n",
      "Epoch 740, Loss_data: 5.7542, Loss_ode: 3.7067\n",
      "Current learning rate:  0.0001\n",
      "Epoch 750, Loss_data: 5.7458, Loss_ode: 3.7334\n",
      "Current learning rate:  0.0001\n",
      "Epoch 760, Loss_data: 5.7336, Loss_ode: 3.7512\n",
      "Current learning rate:  0.0001\n",
      "Epoch 770, Loss_data: 5.7127, Loss_ode: 3.7041\n",
      "Current learning rate:  0.0001\n",
      "Epoch 780, Loss_data: 5.6700, Loss_ode: 3.6861\n",
      "Current learning rate:  0.0001\n",
      "Epoch 790, Loss_data: 5.5926, Loss_ode: 3.6996\n",
      "Current learning rate:  0.0001\n",
      "Epoch 800, Loss_data: 5.4654, Loss_ode: 3.8057\n",
      "Current learning rate:  0.0001\n",
      "Epoch 810, Loss_data: 5.2644, Loss_ode: 3.7009\n",
      "Current learning rate:  0.0001\n",
      "Epoch 820, Loss_data: 4.6294, Loss_ode: 3.6019\n",
      "Current learning rate:  0.0001\n",
      "Epoch 830, Loss_data: 3.5214, Loss_ode: 3.5803\n",
      "Current learning rate:  0.0001\n",
      "Epoch 840, Loss_data: 3.2045, Loss_ode: 3.5044\n",
      "Current learning rate:  0.0001\n",
      "Epoch 850, Loss_data: 2.9862, Loss_ode: 3.4751\n",
      "Current learning rate:  0.0001\n",
      "Epoch 860, Loss_data: 2.8020, Loss_ode: 3.3383\n",
      "Current learning rate:  0.0001\n",
      "Epoch 870, Loss_data: 2.6188, Loss_ode: 3.3331\n",
      "Current learning rate:  0.0001\n",
      "Epoch 880, Loss_data: 2.4625, Loss_ode: 3.2521\n",
      "Current learning rate:  0.0001\n",
      "Epoch 890, Loss_data: 2.3155, Loss_ode: 3.3039\n",
      "Current learning rate:  0.0001\n",
      "Epoch 900, Loss_data: 2.1940, Loss_ode: 3.2540\n",
      "Current learning rate:  0.0001\n",
      "Epoch 910, Loss_data: 2.0799, Loss_ode: 3.1919\n",
      "Current learning rate:  0.0001\n",
      "Epoch 920, Loss_data: 1.9736, Loss_ode: 3.2350\n",
      "Current learning rate:  0.0001\n",
      "Epoch 930, Loss_data: 1.8782, Loss_ode: 3.1736\n",
      "Current learning rate:  0.0001\n",
      "Epoch 940, Loss_data: 1.7881, Loss_ode: 3.1689\n",
      "Current learning rate:  0.0001\n",
      "Epoch 950, Loss_data: 1.7040, Loss_ode: 3.1771\n",
      "Current learning rate:  0.0001\n",
      "Epoch 960, Loss_data: 1.6252, Loss_ode: 3.1779\n",
      "Current learning rate:  0.0001\n",
      "Epoch 970, Loss_data: 1.5520, Loss_ode: 3.1571\n",
      "Current learning rate:  0.0001\n",
      "Epoch 980, Loss_data: 1.4856, Loss_ode: 3.1357\n",
      "Current learning rate:  0.0001\n",
      "Epoch 990, Loss_data: 1.4175, Loss_ode: 3.1184\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1000, Loss_data: 1.3531, Loss_ode: 3.1336\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1010, Loss_data: 1.2972, Loss_ode: 3.1214\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1020, Loss_data: 1.2398, Loss_ode: 3.0250\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1030, Loss_data: 1.1895, Loss_ode: 3.0807\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1040, Loss_data: 1.1381, Loss_ode: 3.1144\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1050, Loss_data: 1.0897, Loss_ode: 3.0358\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1060, Loss_data: 1.0444, Loss_ode: 3.1259\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1070, Loss_data: 0.9996, Loss_ode: 3.0186\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1080, Loss_data: 0.9621, Loss_ode: 3.0056\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1090, Loss_data: 0.9212, Loss_ode: 2.9632\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1100, Loss_data: 0.8824, Loss_ode: 3.1012\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1110, Loss_data: 0.8476, Loss_ode: 2.9135\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1120, Loss_data: 0.8176, Loss_ode: 2.8657\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1130, Loss_data: 0.7816, Loss_ode: 3.0438\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1140, Loss_data: 0.7490, Loss_ode: 3.2435\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1150, Loss_data: 0.7698, Loss_ode: 5.1990\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1160, Loss_data: 0.7438, Loss_ode: 3.8781\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1170, Loss_data: 0.7081, Loss_ode: 3.0362\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1180, Loss_data: 0.6943, Loss_ode: 3.0296\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1190, Loss_data: 0.6649, Loss_ode: 2.9327\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1200, Loss_data: 0.6245, Loss_ode: 2.9620\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1210, Loss_data: 0.6057, Loss_ode: 2.8731\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1220, Loss_data: 0.5755, Loss_ode: 2.9256\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1230, Loss_data: 0.5505, Loss_ode: 2.8480\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1240, Loss_data: 0.5266, Loss_ode: 2.8384\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1250, Loss_data: 0.5074, Loss_ode: 2.8062\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1260, Loss_data: 0.4878, Loss_ode: 2.8187\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1270, Loss_data: 0.4704, Loss_ode: 2.7927\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1280, Loss_data: 0.4512, Loss_ode: 2.7709\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1290, Loss_data: 0.4341, Loss_ode: 2.7477\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1300, Loss_data: 0.4178, Loss_ode: 2.7301\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1310, Loss_data: 0.4023, Loss_ode: 2.7136\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1320, Loss_data: 0.3865, Loss_ode: 2.6598\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1330, Loss_data: 0.3738, Loss_ode: 2.6156\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1340, Loss_data: 0.3600, Loss_ode: 2.6279\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1350, Loss_data: 0.3496, Loss_ode: 2.5747\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1360, Loss_data: 0.3337, Loss_ode: 2.5739\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1370, Loss_data: 0.3277, Loss_ode: 2.6575\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1380, Loss_data: 0.3062, Loss_ode: 2.5618\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1390, Loss_data: 0.2997, Loss_ode: 2.6196\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1400, Loss_data: 0.2906, Loss_ode: 2.4840\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1410, Loss_data: 0.2891, Loss_ode: 2.4766\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1420, Loss_data: 0.2712, Loss_ode: 2.6267\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1430, Loss_data: 0.2642, Loss_ode: 2.2789\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1440, Loss_data: 0.2527, Loss_ode: 2.2616\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1450, Loss_data: 0.2430, Loss_ode: 2.3144\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1460, Loss_data: 0.7730, Loss_ode: 11.5760\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1470, Loss_data: 2.0400, Loss_ode: 4.4530\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1480, Loss_data: 1.1589, Loss_ode: 3.8331\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1490, Loss_data: 0.6481, Loss_ode: 3.5927\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1500, Loss_data: 0.5314, Loss_ode: 3.2438\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1510, Loss_data: 0.4331, Loss_ode: 3.0985\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1520, Loss_data: 0.3910, Loss_ode: 3.0243\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1530, Loss_data: 0.3778, Loss_ode: 2.9900\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1540, Loss_data: 0.3611, Loss_ode: 2.8885\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1550, Loss_data: 0.3390, Loss_ode: 2.9464\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1560, Loss_data: 0.3248, Loss_ode: 2.8777\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1570, Loss_data: 0.3107, Loss_ode: 2.8017\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1580, Loss_data: 0.2962, Loss_ode: 2.8045\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1590, Loss_data: 0.2833, Loss_ode: 2.7612\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1600, Loss_data: 0.2724, Loss_ode: 2.7465\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1610, Loss_data: 0.2601, Loss_ode: 2.7091\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1620, Loss_data: 0.2497, Loss_ode: 2.6450\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1630, Loss_data: 0.2390, Loss_ode: 2.6509\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1640, Loss_data: 0.2324, Loss_ode: 2.5803\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1650, Loss_data: 0.2240, Loss_ode: 2.5727\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1660, Loss_data: 0.2158, Loss_ode: 2.4788\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1670, Loss_data: 0.2076, Loss_ode: 2.4497\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1680, Loss_data: 0.2005, Loss_ode: 2.4638\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1690, Loss_data: 0.1942, Loss_ode: 2.4053\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1700, Loss_data: 0.1880, Loss_ode: 2.3934\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1710, Loss_data: 0.1825, Loss_ode: 2.3499\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1720, Loss_data: 0.1754, Loss_ode: 2.2967\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1730, Loss_data: 0.1707, Loss_ode: 2.2507\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1740, Loss_data: 0.1664, Loss_ode: 2.2478\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1750, Loss_data: 0.1597, Loss_ode: 2.1972\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1760, Loss_data: 0.1537, Loss_ode: 2.2616\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1770, Loss_data: 0.1448, Loss_ode: 2.1248\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1780, Loss_data: 0.1469, Loss_ode: 2.0500\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1790, Loss_data: 0.1434, Loss_ode: 1.9855\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1800, Loss_data: 0.1318, Loss_ode: 2.0086\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1810, Loss_data: 0.1335, Loss_ode: 1.9134\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1820, Loss_data: 0.1134, Loss_ode: 6.1884\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1830, Loss_data: 0.1286, Loss_ode: 2.9634\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1840, Loss_data: 0.1133, Loss_ode: 2.7807\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1850, Loss_data: 0.1366, Loss_ode: 2.3490\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1860, Loss_data: 0.1375, Loss_ode: 2.3085\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1870, Loss_data: 0.1263, Loss_ode: 2.2120\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1880, Loss_data: 0.1176, Loss_ode: 2.1250\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1890, Loss_data: 0.1129, Loss_ode: 2.0568\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1900, Loss_data: 0.1056, Loss_ode: 1.9873\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1910, Loss_data: 0.1000, Loss_ode: 1.9301\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1920, Loss_data: 0.0972, Loss_ode: 1.8992\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1930, Loss_data: 0.0956, Loss_ode: 1.8260\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1940, Loss_data: 0.0923, Loss_ode: 1.7705\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1950, Loss_data: 0.0893, Loss_ode: 1.7654\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1960, Loss_data: 0.0884, Loss_ode: 1.6950\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1970, Loss_data: 0.0861, Loss_ode: 1.6629\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1980, Loss_data: 0.0845, Loss_ode: 1.6365\n",
      "Current learning rate:  0.0001\n",
      "Epoch 1990, Loss_data: 0.0830, Loss_ode: 1.5613\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2000, Loss_data: 0.0815, Loss_ode: 1.5273\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2010, Loss_data: 0.0803, Loss_ode: 1.4927\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2020, Loss_data: 0.0779, Loss_ode: 1.5071\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2030, Loss_data: 0.0756, Loss_ode: 1.7335\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2040, Loss_data: 0.0714, Loss_ode: 1.3678\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2050, Loss_data: 0.0785, Loss_ode: 2.9399\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2060, Loss_data: 0.0665, Loss_ode: 1.5123\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2070, Loss_data: 0.0643, Loss_ode: 1.3213\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2080, Loss_data: 0.0683, Loss_ode: 1.3953\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2090, Loss_data: 0.0710, Loss_ode: 1.3116\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2100, Loss_data: 0.0714, Loss_ode: 1.5474\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2110, Loss_data: 0.0657, Loss_ode: 1.2690\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2120, Loss_data: 0.0617, Loss_ode: 1.2516\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2130, Loss_data: 0.0612, Loss_ode: 1.5261\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2140, Loss_data: 0.0629, Loss_ode: 1.2876\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2150, Loss_data: 0.0624, Loss_ode: 1.2605\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2160, Loss_data: 0.0624, Loss_ode: 1.1543\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2170, Loss_data: 0.0598, Loss_ode: 1.1931\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2180, Loss_data: 0.0603, Loss_ode: 1.0657\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2190, Loss_data: 0.0631, Loss_ode: 1.2655\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2200, Loss_data: 0.0549, Loss_ode: 1.9461\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2210, Loss_data: 0.0547, Loss_ode: 1.0551\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2220, Loss_data: 0.0584, Loss_ode: 1.0715\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2230, Loss_data: 0.0595, Loss_ode: 1.0403\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2240, Loss_data: 0.0555, Loss_ode: 1.3248\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2250, Loss_data: 0.0514, Loss_ode: 1.1753\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2260, Loss_data: 0.0535, Loss_ode: 1.0052\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2270, Loss_data: 0.0547, Loss_ode: 1.2315\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2280, Loss_data: 0.0556, Loss_ode: 1.0051\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2290, Loss_data: 0.0560, Loss_ode: 1.0669\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2300, Loss_data: 0.0509, Loss_ode: 0.9985\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2310, Loss_data: 0.0504, Loss_ode: 0.9461\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2320, Loss_data: 0.0516, Loss_ode: 0.9026\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2330, Loss_data: 0.0511, Loss_ode: 1.0284\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2340, Loss_data: 0.0528, Loss_ode: 1.4075\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2350, Loss_data: 0.0490, Loss_ode: 1.0941\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2360, Loss_data: 0.0505, Loss_ode: 0.9831\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2370, Loss_data: 0.0509, Loss_ode: 0.8874\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2380, Loss_data: 0.0520, Loss_ode: 1.4771\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2390, Loss_data: 0.0478, Loss_ode: 0.9032\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2400, Loss_data: 0.0475, Loss_ode: 0.9264\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2410, Loss_data: 0.0490, Loss_ode: 0.8396\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2420, Loss_data: 0.0516, Loss_ode: 1.7158\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2430, Loss_data: 0.0457, Loss_ode: 1.0244\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2440, Loss_data: 0.0479, Loss_ode: 0.8883\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2450, Loss_data: 0.0483, Loss_ode: 0.8228\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2460, Loss_data: 0.0500, Loss_ode: 1.5939\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2470, Loss_data: 0.0451, Loss_ode: 0.9316\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2480, Loss_data: 0.0464, Loss_ode: 0.7922\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2490, Loss_data: 0.0484, Loss_ode: 1.0739\n",
      "Current learning rate:  0.0001\n",
      "Epoch 2500, Loss_data: 0.0452, Loss_ode: 0.7792\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2510, Loss_data: 0.0460, Loss_ode: 0.8010\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2520, Loss_data: 0.0467, Loss_ode: 0.7872\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2530, Loss_data: 0.0466, Loss_ode: 0.7675\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2540, Loss_data: 0.0466, Loss_ode: 0.7698\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2550, Loss_data: 0.0464, Loss_ode: 0.7587\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2560, Loss_data: 0.0456, Loss_ode: 0.7513\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2570, Loss_data: 0.0456, Loss_ode: 0.7680\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2580, Loss_data: 0.0458, Loss_ode: 0.7411\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2590, Loss_data: 0.0455, Loss_ode: 0.7542\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2600, Loss_data: 0.0455, Loss_ode: 0.7338\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2610, Loss_data: 0.0452, Loss_ode: 0.7411\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2620, Loss_data: 0.0449, Loss_ode: 0.7220\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2630, Loss_data: 0.0451, Loss_ode: 0.7235\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2640, Loss_data: 0.0446, Loss_ode: 0.7437\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2650, Loss_data: 0.0445, Loss_ode: 0.7202\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2660, Loss_data: 0.0443, Loss_ode: 0.7283\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2670, Loss_data: 0.0442, Loss_ode: 0.7250\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2680, Loss_data: 0.0441, Loss_ode: 0.7168\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2690, Loss_data: 0.0439, Loss_ode: 0.7077\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2700, Loss_data: 0.0438, Loss_ode: 0.7105\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2710, Loss_data: 0.0439, Loss_ode: 0.7151\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2720, Loss_data: 0.0439, Loss_ode: 0.7164\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2730, Loss_data: 0.0439, Loss_ode: 0.7027\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2740, Loss_data: 0.0434, Loss_ode: 0.6909\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2750, Loss_data: 0.0435, Loss_ode: 0.6974\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2760, Loss_data: 0.0435, Loss_ode: 0.6953\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2770, Loss_data: 0.0428, Loss_ode: 0.6997\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2780, Loss_data: 0.0434, Loss_ode: 0.6940\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2790, Loss_data: 0.0431, Loss_ode: 0.7028\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2800, Loss_data: 0.0428, Loss_ode: 0.6949\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2810, Loss_data: 0.0432, Loss_ode: 0.7104\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2820, Loss_data: 0.0423, Loss_ode: 0.7014\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2830, Loss_data: 0.0427, Loss_ode: 0.6654\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2840, Loss_data: 0.0429, Loss_ode: 0.6889\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2850, Loss_data: 0.0434, Loss_ode: 0.8080\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2860, Loss_data: 0.0421, Loss_ode: 0.6864\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2870, Loss_data: 0.0424, Loss_ode: 0.6699\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2880, Loss_data: 0.0424, Loss_ode: 0.6626\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2890, Loss_data: 0.0424, Loss_ode: 0.6832\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2900, Loss_data: 0.0421, Loss_ode: 0.6844\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2910, Loss_data: 0.0417, Loss_ode: 0.7470\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2920, Loss_data: 0.0423, Loss_ode: 0.6661\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2930, Loss_data: 0.0420, Loss_ode: 0.6664\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2940, Loss_data: 0.0422, Loss_ode: 0.6659\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2950, Loss_data: 0.0424, Loss_ode: 0.6610\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2960, Loss_data: 0.0434, Loss_ode: 0.9218\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2970, Loss_data: 0.0408, Loss_ode: 0.7523\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2980, Loss_data: 0.0417, Loss_ode: 0.6551\n",
      "Current learning rate:  7e-05\n",
      "Epoch 2990, Loss_data: 0.0416, Loss_ode: 0.6542\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3000, Loss_data: 0.0414, Loss_ode: 0.6570\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3010, Loss_data: 0.0418, Loss_ode: 0.6403\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3020, Loss_data: 0.0410, Loss_ode: 0.7049\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3030, Loss_data: 0.0414, Loss_ode: 0.6284\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3040, Loss_data: 0.0416, Loss_ode: 0.6386\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3050, Loss_data: 0.0413, Loss_ode: 0.6205\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3060, Loss_data: 0.0421, Loss_ode: 0.7153\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3070, Loss_data: 0.0412, Loss_ode: 0.6273\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3080, Loss_data: 0.0410, Loss_ode: 0.6424\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3090, Loss_data: 0.0408, Loss_ode: 0.6429\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3100, Loss_data: 0.0412, Loss_ode: 0.6103\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3110, Loss_data: 0.0421, Loss_ode: 0.7316\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3120, Loss_data: 0.0407, Loss_ode: 0.6114\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3130, Loss_data: 0.0410, Loss_ode: 0.6286\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3140, Loss_data: 0.0406, Loss_ode: 0.6197\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3150, Loss_data: 0.0416, Loss_ode: 0.6475\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3160, Loss_data: 0.0406, Loss_ode: 0.6019\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3170, Loss_data: 0.0408, Loss_ode: 0.6057\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3180, Loss_data: 0.0413, Loss_ode: 0.6417\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3190, Loss_data: 0.0414, Loss_ode: 0.6833\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3200, Loss_data: 0.0404, Loss_ode: 0.5949\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3210, Loss_data: 0.0402, Loss_ode: 0.6193\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3220, Loss_data: 0.0410, Loss_ode: 0.6196\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3230, Loss_data: 0.0407, Loss_ode: 0.5901\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3240, Loss_data: 0.0408, Loss_ode: 0.5938\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3250, Loss_data: 0.0418, Loss_ode: 0.8157\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3260, Loss_data: 0.0394, Loss_ode: 0.7388\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3270, Loss_data: 0.0393, Loss_ode: 0.6508\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3280, Loss_data: 0.0395, Loss_ode: 0.6064\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3290, Loss_data: 0.0404, Loss_ode: 0.5890\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3300, Loss_data: 0.0404, Loss_ode: 0.5710\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3310, Loss_data: 0.0401, Loss_ode: 0.5711\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3320, Loss_data: 0.0410, Loss_ode: 0.6696\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3330, Loss_data: 0.0399, Loss_ode: 0.5750\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3340, Loss_data: 0.0402, Loss_ode: 0.5860\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3350, Loss_data: 0.0393, Loss_ode: 0.5873\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3360, Loss_data: 0.0398, Loss_ode: 0.5628\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3370, Loss_data: 0.0404, Loss_ode: 0.5739\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3380, Loss_data: 0.0407, Loss_ode: 0.6091\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3390, Loss_data: 0.0399, Loss_ode: 0.5627\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3400, Loss_data: 0.0400, Loss_ode: 0.5988\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3410, Loss_data: 0.0400, Loss_ode: 0.5847\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3420, Loss_data: 0.0395, Loss_ode: 0.5455\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3430, Loss_data: 0.0390, Loss_ode: 0.5821\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3440, Loss_data: 0.0387, Loss_ode: 0.6199\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3450, Loss_data: 0.0392, Loss_ode: 0.5358\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3460, Loss_data: 0.0396, Loss_ode: 0.5670\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3470, Loss_data: 0.0388, Loss_ode: 0.5500\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3480, Loss_data: 0.0385, Loss_ode: 0.5844\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3490, Loss_data: 0.0388, Loss_ode: 0.5445\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3500, Loss_data: 0.0396, Loss_ode: 0.6006\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3510, Loss_data: 0.0394, Loss_ode: 0.5579\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3520, Loss_data: 0.0385, Loss_ode: 0.5523\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3530, Loss_data: 0.0391, Loss_ode: 0.5629\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3540, Loss_data: 0.0394, Loss_ode: 0.5654\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3550, Loss_data: 0.0395, Loss_ode: 0.6222\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3560, Loss_data: 0.0386, Loss_ode: 0.5338\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3570, Loss_data: 0.0383, Loss_ode: 0.5357\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3580, Loss_data: 0.0392, Loss_ode: 0.5898\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3590, Loss_data: 0.0386, Loss_ode: 0.5374\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3600, Loss_data: 0.0383, Loss_ode: 0.5140\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3610, Loss_data: 0.0377, Loss_ode: 0.6559\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3620, Loss_data: 0.0390, Loss_ode: 0.6040\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3630, Loss_data: 0.0379, Loss_ode: 0.5180\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3640, Loss_data: 0.0377, Loss_ode: 0.5301\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3650, Loss_data: 0.0382, Loss_ode: 0.5174\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3660, Loss_data: 0.0375, Loss_ode: 0.5607\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3670, Loss_data: 0.0375, Loss_ode: 0.5616\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3680, Loss_data: 0.0381, Loss_ode: 0.5169\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3690, Loss_data: 0.0376, Loss_ode: 0.5144\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3700, Loss_data: 0.0369, Loss_ode: 0.5809\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3710, Loss_data: 0.0374, Loss_ode: 0.5113\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3720, Loss_data: 0.0376, Loss_ode: 0.5088\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3730, Loss_data: 0.0372, Loss_ode: 0.5472\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3740, Loss_data: 0.0369, Loss_ode: 0.5493\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3750, Loss_data: 0.0370, Loss_ode: 0.5067\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3760, Loss_data: 0.0379, Loss_ode: 0.5499\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3770, Loss_data: 0.0372, Loss_ode: 0.5135\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3780, Loss_data: 0.0368, Loss_ode: 0.5619\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3790, Loss_data: 0.0367, Loss_ode: 0.5027\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3800, Loss_data: 0.0363, Loss_ode: 0.5119\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3810, Loss_data: 0.0370, Loss_ode: 0.4999\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3820, Loss_data: 0.0370, Loss_ode: 0.4948\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3830, Loss_data: 0.0368, Loss_ode: 0.4876\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3840, Loss_data: 0.0355, Loss_ode: 0.7552\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3850, Loss_data: 0.0373, Loss_ode: 0.5872\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3860, Loss_data: 0.0367, Loss_ode: 0.5064\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3870, Loss_data: 0.0365, Loss_ode: 0.4916\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3880, Loss_data: 0.0366, Loss_ode: 0.4913\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3890, Loss_data: 0.0360, Loss_ode: 0.5379\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3900, Loss_data: 0.0363, Loss_ode: 0.4703\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3910, Loss_data: 0.0366, Loss_ode: 0.5051\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3920, Loss_data: 0.0361, Loss_ode: 0.4749\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3930, Loss_data: 0.0356, Loss_ode: 0.5556\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3940, Loss_data: 0.0362, Loss_ode: 0.4801\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3950, Loss_data: 0.0361, Loss_ode: 0.4774\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3960, Loss_data: 0.0354, Loss_ode: 0.5170\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3970, Loss_data: 0.0354, Loss_ode: 0.4820\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3980, Loss_data: 0.0359, Loss_ode: 0.4768\n",
      "Current learning rate:  7e-05\n",
      "Epoch 3990, Loss_data: 0.0357, Loss_ode: 0.4760\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4000, Loss_data: 0.0361, Loss_ode: 0.4713\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4010, Loss_data: 0.0377, Loss_ode: 0.8192\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4020, Loss_data: 0.0344, Loss_ode: 0.5180\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4030, Loss_data: 0.0348, Loss_ode: 0.4797\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4040, Loss_data: 0.0354, Loss_ode: 0.4739\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4050, Loss_data: 0.0357, Loss_ode: 0.4628\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4060, Loss_data: 0.0355, Loss_ode: 0.4578\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4070, Loss_data: 0.0357, Loss_ode: 0.4556\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4080, Loss_data: 0.0370, Loss_ode: 0.7628\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4090, Loss_data: 0.0339, Loss_ode: 0.5023\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4100, Loss_data: 0.0347, Loss_ode: 0.4570\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4110, Loss_data: 0.0350, Loss_ode: 0.4622\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4120, Loss_data: 0.0351, Loss_ode: 0.4624\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4130, Loss_data: 0.0344, Loss_ode: 0.4807\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4140, Loss_data: 0.0339, Loss_ode: 0.5008\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4150, Loss_data: 0.0345, Loss_ode: 0.4548\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4160, Loss_data: 0.0346, Loss_ode: 0.4467\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4170, Loss_data: 0.0348, Loss_ode: 0.4461\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4180, Loss_data: 0.0342, Loss_ode: 0.4711\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4190, Loss_data: 0.0335, Loss_ode: 0.5704\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4200, Loss_data: 0.0343, Loss_ode: 0.4638\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4210, Loss_data: 0.0338, Loss_ode: 0.4538\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4220, Loss_data: 0.0349, Loss_ode: 0.4702\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4230, Loss_data: 0.0343, Loss_ode: 0.4534\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4240, Loss_data: 0.0338, Loss_ode: 0.4375\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4250, Loss_data: 0.0335, Loss_ode: 0.4662\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4260, Loss_data: 0.0336, Loss_ode: 0.4405\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4270, Loss_data: 0.0328, Loss_ode: 0.4720\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4280, Loss_data: 0.0335, Loss_ode: 0.4412\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4290, Loss_data: 0.0340, Loss_ode: 0.4176\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4300, Loss_data: 0.0339, Loss_ode: 0.4259\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4310, Loss_data: 0.0342, Loss_ode: 0.4729\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4320, Loss_data: 0.0333, Loss_ode: 0.4430\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4330, Loss_data: 0.0332, Loss_ode: 0.4550\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4340, Loss_data: 0.0338, Loss_ode: 0.4462\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4350, Loss_data: 0.0337, Loss_ode: 0.4286\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4360, Loss_data: 0.0334, Loss_ode: 0.4259\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4370, Loss_data: 0.0328, Loss_ode: 0.4345\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4380, Loss_data: 0.0323, Loss_ode: 0.4856\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4390, Loss_data: 0.0328, Loss_ode: 0.4236\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4400, Loss_data: 0.0333, Loss_ode: 0.4219\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4410, Loss_data: 0.0323, Loss_ode: 0.4468\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4420, Loss_data: 0.0323, Loss_ode: 0.4238\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4430, Loss_data: 0.0328, Loss_ode: 0.4090\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4440, Loss_data: 0.0331, Loss_ode: 0.4335\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4450, Loss_data: 0.0335, Loss_ode: 0.5063\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4460, Loss_data: 0.0320, Loss_ode: 0.4135\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4470, Loss_data: 0.0322, Loss_ode: 0.4170\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4480, Loss_data: 0.0328, Loss_ode: 0.4278\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4490, Loss_data: 0.0331, Loss_ode: 0.4699\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4500, Loss_data: 0.0319, Loss_ode: 0.4034\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4510, Loss_data: 0.0323, Loss_ode: 0.4655\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4520, Loss_data: 0.0319, Loss_ode: 0.4085\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4530, Loss_data: 0.0323, Loss_ode: 0.4092\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4540, Loss_data: 0.0320, Loss_ode: 0.3974\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4550, Loss_data: 0.0328, Loss_ode: 0.5005\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4560, Loss_data: 0.0317, Loss_ode: 0.3985\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4570, Loss_data: 0.0315, Loss_ode: 0.4023\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4580, Loss_data: 0.0314, Loss_ode: 0.3994\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4590, Loss_data: 0.0314, Loss_ode: 0.4057\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4600, Loss_data: 0.0314, Loss_ode: 0.3973\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4610, Loss_data: 0.0308, Loss_ode: 0.4605\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4620, Loss_data: 0.0314, Loss_ode: 0.4029\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4630, Loss_data: 0.0306, Loss_ode: 0.4048\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4640, Loss_data: 0.0312, Loss_ode: 0.4190\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4650, Loss_data: 0.0315, Loss_ode: 0.3939\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4660, Loss_data: 0.0311, Loss_ode: 0.3996\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4670, Loss_data: 0.0309, Loss_ode: 0.3912\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4680, Loss_data: 0.0307, Loss_ode: 0.3960\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4690, Loss_data: 0.0302, Loss_ode: 0.5417\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4700, Loss_data: 0.0299, Loss_ode: 0.3966\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4710, Loss_data: 0.0312, Loss_ode: 0.3969\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4720, Loss_data: 0.0310, Loss_ode: 0.3853\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4730, Loss_data: 0.0306, Loss_ode: 0.3842\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4740, Loss_data: 0.0296, Loss_ode: 0.4940\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4750, Loss_data: 0.0308, Loss_ode: 0.4428\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4760, Loss_data: 0.0301, Loss_ode: 0.3811\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4770, Loss_data: 0.0308, Loss_ode: 0.3827\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4780, Loss_data: 0.0305, Loss_ode: 0.3818\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4790, Loss_data: 0.0298, Loss_ode: 0.3943\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4800, Loss_data: 0.0292, Loss_ode: 0.5269\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4810, Loss_data: 0.0298, Loss_ode: 0.3776\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4820, Loss_data: 0.0304, Loss_ode: 0.3777\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4830, Loss_data: 0.0299, Loss_ode: 0.3870\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4840, Loss_data: 0.0295, Loss_ode: 0.4054\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4850, Loss_data: 0.0288, Loss_ode: 0.4654\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4860, Loss_data: 0.0300, Loss_ode: 0.4189\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4870, Loss_data: 0.0296, Loss_ode: 0.3701\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4880, Loss_data: 0.0299, Loss_ode: 0.3708\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4890, Loss_data: 0.0296, Loss_ode: 0.3708\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4900, Loss_data: 0.0289, Loss_ode: 0.4753\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4910, Loss_data: 0.0297, Loss_ode: 0.4401\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4920, Loss_data: 0.0288, Loss_ode: 0.3664\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4930, Loss_data: 0.0291, Loss_ode: 0.3860\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4940, Loss_data: 0.0298, Loss_ode: 0.3687\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4950, Loss_data: 0.0290, Loss_ode: 0.3838\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4960, Loss_data: 0.0280, Loss_ode: 0.4243\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4970, Loss_data: 0.0282, Loss_ode: 0.3726\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4980, Loss_data: 0.0294, Loss_ode: 0.3677\n",
      "Current learning rate:  7e-05\n",
      "Epoch 4990, Loss_data: 0.0287, Loss_ode: 0.3620\n",
      "Current learning rate:  7e-05\n",
      "Epoch 5000, Loss_data: 0.0291, Loss_ode: 0.3559\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5010, Loss_data: 0.0287, Loss_ode: 0.3543\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5020, Loss_data: 0.0288, Loss_ode: 0.3572\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5030, Loss_data: 0.0288, Loss_ode: 0.3511\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5040, Loss_data: 0.0288, Loss_ode: 0.3607\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5050, Loss_data: 0.0287, Loss_ode: 0.3553\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5060, Loss_data: 0.0289, Loss_ode: 0.3484\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5070, Loss_data: 0.0283, Loss_ode: 0.3531\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5080, Loss_data: 0.0285, Loss_ode: 0.3436\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5090, Loss_data: 0.0285, Loss_ode: 0.3530\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5100, Loss_data: 0.0286, Loss_ode: 0.3526\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5110, Loss_data: 0.0282, Loss_ode: 0.3450\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5120, Loss_data: 0.0283, Loss_ode: 0.3434\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5130, Loss_data: 0.0282, Loss_ode: 0.3482\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5140, Loss_data: 0.0284, Loss_ode: 0.3466\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5150, Loss_data: 0.0281, Loss_ode: 0.3456\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5160, Loss_data: 0.0280, Loss_ode: 0.3463\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5170, Loss_data: 0.0281, Loss_ode: 0.3436\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5180, Loss_data: 0.0279, Loss_ode: 0.3463\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5190, Loss_data: 0.0281, Loss_ode: 0.3436\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5200, Loss_data: 0.0277, Loss_ode: 0.3431\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5210, Loss_data: 0.0279, Loss_ode: 0.3470\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5220, Loss_data: 0.0277, Loss_ode: 0.3430\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5230, Loss_data: 0.0277, Loss_ode: 0.3470\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5240, Loss_data: 0.0275, Loss_ode: 0.3354\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5250, Loss_data: 0.0276, Loss_ode: 0.3410\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5260, Loss_data: 0.0274, Loss_ode: 0.3435\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5270, Loss_data: 0.0275, Loss_ode: 0.3390\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5280, Loss_data: 0.0275, Loss_ode: 0.3402\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5290, Loss_data: 0.0273, Loss_ode: 0.3383\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5300, Loss_data: 0.0274, Loss_ode: 0.3410\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5310, Loss_data: 0.0274, Loss_ode: 0.3285\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5320, Loss_data: 0.0274, Loss_ode: 0.3452\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5330, Loss_data: 0.0273, Loss_ode: 0.3314\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5340, Loss_data: 0.0270, Loss_ode: 0.3343\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5350, Loss_data: 0.0272, Loss_ode: 0.3374\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5360, Loss_data: 0.0271, Loss_ode: 0.3286\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5370, Loss_data: 0.0271, Loss_ode: 0.3366\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5380, Loss_data: 0.0269, Loss_ode: 0.3427\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5390, Loss_data: 0.0270, Loss_ode: 0.3300\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5400, Loss_data: 0.0268, Loss_ode: 0.3274\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5410, Loss_data: 0.0268, Loss_ode: 0.3282\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5420, Loss_data: 0.0268, Loss_ode: 0.3288\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5430, Loss_data: 0.0267, Loss_ode: 0.3264\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5440, Loss_data: 0.0267, Loss_ode: 0.3300\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5450, Loss_data: 0.0268, Loss_ode: 0.3265\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5460, Loss_data: 0.0267, Loss_ode: 0.3255\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5470, Loss_data: 0.0266, Loss_ode: 0.3232\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5480, Loss_data: 0.0267, Loss_ode: 0.3288\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5490, Loss_data: 0.0268, Loss_ode: 0.3201\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5500, Loss_data: 0.0264, Loss_ode: 0.3264\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5510, Loss_data: 0.0263, Loss_ode: 0.3288\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5520, Loss_data: 0.0263, Loss_ode: 0.3173\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5530, Loss_data: 0.0265, Loss_ode: 0.3275\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5540, Loss_data: 0.0262, Loss_ode: 0.3227\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5550, Loss_data: 0.0261, Loss_ode: 0.3229\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5560, Loss_data: 0.0262, Loss_ode: 0.3202\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5570, Loss_data: 0.0260, Loss_ode: 0.3200\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5580, Loss_data: 0.0260, Loss_ode: 0.3194\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5590, Loss_data: 0.0260, Loss_ode: 0.3184\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5600, Loss_data: 0.0259, Loss_ode: 0.3182\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5610, Loss_data: 0.0261, Loss_ode: 0.3216\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5620, Loss_data: 0.0257, Loss_ode: 0.3213\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5630, Loss_data: 0.0261, Loss_ode: 0.3272\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5640, Loss_data: 0.0256, Loss_ode: 0.3176\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5650, Loss_data: 0.0255, Loss_ode: 0.3281\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5660, Loss_data: 0.0253, Loss_ode: 0.3189\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5670, Loss_data: 0.0255, Loss_ode: 0.3099\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5680, Loss_data: 0.0258, Loss_ode: 0.3224\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5690, Loss_data: 0.0270, Loss_ode: 0.4956\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5700, Loss_data: 0.0250, Loss_ode: 0.3168\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5710, Loss_data: 0.0253, Loss_ode: 0.3257\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5720, Loss_data: 0.0253, Loss_ode: 0.3155\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5730, Loss_data: 0.0250, Loss_ode: 0.3212\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5740, Loss_data: 0.0255, Loss_ode: 0.3168\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5750, Loss_data: 0.0256, Loss_ode: 0.3215\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5760, Loss_data: 0.0251, Loss_ode: 0.3205\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5770, Loss_data: 0.0251, Loss_ode: 0.3072\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5780, Loss_data: 0.0257, Loss_ode: 0.3330\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5790, Loss_data: 0.0250, Loss_ode: 0.3162\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5800, Loss_data: 0.0248, Loss_ode: 0.3164\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5810, Loss_data: 0.0254, Loss_ode: 0.3206\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5820, Loss_data: 0.0260, Loss_ode: 0.4343\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5830, Loss_data: 0.0239, Loss_ode: 0.3437\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5840, Loss_data: 0.0250, Loss_ode: 0.3077\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5850, Loss_data: 0.0250, Loss_ode: 0.2983\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5860, Loss_data: 0.0244, Loss_ode: 0.3113\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5870, Loss_data: 0.0248, Loss_ode: 0.3023\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5880, Loss_data: 0.0253, Loss_ode: 0.3402\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5890, Loss_data: 0.0243, Loss_ode: 0.3066\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5900, Loss_data: 0.0245, Loss_ode: 0.3035\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5910, Loss_data: 0.0246, Loss_ode: 0.3050\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5920, Loss_data: 0.0243, Loss_ode: 0.3237\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5930, Loss_data: 0.0242, Loss_ode: 0.3066\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5940, Loss_data: 0.0241, Loss_ode: 0.3023\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5950, Loss_data: 0.0243, Loss_ode: 0.3005\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5960, Loss_data: 0.0240, Loss_ode: 0.3012\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5970, Loss_data: 0.0233, Loss_ode: 0.3993\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5980, Loss_data: 0.0241, Loss_ode: 0.3288\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 5990, Loss_data: 0.0239, Loss_ode: 0.3089\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6000, Loss_data: 0.0243, Loss_ode: 0.2984\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6010, Loss_data: 0.0240, Loss_ode: 0.2990\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6020, Loss_data: 0.0243, Loss_ode: 0.3079\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6030, Loss_data: 0.0255, Loss_ode: 0.5072\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6040, Loss_data: 0.0230, Loss_ode: 0.3336\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6050, Loss_data: 0.0240, Loss_ode: 0.2976\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6060, Loss_data: 0.0242, Loss_ode: 0.3010\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6070, Loss_data: 0.0236, Loss_ode: 0.3035\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6080, Loss_data: 0.0235, Loss_ode: 0.3033\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6090, Loss_data: 0.0245, Loss_ode: 0.3294\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6100, Loss_data: 0.0236, Loss_ode: 0.2872\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6110, Loss_data: 0.0237, Loss_ode: 0.2943\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6120, Loss_data: 0.0236, Loss_ode: 0.2954\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6130, Loss_data: 0.0233, Loss_ode: 0.3274\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6140, Loss_data: 0.0232, Loss_ode: 0.3120\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6150, Loss_data: 0.0236, Loss_ode: 0.3038\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6160, Loss_data: 0.0233, Loss_ode: 0.2873\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6170, Loss_data: 0.0236, Loss_ode: 0.2919\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6180, Loss_data: 0.0240, Loss_ode: 0.3635\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6190, Loss_data: 0.0228, Loss_ode: 0.2986\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6200, Loss_data: 0.0236, Loss_ode: 0.2919\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6210, Loss_data: 0.0233, Loss_ode: 0.2948\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6220, Loss_data: 0.0227, Loss_ode: 0.3258\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6230, Loss_data: 0.0231, Loss_ode: 0.2894\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6240, Loss_data: 0.0232, Loss_ode: 0.2853\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6250, Loss_data: 0.0230, Loss_ode: 0.2901\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6260, Loss_data: 0.0231, Loss_ode: 0.2882\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6270, Loss_data: 0.0237, Loss_ode: 0.3205\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6280, Loss_data: 0.0235, Loss_ode: 0.2930\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6290, Loss_data: 0.0231, Loss_ode: 0.2858\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6300, Loss_data: 0.0228, Loss_ode: 0.2918\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6310, Loss_data: 0.0228, Loss_ode: 0.2902\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6320, Loss_data: 0.0233, Loss_ode: 0.2991\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6330, Loss_data: 0.0233, Loss_ode: 0.3291\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6340, Loss_data: 0.0224, Loss_ode: 0.3064\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6350, Loss_data: 0.0231, Loss_ode: 0.2873\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6360, Loss_data: 0.0228, Loss_ode: 0.2822\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6370, Loss_data: 0.0221, Loss_ode: 0.3200\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6380, Loss_data: 0.0224, Loss_ode: 0.2830\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6390, Loss_data: 0.0230, Loss_ode: 0.2949\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6400, Loss_data: 0.0229, Loss_ode: 0.2922\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6410, Loss_data: 0.0222, Loss_ode: 0.3061\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6420, Loss_data: 0.0224, Loss_ode: 0.3348\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6430, Loss_data: 0.0229, Loss_ode: 0.3074\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6440, Loss_data: 0.0225, Loss_ode: 0.2873\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6450, Loss_data: 0.0228, Loss_ode: 0.2805\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6460, Loss_data: 0.0228, Loss_ode: 0.3047\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6470, Loss_data: 0.0230, Loss_ode: 0.3029\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6480, Loss_data: 0.0222, Loss_ode: 0.2813\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6490, Loss_data: 0.0224, Loss_ode: 0.2844\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6500, Loss_data: 0.0219, Loss_ode: 0.3122\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6510, Loss_data: 0.0217, Loss_ode: 0.2946\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6520, Loss_data: 0.0222, Loss_ode: 0.2779\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6530, Loss_data: 0.0224, Loss_ode: 0.2897\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6540, Loss_data: 0.0221, Loss_ode: 0.2750\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6550, Loss_data: 0.0220, Loss_ode: 0.2780\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6560, Loss_data: 0.0221, Loss_ode: 0.2823\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6570, Loss_data: 0.0214, Loss_ode: 0.3990\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6580, Loss_data: 0.0222, Loss_ode: 0.3213\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6590, Loss_data: 0.0221, Loss_ode: 0.2710\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6600, Loss_data: 0.0218, Loss_ode: 0.2862\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6610, Loss_data: 0.0220, Loss_ode: 0.2768\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6620, Loss_data: 0.0220, Loss_ode: 0.2814\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6630, Loss_data: 0.0220, Loss_ode: 0.2794\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6640, Loss_data: 0.0219, Loss_ode: 0.2739\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6650, Loss_data: 0.0218, Loss_ode: 0.2749\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6660, Loss_data: 0.0225, Loss_ode: 0.3252\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6670, Loss_data: 0.0218, Loss_ode: 0.2790\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6680, Loss_data: 0.0216, Loss_ode: 0.2719\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6690, Loss_data: 0.0215, Loss_ode: 0.2697\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6700, Loss_data: 0.0214, Loss_ode: 0.2776\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6710, Loss_data: 0.0220, Loss_ode: 0.3020\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6720, Loss_data: 0.0216, Loss_ode: 0.2716\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6730, Loss_data: 0.0214, Loss_ode: 0.2889\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6740, Loss_data: 0.0211, Loss_ode: 0.2877\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6750, Loss_data: 0.0214, Loss_ode: 0.2664\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6760, Loss_data: 0.0219, Loss_ode: 0.2889\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6770, Loss_data: 0.0216, Loss_ode: 0.2717\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6780, Loss_data: 0.0215, Loss_ode: 0.2735\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6790, Loss_data: 0.0206, Loss_ode: 0.3101\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6800, Loss_data: 0.0211, Loss_ode: 0.2778\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6810, Loss_data: 0.0218, Loss_ode: 0.2788\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6820, Loss_data: 0.0211, Loss_ode: 0.2675\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6830, Loss_data: 0.0206, Loss_ode: 0.3172\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6840, Loss_data: 0.0212, Loss_ode: 0.2711\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6850, Loss_data: 0.0212, Loss_ode: 0.2776\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6860, Loss_data: 0.0210, Loss_ode: 0.2680\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6870, Loss_data: 0.0210, Loss_ode: 0.2652\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6880, Loss_data: 0.0217, Loss_ode: 0.3331\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6890, Loss_data: 0.0208, Loss_ode: 0.2687\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6900, Loss_data: 0.0216, Loss_ode: 0.2920\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6910, Loss_data: 0.0208, Loss_ode: 0.2788\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6920, Loss_data: 0.0211, Loss_ode: 0.2662\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6930, Loss_data: 0.0209, Loss_ode: 0.2641\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6940, Loss_data: 0.0204, Loss_ode: 0.3011\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6950, Loss_data: 0.0206, Loss_ode: 0.2643\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6960, Loss_data: 0.0208, Loss_ode: 0.2658\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6970, Loss_data: 0.0205, Loss_ode: 0.2827\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6980, Loss_data: 0.0210, Loss_ode: 0.2820\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 6990, Loss_data: 0.0210, Loss_ode: 0.2794\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7000, Loss_data: 0.0205, Loss_ode: 0.2721\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7010, Loss_data: 0.0206, Loss_ode: 0.2730\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7020, Loss_data: 0.0207, Loss_ode: 0.2635\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7030, Loss_data: 0.0210, Loss_ode: 0.2731\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7040, Loss_data: 0.0219, Loss_ode: 0.3951\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7050, Loss_data: 0.0198, Loss_ode: 0.3158\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7060, Loss_data: 0.0211, Loss_ode: 0.2689\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7070, Loss_data: 0.0207, Loss_ode: 0.2570\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7080, Loss_data: 0.0209, Loss_ode: 0.2785\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7090, Loss_data: 0.0204, Loss_ode: 0.2699\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7100, Loss_data: 0.0202, Loss_ode: 0.2653\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7110, Loss_data: 0.0208, Loss_ode: 0.2663\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7120, Loss_data: 0.0212, Loss_ode: 0.3383\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7130, Loss_data: 0.0199, Loss_ode: 0.2776\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7140, Loss_data: 0.0203, Loss_ode: 0.2594\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7150, Loss_data: 0.0202, Loss_ode: 0.2624\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7160, Loss_data: 0.0205, Loss_ode: 0.2669\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7170, Loss_data: 0.0212, Loss_ode: 0.3646\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7180, Loss_data: 0.0202, Loss_ode: 0.2590\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7190, Loss_data: 0.0200, Loss_ode: 0.2623\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7200, Loss_data: 0.0203, Loss_ode: 0.2597\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7210, Loss_data: 0.0200, Loss_ode: 0.2560\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7220, Loss_data: 0.0201, Loss_ode: 0.2620\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7230, Loss_data: 0.0204, Loss_ode: 0.2909\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7240, Loss_data: 0.0202, Loss_ode: 0.2624\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7250, Loss_data: 0.0200, Loss_ode: 0.2550\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7260, Loss_data: 0.0203, Loss_ode: 0.2623\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7270, Loss_data: 0.0205, Loss_ode: 0.3328\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7280, Loss_data: 0.0196, Loss_ode: 0.2587\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7290, Loss_data: 0.0199, Loss_ode: 0.2558\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7300, Loss_data: 0.0205, Loss_ode: 0.2809\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7310, Loss_data: 0.0200, Loss_ode: 0.2672\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7320, Loss_data: 0.0197, Loss_ode: 0.2684\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7330, Loss_data: 0.0197, Loss_ode: 0.2639\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7340, Loss_data: 0.0200, Loss_ode: 0.2631\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7350, Loss_data: 0.0202, Loss_ode: 0.3170\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7360, Loss_data: 0.0192, Loss_ode: 0.2880\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7370, Loss_data: 0.0197, Loss_ode: 0.2591\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7380, Loss_data: 0.0199, Loss_ode: 0.2671\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7390, Loss_data: 0.0197, Loss_ode: 0.2564\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7400, Loss_data: 0.0194, Loss_ode: 0.2651\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7410, Loss_data: 0.0188, Loss_ode: 0.3715\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7420, Loss_data: 0.0193, Loss_ode: 0.2543\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7430, Loss_data: 0.0197, Loss_ode: 0.2576\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7440, Loss_data: 0.0197, Loss_ode: 0.2552\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7450, Loss_data: 0.0193, Loss_ode: 0.2730\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7460, Loss_data: 0.0193, Loss_ode: 0.2629\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7470, Loss_data: 0.0196, Loss_ode: 0.2709\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7480, Loss_data: 0.0191, Loss_ode: 0.2592\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7490, Loss_data: 0.0190, Loss_ode: 0.2791\n",
      "Current learning rate:  4.899999999999999e-05\n",
      "Epoch 7500, Loss_data: 0.0190, Loss_ode: 0.2650\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7510, Loss_data: 0.0192, Loss_ode: 0.2532\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7520, Loss_data: 0.0192, Loss_ode: 0.2526\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7530, Loss_data: 0.0196, Loss_ode: 0.2487\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7540, Loss_data: 0.0192, Loss_ode: 0.2509\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7550, Loss_data: 0.0193, Loss_ode: 0.2548\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7560, Loss_data: 0.0192, Loss_ode: 0.2500\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7570, Loss_data: 0.0191, Loss_ode: 0.2538\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7580, Loss_data: 0.0192, Loss_ode: 0.2536\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7590, Loss_data: 0.0192, Loss_ode: 0.2465\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7600, Loss_data: 0.0192, Loss_ode: 0.2458\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7610, Loss_data: 0.0190, Loss_ode: 0.2487\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7620, Loss_data: 0.0191, Loss_ode: 0.2490\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7630, Loss_data: 0.0190, Loss_ode: 0.2469\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7640, Loss_data: 0.0190, Loss_ode: 0.2522\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7650, Loss_data: 0.0191, Loss_ode: 0.2476\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7660, Loss_data: 0.0192, Loss_ode: 0.2531\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7670, Loss_data: 0.0191, Loss_ode: 0.2495\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7680, Loss_data: 0.0190, Loss_ode: 0.2471\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7690, Loss_data: 0.0190, Loss_ode: 0.2546\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7700, Loss_data: 0.0188, Loss_ode: 0.2520\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7710, Loss_data: 0.0189, Loss_ode: 0.2518\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7720, Loss_data: 0.0190, Loss_ode: 0.2508\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7730, Loss_data: 0.0190, Loss_ode: 0.2420\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7740, Loss_data: 0.0188, Loss_ode: 0.2481\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7750, Loss_data: 0.0187, Loss_ode: 0.2478\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7760, Loss_data: 0.0189, Loss_ode: 0.2547\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7770, Loss_data: 0.0190, Loss_ode: 0.2506\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7780, Loss_data: 0.0187, Loss_ode: 0.2480\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7790, Loss_data: 0.0186, Loss_ode: 0.2512\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7800, Loss_data: 0.0186, Loss_ode: 0.2533\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7810, Loss_data: 0.0187, Loss_ode: 0.2471\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7820, Loss_data: 0.0186, Loss_ode: 0.2432\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7830, Loss_data: 0.0186, Loss_ode: 0.2439\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7840, Loss_data: 0.0188, Loss_ode: 0.2426\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7850, Loss_data: 0.0187, Loss_ode: 0.2458\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7860, Loss_data: 0.0186, Loss_ode: 0.2501\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7870, Loss_data: 0.0188, Loss_ode: 0.2468\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7880, Loss_data: 0.0186, Loss_ode: 0.2416\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7890, Loss_data: 0.0185, Loss_ode: 0.2509\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7900, Loss_data: 0.0184, Loss_ode: 0.2468\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7910, Loss_data: 0.0186, Loss_ode: 0.2437\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7920, Loss_data: 0.0186, Loss_ode: 0.2486\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7930, Loss_data: 0.0184, Loss_ode: 0.2445\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7940, Loss_data: 0.0185, Loss_ode: 0.2450\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7950, Loss_data: 0.0185, Loss_ode: 0.2465\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7960, Loss_data: 0.0184, Loss_ode: 0.2436\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7970, Loss_data: 0.0182, Loss_ode: 0.2388\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7980, Loss_data: 0.0183, Loss_ode: 0.2457\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 7990, Loss_data: 0.0184, Loss_ode: 0.2482\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8000, Loss_data: 0.0183, Loss_ode: 0.2457\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8010, Loss_data: 0.0182, Loss_ode: 0.2438\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8020, Loss_data: 0.0183, Loss_ode: 0.2433\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8030, Loss_data: 0.0181, Loss_ode: 0.2442\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8040, Loss_data: 0.0182, Loss_ode: 0.2477\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8050, Loss_data: 0.0182, Loss_ode: 0.2442\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8060, Loss_data: 0.0182, Loss_ode: 0.2435\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8070, Loss_data: 0.0181, Loss_ode: 0.2496\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8080, Loss_data: 0.0181, Loss_ode: 0.2415\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8090, Loss_data: 0.0182, Loss_ode: 0.2444\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8100, Loss_data: 0.0180, Loss_ode: 0.2448\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8110, Loss_data: 0.0179, Loss_ode: 0.2467\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8120, Loss_data: 0.0181, Loss_ode: 0.2395\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8130, Loss_data: 0.0178, Loss_ode: 0.2424\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8140, Loss_data: 0.0179, Loss_ode: 0.2412\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8150, Loss_data: 0.0178, Loss_ode: 0.2438\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8160, Loss_data: 0.0177, Loss_ode: 0.2395\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8170, Loss_data: 0.0178, Loss_ode: 0.2416\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8180, Loss_data: 0.0180, Loss_ode: 0.2456\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8190, Loss_data: 0.0180, Loss_ode: 0.2551\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8200, Loss_data: 0.0180, Loss_ode: 0.2394\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8210, Loss_data: 0.0179, Loss_ode: 0.2466\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8220, Loss_data: 0.0177, Loss_ode: 0.2555\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8230, Loss_data: 0.0180, Loss_ode: 0.2511\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8240, Loss_data: 0.0177, Loss_ode: 0.2408\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8250, Loss_data: 0.0177, Loss_ode: 0.2403\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8260, Loss_data: 0.0177, Loss_ode: 0.2381\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8270, Loss_data: 0.0176, Loss_ode: 0.2454\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8280, Loss_data: 0.0173, Loss_ode: 0.2754\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8290, Loss_data: 0.0177, Loss_ode: 0.2380\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8300, Loss_data: 0.0180, Loss_ode: 0.2337\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8310, Loss_data: 0.0175, Loss_ode: 0.2428\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8320, Loss_data: 0.0175, Loss_ode: 0.2498\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8330, Loss_data: 0.0174, Loss_ode: 0.2609\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8340, Loss_data: 0.0177, Loss_ode: 0.2472\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8350, Loss_data: 0.0178, Loss_ode: 0.2418\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8360, Loss_data: 0.0172, Loss_ode: 0.2551\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8370, Loss_data: 0.0171, Loss_ode: 0.2700\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8380, Loss_data: 0.0176, Loss_ode: 0.2354\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8390, Loss_data: 0.0176, Loss_ode: 0.2471\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8400, Loss_data: 0.0175, Loss_ode: 0.2353\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8410, Loss_data: 0.0175, Loss_ode: 0.2430\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8420, Loss_data: 0.0175, Loss_ode: 0.2366\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8430, Loss_data: 0.0173, Loss_ode: 0.2388\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8440, Loss_data: 0.0169, Loss_ode: 0.2529\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8450, Loss_data: 0.0171, Loss_ode: 0.2353\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8460, Loss_data: 0.0175, Loss_ode: 0.2443\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8470, Loss_data: 0.0177, Loss_ode: 0.2544\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8480, Loss_data: 0.0175, Loss_ode: 0.2453\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8490, Loss_data: 0.0172, Loss_ode: 0.2395\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8500, Loss_data: 0.0174, Loss_ode: 0.2359\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8510, Loss_data: 0.0174, Loss_ode: 0.2388\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8520, Loss_data: 0.0172, Loss_ode: 0.2329\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8530, Loss_data: 0.0171, Loss_ode: 0.2388\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8540, Loss_data: 0.0173, Loss_ode: 0.2386\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8550, Loss_data: 0.0176, Loss_ode: 0.2940\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8560, Loss_data: 0.0166, Loss_ode: 0.2563\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8570, Loss_data: 0.0172, Loss_ode: 0.2471\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8580, Loss_data: 0.0169, Loss_ode: 0.2369\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8590, Loss_data: 0.0169, Loss_ode: 0.2476\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8600, Loss_data: 0.0166, Loss_ode: 0.2377\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8610, Loss_data: 0.0171, Loss_ode: 0.2421\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8620, Loss_data: 0.0172, Loss_ode: 0.2456\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8630, Loss_data: 0.0169, Loss_ode: 0.2458\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8640, Loss_data: 0.0165, Loss_ode: 0.2557\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8650, Loss_data: 0.0167, Loss_ode: 0.2358\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8660, Loss_data: 0.0168, Loss_ode: 0.2387\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8670, Loss_data: 0.0172, Loss_ode: 0.2393\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8680, Loss_data: 0.0171, Loss_ode: 0.2425\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8690, Loss_data: 0.0167, Loss_ode: 0.2430\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8700, Loss_data: 0.0166, Loss_ode: 0.2449\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8710, Loss_data: 0.0169, Loss_ode: 0.2364\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8720, Loss_data: 0.0168, Loss_ode: 0.2360\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8730, Loss_data: 0.0164, Loss_ode: 0.2505\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8740, Loss_data: 0.0165, Loss_ode: 0.2439\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8750, Loss_data: 0.0170, Loss_ode: 0.2417\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8760, Loss_data: 0.0166, Loss_ode: 0.2380\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8770, Loss_data: 0.0164, Loss_ode: 0.2468\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8780, Loss_data: 0.0163, Loss_ode: 0.2382\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8790, Loss_data: 0.0167, Loss_ode: 0.2367\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8800, Loss_data: 0.0167, Loss_ode: 0.2381\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8810, Loss_data: 0.0166, Loss_ode: 0.2354\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8820, Loss_data: 0.0161, Loss_ode: 0.2569\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8830, Loss_data: 0.0165, Loss_ode: 0.2382\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8840, Loss_data: 0.0168, Loss_ode: 0.2364\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8850, Loss_data: 0.0165, Loss_ode: 0.2374\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8860, Loss_data: 0.0162, Loss_ode: 0.2325\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8870, Loss_data: 0.0161, Loss_ode: 0.2562\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8880, Loss_data: 0.0162, Loss_ode: 0.2316\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8890, Loss_data: 0.0167, Loss_ode: 0.2427\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8900, Loss_data: 0.0165, Loss_ode: 0.2324\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8910, Loss_data: 0.0160, Loss_ode: 0.2478\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8920, Loss_data: 0.0161, Loss_ode: 0.2535\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8930, Loss_data: 0.0165, Loss_ode: 0.2395\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8940, Loss_data: 0.0163, Loss_ode: 0.2383\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8950, Loss_data: 0.0163, Loss_ode: 0.2480\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8960, Loss_data: 0.0160, Loss_ode: 0.2492\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8970, Loss_data: 0.0159, Loss_ode: 0.2343\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8980, Loss_data: 0.0164, Loss_ode: 0.2371\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 8990, Loss_data: 0.0162, Loss_ode: 0.2339\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9000, Loss_data: 0.0164, Loss_ode: 0.2337\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9010, Loss_data: 0.0168, Loss_ode: 0.2410\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9020, Loss_data: 0.0159, Loss_ode: 0.2330\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9030, Loss_data: 0.0164, Loss_ode: 0.2299\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9040, Loss_data: 0.0163, Loss_ode: 0.2428\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9050, Loss_data: 0.0163, Loss_ode: 0.2372\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9060, Loss_data: 0.0163, Loss_ode: 0.2319\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9070, Loss_data: 0.0160, Loss_ode: 0.2394\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9080, Loss_data: 0.0160, Loss_ode: 0.2328\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9090, Loss_data: 0.0163, Loss_ode: 0.2311\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9100, Loss_data: 0.0162, Loss_ode: 0.2435\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9110, Loss_data: 0.0168, Loss_ode: 0.2952\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9120, Loss_data: 0.0155, Loss_ode: 0.2503\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9130, Loss_data: 0.0164, Loss_ode: 0.2405\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9140, Loss_data: 0.0159, Loss_ode: 0.2364\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9150, Loss_data: 0.0162, Loss_ode: 0.2296\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9160, Loss_data: 0.0159, Loss_ode: 0.2317\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9170, Loss_data: 0.0159, Loss_ode: 0.2378\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9180, Loss_data: 0.0155, Loss_ode: 0.2710\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9190, Loss_data: 0.0165, Loss_ode: 0.2484\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9200, Loss_data: 0.0156, Loss_ode: 0.2483\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9210, Loss_data: 0.0160, Loss_ode: 0.2373\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9220, Loss_data: 0.0159, Loss_ode: 0.2335\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9230, Loss_data: 0.0157, Loss_ode: 0.2334\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9240, Loss_data: 0.0159, Loss_ode: 0.2310\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9250, Loss_data: 0.0162, Loss_ode: 0.2421\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9260, Loss_data: 0.0160, Loss_ode: 0.2324\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9270, Loss_data: 0.0155, Loss_ode: 0.2458\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9280, Loss_data: 0.0154, Loss_ode: 0.2374\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9290, Loss_data: 0.0159, Loss_ode: 0.2351\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9300, Loss_data: 0.0162, Loss_ode: 0.2417\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9310, Loss_data: 0.0157, Loss_ode: 0.2305\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9320, Loss_data: 0.0155, Loss_ode: 0.2419\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9330, Loss_data: 0.0156, Loss_ode: 0.2376\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9340, Loss_data: 0.0156, Loss_ode: 0.2269\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9350, Loss_data: 0.0162, Loss_ode: 0.2628\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9360, Loss_data: 0.0157, Loss_ode: 0.2298\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9370, Loss_data: 0.0158, Loss_ode: 0.2246\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9380, Loss_data: 0.0157, Loss_ode: 0.2339\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9390, Loss_data: 0.0152, Loss_ode: 0.2514\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9400, Loss_data: 0.0154, Loss_ode: 0.2246\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9410, Loss_data: 0.0157, Loss_ode: 0.2305\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9420, Loss_data: 0.0157, Loss_ode: 0.2336\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9430, Loss_data: 0.0157, Loss_ode: 0.2368\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9440, Loss_data: 0.0154, Loss_ode: 0.2337\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9450, Loss_data: 0.0156, Loss_ode: 0.2346\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9460, Loss_data: 0.0157, Loss_ode: 0.2271\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9470, Loss_data: 0.0160, Loss_ode: 0.2450\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9480, Loss_data: 0.0158, Loss_ode: 0.2467\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9490, Loss_data: 0.0155, Loss_ode: 0.2278\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9500, Loss_data: 0.0154, Loss_ode: 0.2274\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9510, Loss_data: 0.0153, Loss_ode: 0.2351\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9520, Loss_data: 0.0155, Loss_ode: 0.2283\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9530, Loss_data: 0.0155, Loss_ode: 0.2344\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9540, Loss_data: 0.0158, Loss_ode: 0.2686\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9550, Loss_data: 0.0149, Loss_ode: 0.2518\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9560, Loss_data: 0.0153, Loss_ode: 0.2308\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9570, Loss_data: 0.0156, Loss_ode: 0.2220\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9580, Loss_data: 0.0155, Loss_ode: 0.2321\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9590, Loss_data: 0.0154, Loss_ode: 0.2301\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9600, Loss_data: 0.0155, Loss_ode: 0.2533\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9610, Loss_data: 0.0148, Loss_ode: 0.2312\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9620, Loss_data: 0.0152, Loss_ode: 0.2340\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9630, Loss_data: 0.0154, Loss_ode: 0.2304\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9640, Loss_data: 0.0154, Loss_ode: 0.2395\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9650, Loss_data: 0.0151, Loss_ode: 0.2270\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9660, Loss_data: 0.0151, Loss_ode: 0.2288\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9670, Loss_data: 0.0148, Loss_ode: 0.2970\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9680, Loss_data: 0.0156, Loss_ode: 0.2492\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9690, Loss_data: 0.0151, Loss_ode: 0.2232\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9700, Loss_data: 0.0150, Loss_ode: 0.2250\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9710, Loss_data: 0.0152, Loss_ode: 0.2281\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9720, Loss_data: 0.0149, Loss_ode: 0.2276\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9730, Loss_data: 0.0152, Loss_ode: 0.2266\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9740, Loss_data: 0.0151, Loss_ode: 0.2249\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9750, Loss_data: 0.0149, Loss_ode: 0.2224\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9760, Loss_data: 0.0154, Loss_ode: 0.2424\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9770, Loss_data: 0.0150, Loss_ode: 0.2285\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9780, Loss_data: 0.0150, Loss_ode: 0.2192\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9790, Loss_data: 0.0153, Loss_ode: 0.2281\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9800, Loss_data: 0.0154, Loss_ode: 0.2659\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9810, Loss_data: 0.0146, Loss_ode: 0.2375\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9820, Loss_data: 0.0151, Loss_ode: 0.2257\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9830, Loss_data: 0.0150, Loss_ode: 0.2294\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9840, Loss_data: 0.0148, Loss_ode: 0.2257\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9850, Loss_data: 0.0146, Loss_ode: 0.2293\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9860, Loss_data: 0.0143, Loss_ode: 0.2534\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9870, Loss_data: 0.0148, Loss_ode: 0.2229\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9880, Loss_data: 0.0148, Loss_ode: 0.2233\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9890, Loss_data: 0.0146, Loss_ode: 0.2342\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9900, Loss_data: 0.0146, Loss_ode: 0.2470\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9910, Loss_data: 0.0150, Loss_ode: 0.2347\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9920, Loss_data: 0.0145, Loss_ode: 0.2195\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9930, Loss_data: 0.0146, Loss_ode: 0.2241\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9940, Loss_data: 0.0144, Loss_ode: 0.2286\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9950, Loss_data: 0.0147, Loss_ode: 0.2306\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9960, Loss_data: 0.0142, Loss_ode: 0.2528\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9970, Loss_data: 0.0145, Loss_ode: 0.2260\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9980, Loss_data: 0.0150, Loss_ode: 0.2355\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 9990, Loss_data: 0.0148, Loss_ode: 0.2356\n",
      "Current learning rate:  3.4299999999999993e-05\n",
      "Epoch 10000, Loss_data: 0.0148, Loss_ode: 0.2267\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10010, Loss_data: 0.0147, Loss_ode: 0.2234\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10020, Loss_data: 0.0146, Loss_ode: 0.2206\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10030, Loss_data: 0.0146, Loss_ode: 0.2242\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10040, Loss_data: 0.0146, Loss_ode: 0.2292\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10050, Loss_data: 0.0146, Loss_ode: 0.2179\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10060, Loss_data: 0.0146, Loss_ode: 0.2263\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10070, Loss_data: 0.0145, Loss_ode: 0.2206\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10080, Loss_data: 0.0145, Loss_ode: 0.2233\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10090, Loss_data: 0.0144, Loss_ode: 0.2250\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10100, Loss_data: 0.0148, Loss_ode: 0.2191\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10110, Loss_data: 0.0146, Loss_ode: 0.2182\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10120, Loss_data: 0.0144, Loss_ode: 0.2200\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10130, Loss_data: 0.0146, Loss_ode: 0.2230\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10140, Loss_data: 0.0145, Loss_ode: 0.2240\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10150, Loss_data: 0.0143, Loss_ode: 0.2243\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10160, Loss_data: 0.0143, Loss_ode: 0.2255\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10170, Loss_data: 0.0144, Loss_ode: 0.2240\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10180, Loss_data: 0.0145, Loss_ode: 0.2178\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10190, Loss_data: 0.0144, Loss_ode: 0.2224\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10200, Loss_data: 0.0145, Loss_ode: 0.2222\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10210, Loss_data: 0.0142, Loss_ode: 0.2264\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10220, Loss_data: 0.0142, Loss_ode: 0.2239\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10230, Loss_data: 0.0144, Loss_ode: 0.2186\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10240, Loss_data: 0.0143, Loss_ode: 0.2176\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10250, Loss_data: 0.0144, Loss_ode: 0.2219\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10260, Loss_data: 0.0144, Loss_ode: 0.2216\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10270, Loss_data: 0.0142, Loss_ode: 0.2224\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10280, Loss_data: 0.0143, Loss_ode: 0.2261\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10290, Loss_data: 0.0142, Loss_ode: 0.2211\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10300, Loss_data: 0.0142, Loss_ode: 0.2164\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10310, Loss_data: 0.0142, Loss_ode: 0.2261\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10320, Loss_data: 0.0142, Loss_ode: 0.2174\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10330, Loss_data: 0.0142, Loss_ode: 0.2160\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10340, Loss_data: 0.0142, Loss_ode: 0.2175\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10350, Loss_data: 0.0142, Loss_ode: 0.2206\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10360, Loss_data: 0.0142, Loss_ode: 0.2174\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10370, Loss_data: 0.0141, Loss_ode: 0.2296\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10380, Loss_data: 0.0141, Loss_ode: 0.2197\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10390, Loss_data: 0.0141, Loss_ode: 0.2172\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10400, Loss_data: 0.0141, Loss_ode: 0.2206\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10410, Loss_data: 0.0141, Loss_ode: 0.2213\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10420, Loss_data: 0.0141, Loss_ode: 0.2191\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10430, Loss_data: 0.0142, Loss_ode: 0.2258\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10440, Loss_data: 0.0140, Loss_ode: 0.2188\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10450, Loss_data: 0.0139, Loss_ode: 0.2198\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10460, Loss_data: 0.0139, Loss_ode: 0.2128\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10470, Loss_data: 0.0140, Loss_ode: 0.2187\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10480, Loss_data: 0.0142, Loss_ode: 0.2214\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10490, Loss_data: 0.0141, Loss_ode: 0.2207\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10500, Loss_data: 0.0140, Loss_ode: 0.2219\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10510, Loss_data: 0.0139, Loss_ode: 0.2165\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10520, Loss_data: 0.0137, Loss_ode: 0.2189\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10530, Loss_data: 0.0139, Loss_ode: 0.2191\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10540, Loss_data: 0.0138, Loss_ode: 0.2176\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10550, Loss_data: 0.0139, Loss_ode: 0.2226\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10560, Loss_data: 0.0140, Loss_ode: 0.2201\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10570, Loss_data: 0.0140, Loss_ode: 0.2222\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10580, Loss_data: 0.0140, Loss_ode: 0.2222\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10590, Loss_data: 0.0141, Loss_ode: 0.2224\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10600, Loss_data: 0.0138, Loss_ode: 0.2144\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10610, Loss_data: 0.0138, Loss_ode: 0.2205\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10620, Loss_data: 0.0138, Loss_ode: 0.2158\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10630, Loss_data: 0.0137, Loss_ode: 0.2245\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10640, Loss_data: 0.0138, Loss_ode: 0.2153\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10650, Loss_data: 0.0138, Loss_ode: 0.2258\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10660, Loss_data: 0.0137, Loss_ode: 0.2236\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10670, Loss_data: 0.0139, Loss_ode: 0.2220\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10680, Loss_data: 0.0137, Loss_ode: 0.2288\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10690, Loss_data: 0.0137, Loss_ode: 0.2179\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10700, Loss_data: 0.0139, Loss_ode: 0.2202\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10710, Loss_data: 0.0138, Loss_ode: 0.2199\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10720, Loss_data: 0.0137, Loss_ode: 0.2203\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10730, Loss_data: 0.0138, Loss_ode: 0.2219\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10740, Loss_data: 0.0139, Loss_ode: 0.2198\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10750, Loss_data: 0.0139, Loss_ode: 0.2183\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10760, Loss_data: 0.0134, Loss_ode: 0.2323\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10770, Loss_data: 0.0135, Loss_ode: 0.2148\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10780, Loss_data: 0.0136, Loss_ode: 0.2248\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10790, Loss_data: 0.0136, Loss_ode: 0.2185\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10800, Loss_data: 0.0137, Loss_ode: 0.2164\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10810, Loss_data: 0.0134, Loss_ode: 0.2273\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10820, Loss_data: 0.0134, Loss_ode: 0.2224\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10830, Loss_data: 0.0137, Loss_ode: 0.2175\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10840, Loss_data: 0.0135, Loss_ode: 0.2169\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10850, Loss_data: 0.0134, Loss_ode: 0.2198\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10860, Loss_data: 0.0135, Loss_ode: 0.2227\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10870, Loss_data: 0.0137, Loss_ode: 0.2232\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10880, Loss_data: 0.0136, Loss_ode: 0.2162\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10890, Loss_data: 0.0136, Loss_ode: 0.2172\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10900, Loss_data: 0.0135, Loss_ode: 0.2157\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10910, Loss_data: 0.0135, Loss_ode: 0.2212\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10920, Loss_data: 0.0132, Loss_ode: 0.2303\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10930, Loss_data: 0.0131, Loss_ode: 0.2226\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10940, Loss_data: 0.0134, Loss_ode: 0.2206\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10950, Loss_data: 0.0135, Loss_ode: 0.2226\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10960, Loss_data: 0.0134, Loss_ode: 0.2174\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10970, Loss_data: 0.0137, Loss_ode: 0.2257\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10980, Loss_data: 0.0134, Loss_ode: 0.2175\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 10990, Loss_data: 0.0131, Loss_ode: 0.2205\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11000, Loss_data: 0.0131, Loss_ode: 0.2341\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11010, Loss_data: 0.0134, Loss_ode: 0.2190\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11020, Loss_data: 0.0134, Loss_ode: 0.2188\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11030, Loss_data: 0.0133, Loss_ode: 0.2142\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11040, Loss_data: 0.0134, Loss_ode: 0.2178\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11050, Loss_data: 0.0132, Loss_ode: 0.2183\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11060, Loss_data: 0.0135, Loss_ode: 0.2203\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11070, Loss_data: 0.0131, Loss_ode: 0.2221\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11080, Loss_data: 0.0133, Loss_ode: 0.2195\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11090, Loss_data: 0.0130, Loss_ode: 0.2218\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11100, Loss_data: 0.0132, Loss_ode: 0.2200\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11110, Loss_data: 0.0134, Loss_ode: 0.2262\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11120, Loss_data: 0.0131, Loss_ode: 0.2210\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11130, Loss_data: 0.0131, Loss_ode: 0.2115\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11140, Loss_data: 0.0134, Loss_ode: 0.2203\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11150, Loss_data: 0.0129, Loss_ode: 0.2278\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11160, Loss_data: 0.0133, Loss_ode: 0.2185\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11170, Loss_data: 0.0131, Loss_ode: 0.2167\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11180, Loss_data: 0.0133, Loss_ode: 0.2219\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11190, Loss_data: 0.0130, Loss_ode: 0.2153\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11200, Loss_data: 0.0129, Loss_ode: 0.2225\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11210, Loss_data: 0.0129, Loss_ode: 0.2251\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11220, Loss_data: 0.0130, Loss_ode: 0.2165\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11230, Loss_data: 0.0131, Loss_ode: 0.2151\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11240, Loss_data: 0.0134, Loss_ode: 0.2290\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11250, Loss_data: 0.0132, Loss_ode: 0.2188\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11260, Loss_data: 0.0131, Loss_ode: 0.2175\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11270, Loss_data: 0.0131, Loss_ode: 0.2180\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11280, Loss_data: 0.0131, Loss_ode: 0.2147\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11290, Loss_data: 0.0129, Loss_ode: 0.2202\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11300, Loss_data: 0.0129, Loss_ode: 0.2228\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11310, Loss_data: 0.0130, Loss_ode: 0.2117\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11320, Loss_data: 0.0132, Loss_ode: 0.2206\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11330, Loss_data: 0.0128, Loss_ode: 0.2116\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11340, Loss_data: 0.0129, Loss_ode: 0.2132\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11350, Loss_data: 0.0131, Loss_ode: 0.2222\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11360, Loss_data: 0.0128, Loss_ode: 0.2220\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11370, Loss_data: 0.0128, Loss_ode: 0.2162\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11380, Loss_data: 0.0130, Loss_ode: 0.2174\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11390, Loss_data: 0.0132, Loss_ode: 0.2244\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11400, Loss_data: 0.0127, Loss_ode: 0.2122\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11410, Loss_data: 0.0128, Loss_ode: 0.2202\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11420, Loss_data: 0.0125, Loss_ode: 0.2175\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11430, Loss_data: 0.0131, Loss_ode: 0.2168\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11440, Loss_data: 0.0129, Loss_ode: 0.2096\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11450, Loss_data: 0.0129, Loss_ode: 0.2183\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11460, Loss_data: 0.0129, Loss_ode: 0.2145\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11470, Loss_data: 0.0128, Loss_ode: 0.2121\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11480, Loss_data: 0.0127, Loss_ode: 0.2192\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11490, Loss_data: 0.0125, Loss_ode: 0.2273\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11500, Loss_data: 0.0130, Loss_ode: 0.2124\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11510, Loss_data: 0.0131, Loss_ode: 0.2282\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11520, Loss_data: 0.0128, Loss_ode: 0.2185\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11530, Loss_data: 0.0126, Loss_ode: 0.2152\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11540, Loss_data: 0.0128, Loss_ode: 0.2155\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11550, Loss_data: 0.0127, Loss_ode: 0.2152\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11560, Loss_data: 0.0126, Loss_ode: 0.2132\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11570, Loss_data: 0.0125, Loss_ode: 0.2195\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11580, Loss_data: 0.0126, Loss_ode: 0.2192\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11590, Loss_data: 0.0130, Loss_ode: 0.2215\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11600, Loss_data: 0.0128, Loss_ode: 0.2175\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11610, Loss_data: 0.0127, Loss_ode: 0.2167\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11620, Loss_data: 0.0125, Loss_ode: 0.2162\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11630, Loss_data: 0.0125, Loss_ode: 0.2142\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11640, Loss_data: 0.0127, Loss_ode: 0.2148\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11650, Loss_data: 0.0132, Loss_ode: 0.2613\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11660, Loss_data: 0.0123, Loss_ode: 0.2311\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11670, Loss_data: 0.0128, Loss_ode: 0.2170\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11680, Loss_data: 0.0124, Loss_ode: 0.2135\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11690, Loss_data: 0.0126, Loss_ode: 0.2136\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11700, Loss_data: 0.0124, Loss_ode: 0.2188\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11710, Loss_data: 0.0127, Loss_ode: 0.2144\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11720, Loss_data: 0.0123, Loss_ode: 0.2170\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11730, Loss_data: 0.0126, Loss_ode: 0.2106\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11740, Loss_data: 0.0126, Loss_ode: 0.2133\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11750, Loss_data: 0.0125, Loss_ode: 0.2149\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11760, Loss_data: 0.0125, Loss_ode: 0.2129\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11770, Loss_data: 0.0123, Loss_ode: 0.2132\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11780, Loss_data: 0.0126, Loss_ode: 0.2112\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11790, Loss_data: 0.0128, Loss_ode: 0.2079\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11800, Loss_data: 0.0128, Loss_ode: 0.2234\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11810, Loss_data: 0.0123, Loss_ode: 0.2155\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11820, Loss_data: 0.0125, Loss_ode: 0.2102\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11830, Loss_data: 0.0124, Loss_ode: 0.2129\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11840, Loss_data: 0.0126, Loss_ode: 0.2070\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11850, Loss_data: 0.0124, Loss_ode: 0.2120\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11860, Loss_data: 0.0128, Loss_ode: 0.2261\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11870, Loss_data: 0.0124, Loss_ode: 0.2117\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11880, Loss_data: 0.0124, Loss_ode: 0.2210\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11890, Loss_data: 0.0124, Loss_ode: 0.2080\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11900, Loss_data: 0.0125, Loss_ode: 0.2102\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11910, Loss_data: 0.0125, Loss_ode: 0.2126\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11920, Loss_data: 0.0123, Loss_ode: 0.2100\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11930, Loss_data: 0.0124, Loss_ode: 0.2127\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11940, Loss_data: 0.0122, Loss_ode: 0.2219\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11950, Loss_data: 0.0121, Loss_ode: 0.2194\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11960, Loss_data: 0.0126, Loss_ode: 0.2124\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11970, Loss_data: 0.0123, Loss_ode: 0.2098\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11980, Loss_data: 0.0122, Loss_ode: 0.2096\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 11990, Loss_data: 0.0122, Loss_ode: 0.2167\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12000, Loss_data: 0.0123, Loss_ode: 0.2080\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12010, Loss_data: 0.0128, Loss_ode: 0.2377\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12020, Loss_data: 0.0121, Loss_ode: 0.2094\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12030, Loss_data: 0.0121, Loss_ode: 0.2108\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12040, Loss_data: 0.0123, Loss_ode: 0.2117\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12050, Loss_data: 0.0123, Loss_ode: 0.2140\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12060, Loss_data: 0.0123, Loss_ode: 0.2101\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12070, Loss_data: 0.0122, Loss_ode: 0.2183\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12080, Loss_data: 0.0121, Loss_ode: 0.2141\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12090, Loss_data: 0.0124, Loss_ode: 0.2070\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12100, Loss_data: 0.0123, Loss_ode: 0.2106\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12110, Loss_data: 0.0122, Loss_ode: 0.2125\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12120, Loss_data: 0.0121, Loss_ode: 0.2060\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12130, Loss_data: 0.0121, Loss_ode: 0.2098\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12140, Loss_data: 0.0120, Loss_ode: 0.2262\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12150, Loss_data: 0.0121, Loss_ode: 0.2107\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12160, Loss_data: 0.0123, Loss_ode: 0.2085\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12170, Loss_data: 0.0122, Loss_ode: 0.2112\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12180, Loss_data: 0.0121, Loss_ode: 0.2098\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12190, Loss_data: 0.0120, Loss_ode: 0.2132\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12200, Loss_data: 0.0120, Loss_ode: 0.2157\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12210, Loss_data: 0.0124, Loss_ode: 0.2150\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12220, Loss_data: 0.0123, Loss_ode: 0.2062\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12230, Loss_data: 0.0121, Loss_ode: 0.2177\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12240, Loss_data: 0.0121, Loss_ode: 0.2107\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12250, Loss_data: 0.0119, Loss_ode: 0.2207\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12260, Loss_data: 0.0119, Loss_ode: 0.2144\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12270, Loss_data: 0.0121, Loss_ode: 0.2056\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12280, Loss_data: 0.0121, Loss_ode: 0.2116\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12290, Loss_data: 0.0119, Loss_ode: 0.2186\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12300, Loss_data: 0.0119, Loss_ode: 0.2072\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12310, Loss_data: 0.0123, Loss_ode: 0.2066\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12320, Loss_data: 0.0121, Loss_ode: 0.2068\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12330, Loss_data: 0.0121, Loss_ode: 0.2080\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12340, Loss_data: 0.0123, Loss_ode: 0.2091\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12350, Loss_data: 0.0122, Loss_ode: 0.2181\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12360, Loss_data: 0.0120, Loss_ode: 0.2122\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12370, Loss_data: 0.0115, Loss_ode: 0.2180\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12380, Loss_data: 0.0121, Loss_ode: 0.2069\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12390, Loss_data: 0.0120, Loss_ode: 0.2082\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12400, Loss_data: 0.0117, Loss_ode: 0.2078\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12410, Loss_data: 0.0118, Loss_ode: 0.2077\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12420, Loss_data: 0.0119, Loss_ode: 0.2081\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12430, Loss_data: 0.0117, Loss_ode: 0.2127\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12440, Loss_data: 0.0118, Loss_ode: 0.2112\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12450, Loss_data: 0.0117, Loss_ode: 0.2329\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12460, Loss_data: 0.0120, Loss_ode: 0.2093\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12470, Loss_data: 0.0120, Loss_ode: 0.2078\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12480, Loss_data: 0.0116, Loss_ode: 0.2129\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12490, Loss_data: 0.0120, Loss_ode: 0.2156\n",
      "Current learning rate:  2.4009999999999995e-05\n",
      "Epoch 12500, Loss_data: 0.0122, Loss_ode: 0.2236\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12510, Loss_data: 0.0119, Loss_ode: 0.2099\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12520, Loss_data: 0.0119, Loss_ode: 0.2048\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12530, Loss_data: 0.0118, Loss_ode: 0.2117\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12540, Loss_data: 0.0118, Loss_ode: 0.2073\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12550, Loss_data: 0.0118, Loss_ode: 0.2034\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12560, Loss_data: 0.0118, Loss_ode: 0.2058\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12570, Loss_data: 0.0117, Loss_ode: 0.2117\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12580, Loss_data: 0.0117, Loss_ode: 0.2023\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12590, Loss_data: 0.0119, Loss_ode: 0.2093\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12600, Loss_data: 0.0118, Loss_ode: 0.2106\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12610, Loss_data: 0.0118, Loss_ode: 0.2063\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12620, Loss_data: 0.0118, Loss_ode: 0.2065\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12630, Loss_data: 0.0118, Loss_ode: 0.2050\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12640, Loss_data: 0.0119, Loss_ode: 0.2130\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12650, Loss_data: 0.0120, Loss_ode: 0.2053\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12660, Loss_data: 0.0118, Loss_ode: 0.2072\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12670, Loss_data: 0.0118, Loss_ode: 0.2064\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12680, Loss_data: 0.0117, Loss_ode: 0.2091\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12690, Loss_data: 0.0117, Loss_ode: 0.2063\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12700, Loss_data: 0.0117, Loss_ode: 0.2083\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12710, Loss_data: 0.0118, Loss_ode: 0.2005\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12720, Loss_data: 0.0116, Loss_ode: 0.2048\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12730, Loss_data: 0.0117, Loss_ode: 0.2062\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12740, Loss_data: 0.0117, Loss_ode: 0.2045\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12750, Loss_data: 0.0117, Loss_ode: 0.2052\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12760, Loss_data: 0.0117, Loss_ode: 0.2013\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12770, Loss_data: 0.0117, Loss_ode: 0.2043\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12780, Loss_data: 0.0118, Loss_ode: 0.2087\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12790, Loss_data: 0.0118, Loss_ode: 0.2031\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12800, Loss_data: 0.0117, Loss_ode: 0.2099\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12810, Loss_data: 0.0119, Loss_ode: 0.2038\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12820, Loss_data: 0.0115, Loss_ode: 0.2119\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12830, Loss_data: 0.0117, Loss_ode: 0.2006\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12840, Loss_data: 0.0117, Loss_ode: 0.2084\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12850, Loss_data: 0.0116, Loss_ode: 0.2052\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12860, Loss_data: 0.0116, Loss_ode: 0.2111\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12870, Loss_data: 0.0116, Loss_ode: 0.2034\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12880, Loss_data: 0.0117, Loss_ode: 0.2038\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12890, Loss_data: 0.0116, Loss_ode: 0.2082\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12900, Loss_data: 0.0116, Loss_ode: 0.2079\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12910, Loss_data: 0.0117, Loss_ode: 0.2062\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12920, Loss_data: 0.0116, Loss_ode: 0.2033\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12930, Loss_data: 0.0117, Loss_ode: 0.2020\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12940, Loss_data: 0.0116, Loss_ode: 0.2029\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12950, Loss_data: 0.0116, Loss_ode: 0.2050\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12960, Loss_data: 0.0116, Loss_ode: 0.2064\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12970, Loss_data: 0.0117, Loss_ode: 0.2048\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12980, Loss_data: 0.0115, Loss_ode: 0.2019\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 12990, Loss_data: 0.0117, Loss_ode: 0.2019\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13000, Loss_data: 0.0116, Loss_ode: 0.2075\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13010, Loss_data: 0.0116, Loss_ode: 0.2059\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13020, Loss_data: 0.0117, Loss_ode: 0.2027\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13030, Loss_data: 0.0114, Loss_ode: 0.2047\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13040, Loss_data: 0.0117, Loss_ode: 0.2031\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13050, Loss_data: 0.0116, Loss_ode: 0.2006\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13060, Loss_data: 0.0116, Loss_ode: 0.2042\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13070, Loss_data: 0.0116, Loss_ode: 0.1994\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13080, Loss_data: 0.0115, Loss_ode: 0.2027\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13090, Loss_data: 0.0115, Loss_ode: 0.2030\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13100, Loss_data: 0.0115, Loss_ode: 0.2072\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13110, Loss_data: 0.0116, Loss_ode: 0.2050\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13120, Loss_data: 0.0114, Loss_ode: 0.2016\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13130, Loss_data: 0.0115, Loss_ode: 0.2041\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13140, Loss_data: 0.0117, Loss_ode: 0.2048\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13150, Loss_data: 0.0115, Loss_ode: 0.2056\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13160, Loss_data: 0.0115, Loss_ode: 0.2093\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13170, Loss_data: 0.0113, Loss_ode: 0.2051\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13180, Loss_data: 0.0114, Loss_ode: 0.2004\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13190, Loss_data: 0.0114, Loss_ode: 0.1993\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13200, Loss_data: 0.0116, Loss_ode: 0.2000\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13210, Loss_data: 0.0114, Loss_ode: 0.2022\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13220, Loss_data: 0.0114, Loss_ode: 0.2058\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13230, Loss_data: 0.0115, Loss_ode: 0.2026\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13240, Loss_data: 0.0116, Loss_ode: 0.2051\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13250, Loss_data: 0.0115, Loss_ode: 0.2022\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13260, Loss_data: 0.0114, Loss_ode: 0.2086\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13270, Loss_data: 0.0115, Loss_ode: 0.2068\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13280, Loss_data: 0.0115, Loss_ode: 0.2021\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13290, Loss_data: 0.0115, Loss_ode: 0.2026\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13300, Loss_data: 0.0116, Loss_ode: 0.1994\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13310, Loss_data: 0.0115, Loss_ode: 0.2036\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13320, Loss_data: 0.0114, Loss_ode: 0.1998\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13330, Loss_data: 0.0113, Loss_ode: 0.2029\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13340, Loss_data: 0.0113, Loss_ode: 0.2013\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13350, Loss_data: 0.0112, Loss_ode: 0.2038\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13360, Loss_data: 0.0110, Loss_ode: 0.2244\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13370, Loss_data: 0.0117, Loss_ode: 0.2100\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13380, Loss_data: 0.0114, Loss_ode: 0.2035\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13390, Loss_data: 0.0113, Loss_ode: 0.2034\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13400, Loss_data: 0.0114, Loss_ode: 0.1985\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13410, Loss_data: 0.0114, Loss_ode: 0.1996\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13420, Loss_data: 0.0112, Loss_ode: 0.1990\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13430, Loss_data: 0.0113, Loss_ode: 0.2047\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13440, Loss_data: 0.0114, Loss_ode: 0.2044\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13450, Loss_data: 0.0114, Loss_ode: 0.2008\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13460, Loss_data: 0.0112, Loss_ode: 0.2071\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13470, Loss_data: 0.0111, Loss_ode: 0.2162\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13480, Loss_data: 0.0114, Loss_ode: 0.2065\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13490, Loss_data: 0.0111, Loss_ode: 0.2004\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13500, Loss_data: 0.0113, Loss_ode: 0.1975\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13510, Loss_data: 0.0112, Loss_ode: 0.2045\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13520, Loss_data: 0.0113, Loss_ode: 0.2063\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13530, Loss_data: 0.0112, Loss_ode: 0.2029\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13540, Loss_data: 0.0113, Loss_ode: 0.1995\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13550, Loss_data: 0.0115, Loss_ode: 0.2047\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13560, Loss_data: 0.0112, Loss_ode: 0.2016\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13570, Loss_data: 0.0112, Loss_ode: 0.2001\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13580, Loss_data: 0.0114, Loss_ode: 0.2025\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13590, Loss_data: 0.0113, Loss_ode: 0.2011\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13600, Loss_data: 0.0113, Loss_ode: 0.2005\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13610, Loss_data: 0.0113, Loss_ode: 0.2036\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13620, Loss_data: 0.0111, Loss_ode: 0.2058\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13630, Loss_data: 0.0112, Loss_ode: 0.2014\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13640, Loss_data: 0.0111, Loss_ode: 0.2019\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13650, Loss_data: 0.0112, Loss_ode: 0.2048\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13660, Loss_data: 0.0112, Loss_ode: 0.1996\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13670, Loss_data: 0.0112, Loss_ode: 0.2053\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13680, Loss_data: 0.0117, Loss_ode: 0.2218\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13690, Loss_data: 0.0109, Loss_ode: 0.2049\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13700, Loss_data: 0.0113, Loss_ode: 0.2051\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13710, Loss_data: 0.0110, Loss_ode: 0.2077\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13720, Loss_data: 0.0113, Loss_ode: 0.1980\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13730, Loss_data: 0.0112, Loss_ode: 0.1997\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13740, Loss_data: 0.0111, Loss_ode: 0.1966\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13750, Loss_data: 0.0113, Loss_ode: 0.2001\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13760, Loss_data: 0.0111, Loss_ode: 0.2009\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13770, Loss_data: 0.0113, Loss_ode: 0.1987\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13780, Loss_data: 0.0113, Loss_ode: 0.2036\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13790, Loss_data: 0.0111, Loss_ode: 0.2038\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13800, Loss_data: 0.0110, Loss_ode: 0.2000\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13810, Loss_data: 0.0111, Loss_ode: 0.2025\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13820, Loss_data: 0.0112, Loss_ode: 0.1978\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13830, Loss_data: 0.0111, Loss_ode: 0.2066\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13840, Loss_data: 0.0109, Loss_ode: 0.2056\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13850, Loss_data: 0.0113, Loss_ode: 0.2040\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13860, Loss_data: 0.0110, Loss_ode: 0.2012\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13870, Loss_data: 0.0113, Loss_ode: 0.1976\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13880, Loss_data: 0.0111, Loss_ode: 0.2019\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13890, Loss_data: 0.0111, Loss_ode: 0.2058\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13900, Loss_data: 0.0111, Loss_ode: 0.1982\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13910, Loss_data: 0.0113, Loss_ode: 0.2003\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13920, Loss_data: 0.0110, Loss_ode: 0.2029\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13930, Loss_data: 0.0112, Loss_ode: 0.2013\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13940, Loss_data: 0.0111, Loss_ode: 0.1974\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13950, Loss_data: 0.0110, Loss_ode: 0.1975\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13960, Loss_data: 0.0113, Loss_ode: 0.1979\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13970, Loss_data: 0.0108, Loss_ode: 0.1966\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13980, Loss_data: 0.0111, Loss_ode: 0.2005\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 13990, Loss_data: 0.0111, Loss_ode: 0.2025\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14000, Loss_data: 0.0110, Loss_ode: 0.1985\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14010, Loss_data: 0.0111, Loss_ode: 0.2020\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14020, Loss_data: 0.0108, Loss_ode: 0.2067\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14030, Loss_data: 0.0111, Loss_ode: 0.1996\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14040, Loss_data: 0.0108, Loss_ode: 0.2024\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14050, Loss_data: 0.0113, Loss_ode: 0.1981\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14060, Loss_data: 0.0112, Loss_ode: 0.2029\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14070, Loss_data: 0.0108, Loss_ode: 0.2011\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14080, Loss_data: 0.0111, Loss_ode: 0.1977\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14090, Loss_data: 0.0110, Loss_ode: 0.1997\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14100, Loss_data: 0.0110, Loss_ode: 0.1959\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14110, Loss_data: 0.0112, Loss_ode: 0.2029\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14120, Loss_data: 0.0110, Loss_ode: 0.1992\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14130, Loss_data: 0.0110, Loss_ode: 0.2021\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14140, Loss_data: 0.0111, Loss_ode: 0.2009\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14150, Loss_data: 0.0110, Loss_ode: 0.2020\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14160, Loss_data: 0.0109, Loss_ode: 0.1965\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14170, Loss_data: 0.0112, Loss_ode: 0.1993\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14180, Loss_data: 0.0113, Loss_ode: 0.2049\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14190, Loss_data: 0.0108, Loss_ode: 0.2064\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14200, Loss_data: 0.0109, Loss_ode: 0.1981\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14210, Loss_data: 0.0111, Loss_ode: 0.1958\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14220, Loss_data: 0.0109, Loss_ode: 0.2026\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14230, Loss_data: 0.0110, Loss_ode: 0.1957\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14240, Loss_data: 0.0109, Loss_ode: 0.1979\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14250, Loss_data: 0.0109, Loss_ode: 0.2023\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14260, Loss_data: 0.0109, Loss_ode: 0.1944\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14270, Loss_data: 0.0110, Loss_ode: 0.2007\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14280, Loss_data: 0.0108, Loss_ode: 0.2019\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14290, Loss_data: 0.0109, Loss_ode: 0.1952\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14300, Loss_data: 0.0108, Loss_ode: 0.1931\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14310, Loss_data: 0.0109, Loss_ode: 0.1988\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14320, Loss_data: 0.0109, Loss_ode: 0.1927\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14330, Loss_data: 0.0108, Loss_ode: 0.1979\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14340, Loss_data: 0.0109, Loss_ode: 0.1930\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14350, Loss_data: 0.0109, Loss_ode: 0.1942\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14360, Loss_data: 0.0109, Loss_ode: 0.1977\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14370, Loss_data: 0.0111, Loss_ode: 0.1975\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14380, Loss_data: 0.0109, Loss_ode: 0.1919\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14390, Loss_data: 0.0106, Loss_ode: 0.2221\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14400, Loss_data: 0.0111, Loss_ode: 0.2048\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14410, Loss_data: 0.0108, Loss_ode: 0.1977\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14420, Loss_data: 0.0110, Loss_ode: 0.1917\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14430, Loss_data: 0.0108, Loss_ode: 0.1950\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14440, Loss_data: 0.0109, Loss_ode: 0.1941\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14450, Loss_data: 0.0108, Loss_ode: 0.1959\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14460, Loss_data: 0.0109, Loss_ode: 0.1956\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14470, Loss_data: 0.0110, Loss_ode: 0.1927\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14480, Loss_data: 0.0111, Loss_ode: 0.1963\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14490, Loss_data: 0.0109, Loss_ode: 0.1911\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14500, Loss_data: 0.0110, Loss_ode: 0.1930\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14510, Loss_data: 0.0107, Loss_ode: 0.1976\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14520, Loss_data: 0.0108, Loss_ode: 0.2020\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14530, Loss_data: 0.0110, Loss_ode: 0.1979\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14540, Loss_data: 0.0108, Loss_ode: 0.1868\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14550, Loss_data: 0.0109, Loss_ode: 0.1929\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14560, Loss_data: 0.0109, Loss_ode: 0.1946\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14570, Loss_data: 0.0110, Loss_ode: 0.1924\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14580, Loss_data: 0.0108, Loss_ode: 0.1937\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14590, Loss_data: 0.0105, Loss_ode: 0.1919\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14600, Loss_data: 0.0107, Loss_ode: 0.1950\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14610, Loss_data: 0.0111, Loss_ode: 0.1981\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14620, Loss_data: 0.0106, Loss_ode: 0.1891\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14630, Loss_data: 0.0108, Loss_ode: 0.1928\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14640, Loss_data: 0.0109, Loss_ode: 0.1929\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14650, Loss_data: 0.0109, Loss_ode: 0.1966\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14660, Loss_data: 0.0109, Loss_ode: 0.1930\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14670, Loss_data: 0.0113, Loss_ode: 0.2080\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14680, Loss_data: 0.0107, Loss_ode: 0.1946\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14690, Loss_data: 0.0110, Loss_ode: 0.1926\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14700, Loss_data: 0.0107, Loss_ode: 0.1907\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14710, Loss_data: 0.0109, Loss_ode: 0.1897\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14720, Loss_data: 0.0106, Loss_ode: 0.1893\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14730, Loss_data: 0.0110, Loss_ode: 0.1976\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14740, Loss_data: 0.0108, Loss_ode: 0.1928\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14750, Loss_data: 0.0108, Loss_ode: 0.1918\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14760, Loss_data: 0.0109, Loss_ode: 0.1950\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14770, Loss_data: 0.0110, Loss_ode: 0.1911\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14780, Loss_data: 0.0109, Loss_ode: 0.1887\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14790, Loss_data: 0.0107, Loss_ode: 0.1910\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14800, Loss_data: 0.0106, Loss_ode: 0.1929\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14810, Loss_data: 0.0109, Loss_ode: 0.1922\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14820, Loss_data: 0.0111, Loss_ode: 0.1927\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14830, Loss_data: 0.0108, Loss_ode: 0.1885\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14840, Loss_data: 0.0108, Loss_ode: 0.1907\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14850, Loss_data: 0.0106, Loss_ode: 0.1866\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14860, Loss_data: 0.0108, Loss_ode: 0.1936\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14870, Loss_data: 0.0110, Loss_ode: 0.1947\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14880, Loss_data: 0.0109, Loss_ode: 0.1935\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14890, Loss_data: 0.0108, Loss_ode: 0.1883\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14900, Loss_data: 0.0110, Loss_ode: 0.1862\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14910, Loss_data: 0.0107, Loss_ode: 0.1879\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14920, Loss_data: 0.0109, Loss_ode: 0.1860\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14930, Loss_data: 0.0108, Loss_ode: 0.1887\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14940, Loss_data: 0.0108, Loss_ode: 0.1925\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14950, Loss_data: 0.0107, Loss_ode: 0.1894\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14960, Loss_data: 0.0107, Loss_ode: 0.1896\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14970, Loss_data: 0.0106, Loss_ode: 0.1911\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14980, Loss_data: 0.0106, Loss_ode: 0.1895\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 14990, Loss_data: 0.0110, Loss_ode: 0.1873\n",
      "Current learning rate:  1.6806999999999997e-05\n",
      "Epoch 15000, Loss_data: 0.0111, Loss_ode: 0.1982\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15010, Loss_data: 0.0107, Loss_ode: 0.1922\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15020, Loss_data: 0.0107, Loss_ode: 0.1856\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15030, Loss_data: 0.0106, Loss_ode: 0.1895\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15040, Loss_data: 0.0107, Loss_ode: 0.1859\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15050, Loss_data: 0.0107, Loss_ode: 0.1870\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15060, Loss_data: 0.0108, Loss_ode: 0.1866\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15070, Loss_data: 0.0106, Loss_ode: 0.1899\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15080, Loss_data: 0.0107, Loss_ode: 0.1842\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15090, Loss_data: 0.0107, Loss_ode: 0.1936\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15100, Loss_data: 0.0107, Loss_ode: 0.1826\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15110, Loss_data: 0.0107, Loss_ode: 0.1874\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15120, Loss_data: 0.0107, Loss_ode: 0.1853\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15130, Loss_data: 0.0107, Loss_ode: 0.1879\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15140, Loss_data: 0.0107, Loss_ode: 0.1883\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15150, Loss_data: 0.0107, Loss_ode: 0.1862\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15160, Loss_data: 0.0108, Loss_ode: 0.1871\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15170, Loss_data: 0.0107, Loss_ode: 0.1840\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15180, Loss_data: 0.0106, Loss_ode: 0.1893\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15190, Loss_data: 0.0106, Loss_ode: 0.1874\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15200, Loss_data: 0.0107, Loss_ode: 0.1864\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15210, Loss_data: 0.0107, Loss_ode: 0.1856\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15220, Loss_data: 0.0107, Loss_ode: 0.1832\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15230, Loss_data: 0.0106, Loss_ode: 0.1843\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15240, Loss_data: 0.0107, Loss_ode: 0.1852\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15250, Loss_data: 0.0107, Loss_ode: 0.1838\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15260, Loss_data: 0.0106, Loss_ode: 0.1841\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15270, Loss_data: 0.0107, Loss_ode: 0.1880\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15280, Loss_data: 0.0107, Loss_ode: 0.1869\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15290, Loss_data: 0.0105, Loss_ode: 0.1815\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15300, Loss_data: 0.0107, Loss_ode: 0.1847\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15310, Loss_data: 0.0106, Loss_ode: 0.1870\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15320, Loss_data: 0.0106, Loss_ode: 0.1833\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15330, Loss_data: 0.0107, Loss_ode: 0.1852\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15340, Loss_data: 0.0106, Loss_ode: 0.1854\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15350, Loss_data: 0.0105, Loss_ode: 0.1880\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15360, Loss_data: 0.0106, Loss_ode: 0.1859\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15370, Loss_data: 0.0106, Loss_ode: 0.1864\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15380, Loss_data: 0.0107, Loss_ode: 0.1873\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15390, Loss_data: 0.0106, Loss_ode: 0.1861\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15400, Loss_data: 0.0107, Loss_ode: 0.1807\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15410, Loss_data: 0.0107, Loss_ode: 0.1855\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15420, Loss_data: 0.0105, Loss_ode: 0.1845\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15430, Loss_data: 0.0106, Loss_ode: 0.1825\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15440, Loss_data: 0.0106, Loss_ode: 0.1831\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15450, Loss_data: 0.0107, Loss_ode: 0.1812\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15460, Loss_data: 0.0105, Loss_ode: 0.1876\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15470, Loss_data: 0.0107, Loss_ode: 0.1843\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15480, Loss_data: 0.0107, Loss_ode: 0.1833\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15490, Loss_data: 0.0107, Loss_ode: 0.1860\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15500, Loss_data: 0.0106, Loss_ode: 0.1842\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15510, Loss_data: 0.0106, Loss_ode: 0.1867\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15520, Loss_data: 0.0104, Loss_ode: 0.1825\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15530, Loss_data: 0.0107, Loss_ode: 0.1857\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15540, Loss_data: 0.0106, Loss_ode: 0.1870\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15550, Loss_data: 0.0107, Loss_ode: 0.1851\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15560, Loss_data: 0.0105, Loss_ode: 0.1830\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15570, Loss_data: 0.0105, Loss_ode: 0.1840\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15580, Loss_data: 0.0107, Loss_ode: 0.1831\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15590, Loss_data: 0.0105, Loss_ode: 0.1820\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15600, Loss_data: 0.0106, Loss_ode: 0.1843\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15610, Loss_data: 0.0106, Loss_ode: 0.1808\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15620, Loss_data: 0.0106, Loss_ode: 0.1841\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15630, Loss_data: 0.0106, Loss_ode: 0.1867\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15640, Loss_data: 0.0104, Loss_ode: 0.1818\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15650, Loss_data: 0.0106, Loss_ode: 0.1817\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15660, Loss_data: 0.0106, Loss_ode: 0.1874\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15670, Loss_data: 0.0105, Loss_ode: 0.1810\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15680, Loss_data: 0.0106, Loss_ode: 0.1810\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15690, Loss_data: 0.0105, Loss_ode: 0.1798\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15700, Loss_data: 0.0105, Loss_ode: 0.1818\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15710, Loss_data: 0.0105, Loss_ode: 0.1800\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15720, Loss_data: 0.0105, Loss_ode: 0.1843\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15730, Loss_data: 0.0104, Loss_ode: 0.1784\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15740, Loss_data: 0.0105, Loss_ode: 0.1820\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15750, Loss_data: 0.0105, Loss_ode: 0.1837\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15760, Loss_data: 0.0106, Loss_ode: 0.1817\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15770, Loss_data: 0.0104, Loss_ode: 0.1771\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15780, Loss_data: 0.0105, Loss_ode: 0.1791\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15790, Loss_data: 0.0104, Loss_ode: 0.1776\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15800, Loss_data: 0.0103, Loss_ode: 0.1830\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15810, Loss_data: 0.0106, Loss_ode: 0.1813\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15820, Loss_data: 0.0107, Loss_ode: 0.1817\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15830, Loss_data: 0.0104, Loss_ode: 0.1781\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15840, Loss_data: 0.0104, Loss_ode: 0.1764\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15850, Loss_data: 0.0106, Loss_ode: 0.1792\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15860, Loss_data: 0.0105, Loss_ode: 0.1761\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15870, Loss_data: 0.0105, Loss_ode: 0.1806\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15880, Loss_data: 0.0106, Loss_ode: 0.1789\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15890, Loss_data: 0.0104, Loss_ode: 0.1812\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15900, Loss_data: 0.0106, Loss_ode: 0.1796\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15910, Loss_data: 0.0104, Loss_ode: 0.1790\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15920, Loss_data: 0.0106, Loss_ode: 0.1797\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15930, Loss_data: 0.0107, Loss_ode: 0.1813\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15940, Loss_data: 0.0104, Loss_ode: 0.1788\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15950, Loss_data: 0.0105, Loss_ode: 0.1811\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15960, Loss_data: 0.0107, Loss_ode: 0.1777\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15970, Loss_data: 0.0106, Loss_ode: 0.1834\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15980, Loss_data: 0.0104, Loss_ode: 0.1803\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 15990, Loss_data: 0.0104, Loss_ode: 0.1806\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16000, Loss_data: 0.0104, Loss_ode: 0.1777\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16010, Loss_data: 0.0105, Loss_ode: 0.1802\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16020, Loss_data: 0.0104, Loss_ode: 0.1803\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16030, Loss_data: 0.0102, Loss_ode: 0.1787\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16040, Loss_data: 0.0106, Loss_ode: 0.1786\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16050, Loss_data: 0.0104, Loss_ode: 0.1805\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16060, Loss_data: 0.0106, Loss_ode: 0.1803\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16070, Loss_data: 0.0105, Loss_ode: 0.1727\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16080, Loss_data: 0.0104, Loss_ode: 0.1774\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16090, Loss_data: 0.0106, Loss_ode: 0.1752\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16100, Loss_data: 0.0105, Loss_ode: 0.1786\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16110, Loss_data: 0.0104, Loss_ode: 0.1779\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16120, Loss_data: 0.0105, Loss_ode: 0.1758\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16130, Loss_data: 0.0103, Loss_ode: 0.1809\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16140, Loss_data: 0.0103, Loss_ode: 0.1774\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16150, Loss_data: 0.0106, Loss_ode: 0.1769\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16160, Loss_data: 0.0102, Loss_ode: 0.1769\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16170, Loss_data: 0.0105, Loss_ode: 0.1801\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16180, Loss_data: 0.0105, Loss_ode: 0.1791\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16190, Loss_data: 0.0104, Loss_ode: 0.1791\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16200, Loss_data: 0.0102, Loss_ode: 0.1738\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16210, Loss_data: 0.0103, Loss_ode: 0.1781\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16220, Loss_data: 0.0103, Loss_ode: 0.1786\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16230, Loss_data: 0.0103, Loss_ode: 0.1734\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16240, Loss_data: 0.0103, Loss_ode: 0.1780\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16250, Loss_data: 0.0105, Loss_ode: 0.1735\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16260, Loss_data: 0.0104, Loss_ode: 0.1709\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16270, Loss_data: 0.0103, Loss_ode: 0.1755\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16280, Loss_data: 0.0105, Loss_ode: 0.1745\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16290, Loss_data: 0.0103, Loss_ode: 0.1754\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16300, Loss_data: 0.0104, Loss_ode: 0.1739\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16310, Loss_data: 0.0105, Loss_ode: 0.1725\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16320, Loss_data: 0.0103, Loss_ode: 0.1749\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16330, Loss_data: 0.0104, Loss_ode: 0.1717\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16340, Loss_data: 0.0104, Loss_ode: 0.1742\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16350, Loss_data: 0.0103, Loss_ode: 0.1732\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16360, Loss_data: 0.0103, Loss_ode: 0.1761\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16370, Loss_data: 0.0104, Loss_ode: 0.1711\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16380, Loss_data: 0.0105, Loss_ode: 0.1747\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16390, Loss_data: 0.0103, Loss_ode: 0.1738\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16400, Loss_data: 0.0102, Loss_ode: 0.1731\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16410, Loss_data: 0.0102, Loss_ode: 0.1763\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16420, Loss_data: 0.0104, Loss_ode: 0.1746\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16430, Loss_data: 0.0103, Loss_ode: 0.1720\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16440, Loss_data: 0.0102, Loss_ode: 0.1757\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16450, Loss_data: 0.0102, Loss_ode: 0.1712\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16460, Loss_data: 0.0104, Loss_ode: 0.1708\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16470, Loss_data: 0.0105, Loss_ode: 0.1736\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16480, Loss_data: 0.0105, Loss_ode: 0.1751\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16490, Loss_data: 0.0105, Loss_ode: 0.1700\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16500, Loss_data: 0.0104, Loss_ode: 0.1701\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16510, Loss_data: 0.0105, Loss_ode: 0.1755\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16520, Loss_data: 0.0105, Loss_ode: 0.1713\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16530, Loss_data: 0.0104, Loss_ode: 0.1731\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16540, Loss_data: 0.0104, Loss_ode: 0.1676\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16550, Loss_data: 0.0104, Loss_ode: 0.1781\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16560, Loss_data: 0.0103, Loss_ode: 0.1822\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16570, Loss_data: 0.0103, Loss_ode: 0.1722\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16580, Loss_data: 0.0103, Loss_ode: 0.1750\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16590, Loss_data: 0.0102, Loss_ode: 0.1736\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16600, Loss_data: 0.0102, Loss_ode: 0.1733\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16610, Loss_data: 0.0104, Loss_ode: 0.1703\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16620, Loss_data: 0.0104, Loss_ode: 0.1710\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16630, Loss_data: 0.0103, Loss_ode: 0.1726\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16640, Loss_data: 0.0104, Loss_ode: 0.1720\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16650, Loss_data: 0.0103, Loss_ode: 0.1698\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16660, Loss_data: 0.0103, Loss_ode: 0.1733\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16670, Loss_data: 0.0105, Loss_ode: 0.1784\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16680, Loss_data: 0.0102, Loss_ode: 0.1722\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16690, Loss_data: 0.0103, Loss_ode: 0.1680\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16700, Loss_data: 0.0102, Loss_ode: 0.1702\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16710, Loss_data: 0.0104, Loss_ode: 0.1687\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16720, Loss_data: 0.0104, Loss_ode: 0.1684\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16730, Loss_data: 0.0104, Loss_ode: 0.1692\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16740, Loss_data: 0.0104, Loss_ode: 0.1679\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16750, Loss_data: 0.0105, Loss_ode: 0.1683\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16760, Loss_data: 0.0104, Loss_ode: 0.1706\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16770, Loss_data: 0.0102, Loss_ode: 0.1712\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16780, Loss_data: 0.0102, Loss_ode: 0.1666\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16790, Loss_data: 0.0105, Loss_ode: 0.1685\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16800, Loss_data: 0.0103, Loss_ode: 0.1682\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16810, Loss_data: 0.0103, Loss_ode: 0.1693\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16820, Loss_data: 0.0103, Loss_ode: 0.1677\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16830, Loss_data: 0.0102, Loss_ode: 0.1659\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16840, Loss_data: 0.0102, Loss_ode: 0.1668\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16850, Loss_data: 0.0100, Loss_ode: 0.1715\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16860, Loss_data: 0.0102, Loss_ode: 0.1628\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16870, Loss_data: 0.0103, Loss_ode: 0.1707\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16880, Loss_data: 0.0102, Loss_ode: 0.1689\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16890, Loss_data: 0.0104, Loss_ode: 0.1697\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16900, Loss_data: 0.0102, Loss_ode: 0.1678\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16910, Loss_data: 0.0102, Loss_ode: 0.1651\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16920, Loss_data: 0.0103, Loss_ode: 0.1661\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16930, Loss_data: 0.0102, Loss_ode: 0.1681\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16940, Loss_data: 0.0101, Loss_ode: 0.1698\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16950, Loss_data: 0.0104, Loss_ode: 0.1650\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16960, Loss_data: 0.0102, Loss_ode: 0.1659\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16970, Loss_data: 0.0104, Loss_ode: 0.1679\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16980, Loss_data: 0.0101, Loss_ode: 0.1711\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 16990, Loss_data: 0.0101, Loss_ode: 0.1689\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17000, Loss_data: 0.0102, Loss_ode: 0.1668\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17010, Loss_data: 0.0103, Loss_ode: 0.1688\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17020, Loss_data: 0.0101, Loss_ode: 0.1634\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17030, Loss_data: 0.0104, Loss_ode: 0.1635\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17040, Loss_data: 0.0102, Loss_ode: 0.1677\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17050, Loss_data: 0.0103, Loss_ode: 0.1657\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17060, Loss_data: 0.0102, Loss_ode: 0.1646\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17070, Loss_data: 0.0100, Loss_ode: 0.1682\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17080, Loss_data: 0.0102, Loss_ode: 0.1629\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17090, Loss_data: 0.0100, Loss_ode: 0.1643\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17100, Loss_data: 0.0104, Loss_ode: 0.1663\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17110, Loss_data: 0.0100, Loss_ode: 0.1664\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17120, Loss_data: 0.0103, Loss_ode: 0.1623\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17130, Loss_data: 0.0103, Loss_ode: 0.1684\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17140, Loss_data: 0.0101, Loss_ode: 0.1629\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17150, Loss_data: 0.0103, Loss_ode: 0.1664\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17160, Loss_data: 0.0102, Loss_ode: 0.1595\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17170, Loss_data: 0.0101, Loss_ode: 0.1650\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17180, Loss_data: 0.0102, Loss_ode: 0.1614\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17190, Loss_data: 0.0103, Loss_ode: 0.1639\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17200, Loss_data: 0.0102, Loss_ode: 0.1641\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17210, Loss_data: 0.0104, Loss_ode: 0.1669\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17220, Loss_data: 0.0100, Loss_ode: 0.1646\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17230, Loss_data: 0.0104, Loss_ode: 0.1672\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17240, Loss_data: 0.0102, Loss_ode: 0.1626\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17250, Loss_data: 0.0102, Loss_ode: 0.1639\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17260, Loss_data: 0.0104, Loss_ode: 0.1627\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17270, Loss_data: 0.0102, Loss_ode: 0.1613\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17280, Loss_data: 0.0102, Loss_ode: 0.1625\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17290, Loss_data: 0.0102, Loss_ode: 0.1602\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17300, Loss_data: 0.0103, Loss_ode: 0.1617\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17310, Loss_data: 0.0102, Loss_ode: 0.1600\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17320, Loss_data: 0.0102, Loss_ode: 0.1577\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17330, Loss_data: 0.0102, Loss_ode: 0.1578\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17340, Loss_data: 0.0103, Loss_ode: 0.1601\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17350, Loss_data: 0.0102, Loss_ode: 0.1613\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17360, Loss_data: 0.0103, Loss_ode: 0.1587\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17370, Loss_data: 0.0101, Loss_ode: 0.1586\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17380, Loss_data: 0.0102, Loss_ode: 0.1620\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17390, Loss_data: 0.0104, Loss_ode: 0.1662\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17400, Loss_data: 0.0102, Loss_ode: 0.1588\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17410, Loss_data: 0.0102, Loss_ode: 0.1635\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17420, Loss_data: 0.0102, Loss_ode: 0.1587\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17430, Loss_data: 0.0101, Loss_ode: 0.1596\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17440, Loss_data: 0.0102, Loss_ode: 0.1587\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17450, Loss_data: 0.0103, Loss_ode: 0.1606\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17460, Loss_data: 0.0102, Loss_ode: 0.1629\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17470, Loss_data: 0.0101, Loss_ode: 0.1596\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17480, Loss_data: 0.0103, Loss_ode: 0.1665\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17490, Loss_data: 0.0102, Loss_ode: 0.1569\n",
      "Current learning rate:  1.1764899999999996e-05\n",
      "Epoch 17500, Loss_data: 0.0102, Loss_ode: 0.1531\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17510, Loss_data: 0.0103, Loss_ode: 0.1609\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17520, Loss_data: 0.0102, Loss_ode: 0.1553\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17530, Loss_data: 0.0101, Loss_ode: 0.1586\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17540, Loss_data: 0.0102, Loss_ode: 0.1571\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17550, Loss_data: 0.0102, Loss_ode: 0.1572\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17560, Loss_data: 0.0102, Loss_ode: 0.1582\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17570, Loss_data: 0.0103, Loss_ode: 0.1591\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17580, Loss_data: 0.0101, Loss_ode: 0.1576\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17590, Loss_data: 0.0102, Loss_ode: 0.1548\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17600, Loss_data: 0.0103, Loss_ode: 0.1534\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17610, Loss_data: 0.0102, Loss_ode: 0.1577\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17620, Loss_data: 0.0103, Loss_ode: 0.1569\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17630, Loss_data: 0.0102, Loss_ode: 0.1576\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17640, Loss_data: 0.0103, Loss_ode: 0.1582\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17650, Loss_data: 0.0103, Loss_ode: 0.1530\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17660, Loss_data: 0.0101, Loss_ode: 0.1549\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17670, Loss_data: 0.0102, Loss_ode: 0.1579\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17680, Loss_data: 0.0102, Loss_ode: 0.1556\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17690, Loss_data: 0.0103, Loss_ode: 0.1551\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17700, Loss_data: 0.0101, Loss_ode: 0.1565\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17710, Loss_data: 0.0103, Loss_ode: 0.1567\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17720, Loss_data: 0.0101, Loss_ode: 0.1587\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17730, Loss_data: 0.0102, Loss_ode: 0.1519\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17740, Loss_data: 0.0102, Loss_ode: 0.1568\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17750, Loss_data: 0.0102, Loss_ode: 0.1545\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17760, Loss_data: 0.0101, Loss_ode: 0.1548\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17770, Loss_data: 0.0102, Loss_ode: 0.1523\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17780, Loss_data: 0.0102, Loss_ode: 0.1536\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17790, Loss_data: 0.0102, Loss_ode: 0.1574\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17800, Loss_data: 0.0103, Loss_ode: 0.1507\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17810, Loss_data: 0.0101, Loss_ode: 0.1524\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17820, Loss_data: 0.0102, Loss_ode: 0.1545\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17830, Loss_data: 0.0102, Loss_ode: 0.1552\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17840, Loss_data: 0.0101, Loss_ode: 0.1564\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17850, Loss_data: 0.0101, Loss_ode: 0.1513\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17860, Loss_data: 0.0101, Loss_ode: 0.1498\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17870, Loss_data: 0.0102, Loss_ode: 0.1544\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17880, Loss_data: 0.0102, Loss_ode: 0.1579\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17890, Loss_data: 0.0101, Loss_ode: 0.1544\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17900, Loss_data: 0.0101, Loss_ode: 0.1528\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17910, Loss_data: 0.0101, Loss_ode: 0.1537\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17920, Loss_data: 0.0101, Loss_ode: 0.1535\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17930, Loss_data: 0.0102, Loss_ode: 0.1522\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17940, Loss_data: 0.0101, Loss_ode: 0.1500\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17950, Loss_data: 0.0102, Loss_ode: 0.1462\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17960, Loss_data: 0.0102, Loss_ode: 0.1491\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17970, Loss_data: 0.0102, Loss_ode: 0.1548\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17980, Loss_data: 0.0101, Loss_ode: 0.1572\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 17990, Loss_data: 0.0102, Loss_ode: 0.1499\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18000, Loss_data: 0.0101, Loss_ode: 0.1509\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18010, Loss_data: 0.0102, Loss_ode: 0.1486\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18020, Loss_data: 0.0101, Loss_ode: 0.1506\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18030, Loss_data: 0.0102, Loss_ode: 0.1526\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18040, Loss_data: 0.0101, Loss_ode: 0.1532\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18050, Loss_data: 0.0101, Loss_ode: 0.1517\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18060, Loss_data: 0.0101, Loss_ode: 0.1464\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18070, Loss_data: 0.0102, Loss_ode: 0.1484\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18080, Loss_data: 0.0101, Loss_ode: 0.1467\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18090, Loss_data: 0.0101, Loss_ode: 0.1542\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18100, Loss_data: 0.0101, Loss_ode: 0.1468\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18110, Loss_data: 0.0100, Loss_ode: 0.1521\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18120, Loss_data: 0.0101, Loss_ode: 0.1507\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18130, Loss_data: 0.0101, Loss_ode: 0.1471\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18140, Loss_data: 0.0102, Loss_ode: 0.1473\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18150, Loss_data: 0.0102, Loss_ode: 0.1488\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18160, Loss_data: 0.0101, Loss_ode: 0.1484\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18170, Loss_data: 0.0102, Loss_ode: 0.1472\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18180, Loss_data: 0.0101, Loss_ode: 0.1515\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18190, Loss_data: 0.0102, Loss_ode: 0.1450\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18200, Loss_data: 0.0101, Loss_ode: 0.1457\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18210, Loss_data: 0.0101, Loss_ode: 0.1479\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18220, Loss_data: 0.0101, Loss_ode: 0.1484\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18230, Loss_data: 0.0102, Loss_ode: 0.1462\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18240, Loss_data: 0.0101, Loss_ode: 0.1503\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18250, Loss_data: 0.0101, Loss_ode: 0.1452\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18260, Loss_data: 0.0100, Loss_ode: 0.1497\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18270, Loss_data: 0.0102, Loss_ode: 0.1459\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18280, Loss_data: 0.0101, Loss_ode: 0.1457\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18290, Loss_data: 0.0101, Loss_ode: 0.1468\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18300, Loss_data: 0.0101, Loss_ode: 0.1411\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18310, Loss_data: 0.0102, Loss_ode: 0.1493\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18320, Loss_data: 0.0101, Loss_ode: 0.1477\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18330, Loss_data: 0.0100, Loss_ode: 0.1464\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18340, Loss_data: 0.0101, Loss_ode: 0.1482\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18350, Loss_data: 0.0103, Loss_ode: 0.1488\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18360, Loss_data: 0.0102, Loss_ode: 0.1460\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18370, Loss_data: 0.0100, Loss_ode: 0.1518\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18380, Loss_data: 0.0100, Loss_ode: 0.1493\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18390, Loss_data: 0.0103, Loss_ode: 0.1454\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18400, Loss_data: 0.0100, Loss_ode: 0.1507\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18410, Loss_data: 0.0104, Loss_ode: 0.1451\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18420, Loss_data: 0.0101, Loss_ode: 0.1460\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18430, Loss_data: 0.0102, Loss_ode: 0.1463\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18440, Loss_data: 0.0103, Loss_ode: 0.1462\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18450, Loss_data: 0.0100, Loss_ode: 0.1466\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18460, Loss_data: 0.0103, Loss_ode: 0.1414\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18470, Loss_data: 0.0102, Loss_ode: 0.1424\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18480, Loss_data: 0.0103, Loss_ode: 0.1437\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18490, Loss_data: 0.0102, Loss_ode: 0.1441\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18500, Loss_data: 0.0102, Loss_ode: 0.1458\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18510, Loss_data: 0.0102, Loss_ode: 0.1443\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18520, Loss_data: 0.0102, Loss_ode: 0.1431\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18530, Loss_data: 0.0103, Loss_ode: 0.1473\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18540, Loss_data: 0.0101, Loss_ode: 0.1435\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18550, Loss_data: 0.0103, Loss_ode: 0.1434\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18560, Loss_data: 0.0101, Loss_ode: 0.1446\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18570, Loss_data: 0.0102, Loss_ode: 0.1449\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18580, Loss_data: 0.0102, Loss_ode: 0.1452\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18590, Loss_data: 0.0102, Loss_ode: 0.1426\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18600, Loss_data: 0.0103, Loss_ode: 0.1469\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18610, Loss_data: 0.0102, Loss_ode: 0.1383\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18620, Loss_data: 0.0104, Loss_ode: 0.1427\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18630, Loss_data: 0.0102, Loss_ode: 0.1417\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18640, Loss_data: 0.0101, Loss_ode: 0.1419\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18650, Loss_data: 0.0102, Loss_ode: 0.1406\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18660, Loss_data: 0.0101, Loss_ode: 0.1415\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18670, Loss_data: 0.0102, Loss_ode: 0.1423\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18680, Loss_data: 0.0103, Loss_ode: 0.1404\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18690, Loss_data: 0.0101, Loss_ode: 0.1436\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18700, Loss_data: 0.0102, Loss_ode: 0.1450\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18710, Loss_data: 0.0101, Loss_ode: 0.1393\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18720, Loss_data: 0.0102, Loss_ode: 0.1431\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18730, Loss_data: 0.0101, Loss_ode: 0.1405\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18740, Loss_data: 0.0100, Loss_ode: 0.1440\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18750, Loss_data: 0.0102, Loss_ode: 0.1394\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18760, Loss_data: 0.0103, Loss_ode: 0.1396\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18770, Loss_data: 0.0103, Loss_ode: 0.1421\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18780, Loss_data: 0.0102, Loss_ode: 0.1394\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18790, Loss_data: 0.0103, Loss_ode: 0.1416\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18800, Loss_data: 0.0103, Loss_ode: 0.1424\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18810, Loss_data: 0.0101, Loss_ode: 0.1416\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18820, Loss_data: 0.0102, Loss_ode: 0.1438\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18830, Loss_data: 0.0101, Loss_ode: 0.1429\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18840, Loss_data: 0.0101, Loss_ode: 0.1398\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18850, Loss_data: 0.0102, Loss_ode: 0.1425\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18860, Loss_data: 0.0100, Loss_ode: 0.1396\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18870, Loss_data: 0.0102, Loss_ode: 0.1421\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18880, Loss_data: 0.0101, Loss_ode: 0.1416\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18890, Loss_data: 0.0101, Loss_ode: 0.1401\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18900, Loss_data: 0.0102, Loss_ode: 0.1409\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18910, Loss_data: 0.0101, Loss_ode: 0.1405\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18920, Loss_data: 0.0102, Loss_ode: 0.1395\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18930, Loss_data: 0.0102, Loss_ode: 0.1380\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18940, Loss_data: 0.0101, Loss_ode: 0.1413\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18950, Loss_data: 0.0102, Loss_ode: 0.1388\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18960, Loss_data: 0.0100, Loss_ode: 0.1432\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18970, Loss_data: 0.0102, Loss_ode: 0.1379\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18980, Loss_data: 0.0101, Loss_ode: 0.1366\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 18990, Loss_data: 0.0102, Loss_ode: 0.1378\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19000, Loss_data: 0.0101, Loss_ode: 0.1382\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19010, Loss_data: 0.0101, Loss_ode: 0.1382\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19020, Loss_data: 0.0102, Loss_ode: 0.1357\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19030, Loss_data: 0.0102, Loss_ode: 0.1377\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19040, Loss_data: 0.0101, Loss_ode: 0.1346\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19050, Loss_data: 0.0101, Loss_ode: 0.1357\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19060, Loss_data: 0.0102, Loss_ode: 0.1366\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19070, Loss_data: 0.0100, Loss_ode: 0.1421\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19080, Loss_data: 0.0102, Loss_ode: 0.1357\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19090, Loss_data: 0.0101, Loss_ode: 0.1335\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19100, Loss_data: 0.0104, Loss_ode: 0.1381\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19110, Loss_data: 0.0102, Loss_ode: 0.1367\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19120, Loss_data: 0.0102, Loss_ode: 0.1376\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19130, Loss_data: 0.0102, Loss_ode: 0.1369\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19140, Loss_data: 0.0103, Loss_ode: 0.1365\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19150, Loss_data: 0.0100, Loss_ode: 0.1375\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19160, Loss_data: 0.0103, Loss_ode: 0.1394\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19170, Loss_data: 0.0102, Loss_ode: 0.1341\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19180, Loss_data: 0.0101, Loss_ode: 0.1358\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19190, Loss_data: 0.0103, Loss_ode: 0.1392\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19200, Loss_data: 0.0102, Loss_ode: 0.1347\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19210, Loss_data: 0.0101, Loss_ode: 0.1321\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19220, Loss_data: 0.0102, Loss_ode: 0.1318\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19230, Loss_data: 0.0101, Loss_ode: 0.1388\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19240, Loss_data: 0.0103, Loss_ode: 0.1326\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19250, Loss_data: 0.0100, Loss_ode: 0.1335\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19260, Loss_data: 0.0102, Loss_ode: 0.1354\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19270, Loss_data: 0.0101, Loss_ode: 0.1349\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19280, Loss_data: 0.0101, Loss_ode: 0.1358\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19290, Loss_data: 0.0103, Loss_ode: 0.1303\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19300, Loss_data: 0.0101, Loss_ode: 0.1365\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19310, Loss_data: 0.0102, Loss_ode: 0.1381\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19320, Loss_data: 0.0102, Loss_ode: 0.1346\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19330, Loss_data: 0.0102, Loss_ode: 0.1321\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19340, Loss_data: 0.0102, Loss_ode: 0.1343\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19350, Loss_data: 0.0102, Loss_ode: 0.1321\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19360, Loss_data: 0.0102, Loss_ode: 0.1319\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19370, Loss_data: 0.0102, Loss_ode: 0.1334\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19380, Loss_data: 0.0103, Loss_ode: 0.1316\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19390, Loss_data: 0.0102, Loss_ode: 0.1349\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19400, Loss_data: 0.0103, Loss_ode: 0.1308\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19410, Loss_data: 0.0102, Loss_ode: 0.1298\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19420, Loss_data: 0.0102, Loss_ode: 0.1315\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19430, Loss_data: 0.0102, Loss_ode: 0.1363\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19440, Loss_data: 0.0102, Loss_ode: 0.1308\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19450, Loss_data: 0.0101, Loss_ode: 0.1314\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19460, Loss_data: 0.0102, Loss_ode: 0.1321\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19470, Loss_data: 0.0102, Loss_ode: 0.1315\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19480, Loss_data: 0.0101, Loss_ode: 0.1324\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19490, Loss_data: 0.0102, Loss_ode: 0.1293\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19500, Loss_data: 0.0103, Loss_ode: 0.1329\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19510, Loss_data: 0.0101, Loss_ode: 0.1360\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19520, Loss_data: 0.0102, Loss_ode: 0.1311\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19530, Loss_data: 0.0103, Loss_ode: 0.1305\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19540, Loss_data: 0.0102, Loss_ode: 0.1323\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19550, Loss_data: 0.0103, Loss_ode: 0.1329\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19560, Loss_data: 0.0102, Loss_ode: 0.1302\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19570, Loss_data: 0.0103, Loss_ode: 0.1322\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19580, Loss_data: 0.0102, Loss_ode: 0.1304\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19590, Loss_data: 0.0102, Loss_ode: 0.1284\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19600, Loss_data: 0.0101, Loss_ode: 0.1314\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19610, Loss_data: 0.0102, Loss_ode: 0.1317\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19620, Loss_data: 0.0101, Loss_ode: 0.1310\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19630, Loss_data: 0.0104, Loss_ode: 0.1337\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19640, Loss_data: 0.0101, Loss_ode: 0.1290\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19650, Loss_data: 0.0103, Loss_ode: 0.1259\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19660, Loss_data: 0.0102, Loss_ode: 0.1289\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19670, Loss_data: 0.0102, Loss_ode: 0.1282\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19680, Loss_data: 0.0103, Loss_ode: 0.1272\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19690, Loss_data: 0.0103, Loss_ode: 0.1278\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19700, Loss_data: 0.0102, Loss_ode: 0.1293\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19710, Loss_data: 0.0103, Loss_ode: 0.1336\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19720, Loss_data: 0.0102, Loss_ode: 0.1308\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19730, Loss_data: 0.0103, Loss_ode: 0.1273\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19740, Loss_data: 0.0101, Loss_ode: 0.1298\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19750, Loss_data: 0.0102, Loss_ode: 0.1264\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19760, Loss_data: 0.0102, Loss_ode: 0.1293\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19770, Loss_data: 0.0102, Loss_ode: 0.1273\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19780, Loss_data: 0.0101, Loss_ode: 0.1244\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19790, Loss_data: 0.0103, Loss_ode: 0.1277\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19800, Loss_data: 0.0101, Loss_ode: 0.1292\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19810, Loss_data: 0.0102, Loss_ode: 0.1259\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19820, Loss_data: 0.0102, Loss_ode: 0.1271\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19830, Loss_data: 0.0102, Loss_ode: 0.1274\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19840, Loss_data: 0.0102, Loss_ode: 0.1276\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19850, Loss_data: 0.0102, Loss_ode: 0.1248\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19860, Loss_data: 0.0102, Loss_ode: 0.1308\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19870, Loss_data: 0.0102, Loss_ode: 0.1262\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19880, Loss_data: 0.0103, Loss_ode: 0.1270\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19890, Loss_data: 0.0101, Loss_ode: 0.1295\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19900, Loss_data: 0.0102, Loss_ode: 0.1280\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19910, Loss_data: 0.0101, Loss_ode: 0.1290\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19920, Loss_data: 0.0104, Loss_ode: 0.1256\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19930, Loss_data: 0.0102, Loss_ode: 0.1246\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19940, Loss_data: 0.0103, Loss_ode: 0.1249\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19950, Loss_data: 0.0100, Loss_ode: 0.1242\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19960, Loss_data: 0.0104, Loss_ode: 0.1259\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19970, Loss_data: 0.0101, Loss_ode: 0.1261\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19980, Loss_data: 0.0104, Loss_ode: 0.1208\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 19990, Loss_data: 0.0102, Loss_ode: 0.1256\n",
      "Current learning rate:  8.235429999999996e-06\n",
      "Epoch 20000, Loss_data: 0.0103, Loss_ode: 0.1264\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20010, Loss_data: 0.0102, Loss_ode: 0.1263\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20020, Loss_data: 0.0102, Loss_ode: 0.1226\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20030, Loss_data: 0.0102, Loss_ode: 0.1251\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20040, Loss_data: 0.0103, Loss_ode: 0.1254\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20050, Loss_data: 0.0103, Loss_ode: 0.1270\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20060, Loss_data: 0.0102, Loss_ode: 0.1223\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20070, Loss_data: 0.0102, Loss_ode: 0.1219\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20080, Loss_data: 0.0102, Loss_ode: 0.1276\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20090, Loss_data: 0.0103, Loss_ode: 0.1240\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20100, Loss_data: 0.0102, Loss_ode: 0.1227\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20110, Loss_data: 0.0102, Loss_ode: 0.1242\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20120, Loss_data: 0.0101, Loss_ode: 0.1250\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20130, Loss_data: 0.0103, Loss_ode: 0.1252\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20140, Loss_data: 0.0103, Loss_ode: 0.1217\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20150, Loss_data: 0.0102, Loss_ode: 0.1236\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20160, Loss_data: 0.0103, Loss_ode: 0.1211\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20170, Loss_data: 0.0102, Loss_ode: 0.1221\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20180, Loss_data: 0.0102, Loss_ode: 0.1216\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20190, Loss_data: 0.0102, Loss_ode: 0.1205\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20200, Loss_data: 0.0102, Loss_ode: 0.1211\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20210, Loss_data: 0.0103, Loss_ode: 0.1221\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20220, Loss_data: 0.0102, Loss_ode: 0.1215\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20230, Loss_data: 0.0102, Loss_ode: 0.1228\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20240, Loss_data: 0.0101, Loss_ode: 0.1203\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20250, Loss_data: 0.0103, Loss_ode: 0.1243\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20260, Loss_data: 0.0102, Loss_ode: 0.1213\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20270, Loss_data: 0.0102, Loss_ode: 0.1204\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20280, Loss_data: 0.0103, Loss_ode: 0.1218\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20290, Loss_data: 0.0102, Loss_ode: 0.1204\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20300, Loss_data: 0.0103, Loss_ode: 0.1232\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20310, Loss_data: 0.0103, Loss_ode: 0.1207\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20320, Loss_data: 0.0103, Loss_ode: 0.1211\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20330, Loss_data: 0.0102, Loss_ode: 0.1202\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20340, Loss_data: 0.0102, Loss_ode: 0.1215\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20350, Loss_data: 0.0102, Loss_ode: 0.1218\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20360, Loss_data: 0.0102, Loss_ode: 0.1243\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20370, Loss_data: 0.0102, Loss_ode: 0.1224\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20380, Loss_data: 0.0102, Loss_ode: 0.1175\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20390, Loss_data: 0.0102, Loss_ode: 0.1203\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20400, Loss_data: 0.0103, Loss_ode: 0.1171\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20410, Loss_data: 0.0101, Loss_ode: 0.1223\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20420, Loss_data: 0.0102, Loss_ode: 0.1193\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20430, Loss_data: 0.0102, Loss_ode: 0.1163\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20440, Loss_data: 0.0102, Loss_ode: 0.1190\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20450, Loss_data: 0.0103, Loss_ode: 0.1222\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20460, Loss_data: 0.0103, Loss_ode: 0.1198\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20470, Loss_data: 0.0101, Loss_ode: 0.1195\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20480, Loss_data: 0.0103, Loss_ode: 0.1215\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20490, Loss_data: 0.0102, Loss_ode: 0.1210\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20500, Loss_data: 0.0103, Loss_ode: 0.1186\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20510, Loss_data: 0.0103, Loss_ode: 0.1177\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20520, Loss_data: 0.0103, Loss_ode: 0.1184\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20530, Loss_data: 0.0102, Loss_ode: 0.1220\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20540, Loss_data: 0.0102, Loss_ode: 0.1171\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20550, Loss_data: 0.0103, Loss_ode: 0.1194\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20560, Loss_data: 0.0103, Loss_ode: 0.1204\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20570, Loss_data: 0.0103, Loss_ode: 0.1178\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20580, Loss_data: 0.0104, Loss_ode: 0.1167\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20590, Loss_data: 0.0102, Loss_ode: 0.1146\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20600, Loss_data: 0.0102, Loss_ode: 0.1180\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20610, Loss_data: 0.0103, Loss_ode: 0.1157\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20620, Loss_data: 0.0101, Loss_ode: 0.1182\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20630, Loss_data: 0.0102, Loss_ode: 0.1183\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20640, Loss_data: 0.0102, Loss_ode: 0.1137\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20650, Loss_data: 0.0102, Loss_ode: 0.1180\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20660, Loss_data: 0.0103, Loss_ode: 0.1151\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20670, Loss_data: 0.0103, Loss_ode: 0.1176\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20680, Loss_data: 0.0103, Loss_ode: 0.1187\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20690, Loss_data: 0.0103, Loss_ode: 0.1168\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20700, Loss_data: 0.0102, Loss_ode: 0.1172\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20710, Loss_data: 0.0103, Loss_ode: 0.1149\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20720, Loss_data: 0.0103, Loss_ode: 0.1158\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20730, Loss_data: 0.0102, Loss_ode: 0.1212\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20740, Loss_data: 0.0102, Loss_ode: 0.1168\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20750, Loss_data: 0.0102, Loss_ode: 0.1158\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20760, Loss_data: 0.0103, Loss_ode: 0.1174\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20770, Loss_data: 0.0103, Loss_ode: 0.1128\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20780, Loss_data: 0.0103, Loss_ode: 0.1167\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20790, Loss_data: 0.0103, Loss_ode: 0.1155\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20800, Loss_data: 0.0101, Loss_ode: 0.1194\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20810, Loss_data: 0.0104, Loss_ode: 0.1145\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20820, Loss_data: 0.0103, Loss_ode: 0.1181\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20830, Loss_data: 0.0102, Loss_ode: 0.1134\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20840, Loss_data: 0.0103, Loss_ode: 0.1165\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20850, Loss_data: 0.0102, Loss_ode: 0.1152\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20860, Loss_data: 0.0102, Loss_ode: 0.1165\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20870, Loss_data: 0.0103, Loss_ode: 0.1149\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20880, Loss_data: 0.0101, Loss_ode: 0.1172\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20890, Loss_data: 0.0103, Loss_ode: 0.1130\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20900, Loss_data: 0.0102, Loss_ode: 0.1192\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20910, Loss_data: 0.0103, Loss_ode: 0.1138\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20920, Loss_data: 0.0103, Loss_ode: 0.1112\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20930, Loss_data: 0.0102, Loss_ode: 0.1125\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20940, Loss_data: 0.0103, Loss_ode: 0.1111\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20950, Loss_data: 0.0102, Loss_ode: 0.1137\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20960, Loss_data: 0.0103, Loss_ode: 0.1164\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20970, Loss_data: 0.0102, Loss_ode: 0.1143\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20980, Loss_data: 0.0104, Loss_ode: 0.1136\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 20990, Loss_data: 0.0104, Loss_ode: 0.1118\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21000, Loss_data: 0.0103, Loss_ode: 0.1130\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21010, Loss_data: 0.0102, Loss_ode: 0.1132\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21020, Loss_data: 0.0103, Loss_ode: 0.1149\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21030, Loss_data: 0.0103, Loss_ode: 0.1123\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21040, Loss_data: 0.0103, Loss_ode: 0.1105\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21050, Loss_data: 0.0102, Loss_ode: 0.1169\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21060, Loss_data: 0.0104, Loss_ode: 0.1148\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21070, Loss_data: 0.0103, Loss_ode: 0.1101\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21080, Loss_data: 0.0103, Loss_ode: 0.1103\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21090, Loss_data: 0.0103, Loss_ode: 0.1139\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21100, Loss_data: 0.0103, Loss_ode: 0.1134\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21110, Loss_data: 0.0102, Loss_ode: 0.1125\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21120, Loss_data: 0.0103, Loss_ode: 0.1139\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21130, Loss_data: 0.0104, Loss_ode: 0.1094\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21140, Loss_data: 0.0103, Loss_ode: 0.1121\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21150, Loss_data: 0.0105, Loss_ode: 0.1124\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21160, Loss_data: 0.0103, Loss_ode: 0.1102\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21170, Loss_data: 0.0103, Loss_ode: 0.1075\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21180, Loss_data: 0.0103, Loss_ode: 0.1118\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21190, Loss_data: 0.0104, Loss_ode: 0.1087\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21200, Loss_data: 0.0103, Loss_ode: 0.1122\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21210, Loss_data: 0.0103, Loss_ode: 0.1113\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21220, Loss_data: 0.0103, Loss_ode: 0.1128\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21230, Loss_data: 0.0102, Loss_ode: 0.1127\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21240, Loss_data: 0.0104, Loss_ode: 0.1110\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21250, Loss_data: 0.0102, Loss_ode: 0.1095\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21260, Loss_data: 0.0103, Loss_ode: 0.1111\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21270, Loss_data: 0.0102, Loss_ode: 0.1090\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21280, Loss_data: 0.0103, Loss_ode: 0.1091\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21290, Loss_data: 0.0102, Loss_ode: 0.1079\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21300, Loss_data: 0.0103, Loss_ode: 0.1089\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21310, Loss_data: 0.0103, Loss_ode: 0.1050\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21320, Loss_data: 0.0102, Loss_ode: 0.1108\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21330, Loss_data: 0.0103, Loss_ode: 0.1121\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21340, Loss_data: 0.0103, Loss_ode: 0.1060\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21350, Loss_data: 0.0102, Loss_ode: 0.1102\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21360, Loss_data: 0.0103, Loss_ode: 0.1093\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21370, Loss_data: 0.0102, Loss_ode: 0.1075\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21380, Loss_data: 0.0103, Loss_ode: 0.1080\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21390, Loss_data: 0.0103, Loss_ode: 0.1074\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21400, Loss_data: 0.0102, Loss_ode: 0.1096\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21410, Loss_data: 0.0103, Loss_ode: 0.1085\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21420, Loss_data: 0.0102, Loss_ode: 0.1078\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21430, Loss_data: 0.0103, Loss_ode: 0.1066\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21440, Loss_data: 0.0102, Loss_ode: 0.1096\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21450, Loss_data: 0.0103, Loss_ode: 0.1098\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21460, Loss_data: 0.0102, Loss_ode: 0.1084\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21470, Loss_data: 0.0102, Loss_ode: 0.1068\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21480, Loss_data: 0.0104, Loss_ode: 0.1089\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21490, Loss_data: 0.0102, Loss_ode: 0.1092\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21500, Loss_data: 0.0104, Loss_ode: 0.1104\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21510, Loss_data: 0.0102, Loss_ode: 0.1074\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21520, Loss_data: 0.0102, Loss_ode: 0.1053\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21530, Loss_data: 0.0104, Loss_ode: 0.1047\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21540, Loss_data: 0.0103, Loss_ode: 0.1035\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21550, Loss_data: 0.0103, Loss_ode: 0.1129\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21560, Loss_data: 0.0103, Loss_ode: 0.1070\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21570, Loss_data: 0.0104, Loss_ode: 0.1067\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21580, Loss_data: 0.0102, Loss_ode: 0.1066\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21590, Loss_data: 0.0103, Loss_ode: 0.1046\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21600, Loss_data: 0.0103, Loss_ode: 0.1064\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21610, Loss_data: 0.0102, Loss_ode: 0.1070\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21620, Loss_data: 0.0104, Loss_ode: 0.1044\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21630, Loss_data: 0.0103, Loss_ode: 0.1043\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21640, Loss_data: 0.0103, Loss_ode: 0.1058\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21650, Loss_data: 0.0103, Loss_ode: 0.1026\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21660, Loss_data: 0.0104, Loss_ode: 0.1048\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21670, Loss_data: 0.0103, Loss_ode: 0.1021\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21680, Loss_data: 0.0103, Loss_ode: 0.1070\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21690, Loss_data: 0.0102, Loss_ode: 0.1056\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21700, Loss_data: 0.0103, Loss_ode: 0.1052\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21710, Loss_data: 0.0103, Loss_ode: 0.1035\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21720, Loss_data: 0.0103, Loss_ode: 0.1056\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21730, Loss_data: 0.0103, Loss_ode: 0.1057\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21740, Loss_data: 0.0102, Loss_ode: 0.1051\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21750, Loss_data: 0.0103, Loss_ode: 0.1051\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21760, Loss_data: 0.0103, Loss_ode: 0.1034\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21770, Loss_data: 0.0102, Loss_ode: 0.1039\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21780, Loss_data: 0.0104, Loss_ode: 0.1049\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21790, Loss_data: 0.0102, Loss_ode: 0.1027\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21800, Loss_data: 0.0104, Loss_ode: 0.1041\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21810, Loss_data: 0.0103, Loss_ode: 0.1045\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21820, Loss_data: 0.0104, Loss_ode: 0.1045\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21830, Loss_data: 0.0102, Loss_ode: 0.1030\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21840, Loss_data: 0.0104, Loss_ode: 0.1024\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21850, Loss_data: 0.0103, Loss_ode: 0.1035\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21860, Loss_data: 0.0103, Loss_ode: 0.1009\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21870, Loss_data: 0.0102, Loss_ode: 0.1008\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21880, Loss_data: 0.0103, Loss_ode: 0.1043\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21890, Loss_data: 0.0103, Loss_ode: 0.1014\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21900, Loss_data: 0.0103, Loss_ode: 0.1031\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21910, Loss_data: 0.0103, Loss_ode: 0.1007\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21920, Loss_data: 0.0104, Loss_ode: 0.1013\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21930, Loss_data: 0.0103, Loss_ode: 0.1022\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21940, Loss_data: 0.0104, Loss_ode: 0.1010\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21950, Loss_data: 0.0105, Loss_ode: 0.1006\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21960, Loss_data: 0.0103, Loss_ode: 0.1044\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21970, Loss_data: 0.0104, Loss_ode: 0.1032\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21980, Loss_data: 0.0102, Loss_ode: 0.0990\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 21990, Loss_data: 0.0104, Loss_ode: 0.1002\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22000, Loss_data: 0.0104, Loss_ode: 0.1002\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22010, Loss_data: 0.0103, Loss_ode: 0.1013\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22020, Loss_data: 0.0103, Loss_ode: 0.1009\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22030, Loss_data: 0.0103, Loss_ode: 0.0986\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22040, Loss_data: 0.0104, Loss_ode: 0.1031\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22050, Loss_data: 0.0103, Loss_ode: 0.1011\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22060, Loss_data: 0.0103, Loss_ode: 0.1008\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22070, Loss_data: 0.0102, Loss_ode: 0.1006\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22080, Loss_data: 0.0103, Loss_ode: 0.1009\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22090, Loss_data: 0.0103, Loss_ode: 0.1002\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22100, Loss_data: 0.0104, Loss_ode: 0.0990\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22110, Loss_data: 0.0103, Loss_ode: 0.0998\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22120, Loss_data: 0.0102, Loss_ode: 0.1017\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22130, Loss_data: 0.0102, Loss_ode: 0.0998\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22140, Loss_data: 0.0103, Loss_ode: 0.1001\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22150, Loss_data: 0.0103, Loss_ode: 0.0981\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22160, Loss_data: 0.0104, Loss_ode: 0.0987\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22170, Loss_data: 0.0103, Loss_ode: 0.1020\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22180, Loss_data: 0.0104, Loss_ode: 0.0955\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22190, Loss_data: 0.0104, Loss_ode: 0.0995\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22200, Loss_data: 0.0103, Loss_ode: 0.0996\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22210, Loss_data: 0.0105, Loss_ode: 0.1003\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22220, Loss_data: 0.0103, Loss_ode: 0.0990\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22230, Loss_data: 0.0103, Loss_ode: 0.1005\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22240, Loss_data: 0.0104, Loss_ode: 0.0986\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22250, Loss_data: 0.0104, Loss_ode: 0.1003\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22260, Loss_data: 0.0104, Loss_ode: 0.1004\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22270, Loss_data: 0.0103, Loss_ode: 0.0967\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22280, Loss_data: 0.0104, Loss_ode: 0.0987\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22290, Loss_data: 0.0103, Loss_ode: 0.0971\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22300, Loss_data: 0.0104, Loss_ode: 0.0965\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22310, Loss_data: 0.0104, Loss_ode: 0.0943\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22320, Loss_data: 0.0103, Loss_ode: 0.1013\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22330, Loss_data: 0.0104, Loss_ode: 0.1002\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22340, Loss_data: 0.0104, Loss_ode: 0.0989\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22350, Loss_data: 0.0104, Loss_ode: 0.0990\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22360, Loss_data: 0.0104, Loss_ode: 0.0976\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22370, Loss_data: 0.0102, Loss_ode: 0.0991\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22380, Loss_data: 0.0103, Loss_ode: 0.0959\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22390, Loss_data: 0.0104, Loss_ode: 0.0971\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22400, Loss_data: 0.0103, Loss_ode: 0.0986\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22410, Loss_data: 0.0103, Loss_ode: 0.0987\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22420, Loss_data: 0.0103, Loss_ode: 0.0979\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22430, Loss_data: 0.0103, Loss_ode: 0.0916\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22440, Loss_data: 0.0104, Loss_ode: 0.0926\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22450, Loss_data: 0.0103, Loss_ode: 0.0933\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22460, Loss_data: 0.0105, Loss_ode: 0.0962\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22470, Loss_data: 0.0103, Loss_ode: 0.0941\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22480, Loss_data: 0.0105, Loss_ode: 0.0985\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22490, Loss_data: 0.0104, Loss_ode: 0.0969\n",
      "Current learning rate:  5.764800999999997e-06\n",
      "Epoch 22500, Loss_data: 0.0104, Loss_ode: 0.0976\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22510, Loss_data: 0.0103, Loss_ode: 0.0986\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22520, Loss_data: 0.0103, Loss_ode: 0.0907\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22530, Loss_data: 0.0102, Loss_ode: 0.0965\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22540, Loss_data: 0.0104, Loss_ode: 0.0960\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22550, Loss_data: 0.0104, Loss_ode: 0.0940\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22560, Loss_data: 0.0104, Loss_ode: 0.0946\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22570, Loss_data: 0.0104, Loss_ode: 0.0965\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22580, Loss_data: 0.0103, Loss_ode: 0.0989\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22590, Loss_data: 0.0105, Loss_ode: 0.0909\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22600, Loss_data: 0.0104, Loss_ode: 0.0972\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22610, Loss_data: 0.0104, Loss_ode: 0.0950\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22620, Loss_data: 0.0104, Loss_ode: 0.0933\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22630, Loss_data: 0.0103, Loss_ode: 0.0951\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22640, Loss_data: 0.0103, Loss_ode: 0.0956\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22650, Loss_data: 0.0104, Loss_ode: 0.0920\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22660, Loss_data: 0.0104, Loss_ode: 0.0933\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22670, Loss_data: 0.0103, Loss_ode: 0.0925\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22680, Loss_data: 0.0104, Loss_ode: 0.0943\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22690, Loss_data: 0.0103, Loss_ode: 0.0953\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22700, Loss_data: 0.0103, Loss_ode: 0.0941\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22710, Loss_data: 0.0103, Loss_ode: 0.0937\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22720, Loss_data: 0.0104, Loss_ode: 0.0931\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22730, Loss_data: 0.0103, Loss_ode: 0.0935\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22740, Loss_data: 0.0103, Loss_ode: 0.0933\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22750, Loss_data: 0.0104, Loss_ode: 0.0954\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22760, Loss_data: 0.0104, Loss_ode: 0.0951\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22770, Loss_data: 0.0104, Loss_ode: 0.0922\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22780, Loss_data: 0.0105, Loss_ode: 0.0907\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22790, Loss_data: 0.0103, Loss_ode: 0.0957\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22800, Loss_data: 0.0104, Loss_ode: 0.0897\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22810, Loss_data: 0.0105, Loss_ode: 0.0927\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22820, Loss_data: 0.0103, Loss_ode: 0.0924\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22830, Loss_data: 0.0104, Loss_ode: 0.0945\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22840, Loss_data: 0.0105, Loss_ode: 0.0915\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22850, Loss_data: 0.0104, Loss_ode: 0.0934\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22860, Loss_data: 0.0104, Loss_ode: 0.0926\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22870, Loss_data: 0.0104, Loss_ode: 0.0932\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22880, Loss_data: 0.0103, Loss_ode: 0.0936\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22890, Loss_data: 0.0104, Loss_ode: 0.0927\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22900, Loss_data: 0.0103, Loss_ode: 0.0920\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22910, Loss_data: 0.0105, Loss_ode: 0.0935\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22920, Loss_data: 0.0103, Loss_ode: 0.0914\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22930, Loss_data: 0.0103, Loss_ode: 0.0945\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22940, Loss_data: 0.0104, Loss_ode: 0.0930\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22950, Loss_data: 0.0103, Loss_ode: 0.0893\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22960, Loss_data: 0.0105, Loss_ode: 0.0923\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22970, Loss_data: 0.0103, Loss_ode: 0.0934\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22980, Loss_data: 0.0104, Loss_ode: 0.0899\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 22990, Loss_data: 0.0104, Loss_ode: 0.0910\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23000, Loss_data: 0.0103, Loss_ode: 0.0925\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23010, Loss_data: 0.0104, Loss_ode: 0.0903\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23020, Loss_data: 0.0104, Loss_ode: 0.0898\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23030, Loss_data: 0.0104, Loss_ode: 0.0934\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23040, Loss_data: 0.0106, Loss_ode: 0.0919\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23050, Loss_data: 0.0104, Loss_ode: 0.0908\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23060, Loss_data: 0.0104, Loss_ode: 0.0918\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23070, Loss_data: 0.0105, Loss_ode: 0.0905\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23080, Loss_data: 0.0104, Loss_ode: 0.0892\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23090, Loss_data: 0.0104, Loss_ode: 0.0910\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23100, Loss_data: 0.0103, Loss_ode: 0.0895\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23110, Loss_data: 0.0103, Loss_ode: 0.0895\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23120, Loss_data: 0.0103, Loss_ode: 0.0870\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23130, Loss_data: 0.0104, Loss_ode: 0.0891\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23140, Loss_data: 0.0104, Loss_ode: 0.0878\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23150, Loss_data: 0.0103, Loss_ode: 0.0934\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23160, Loss_data: 0.0105, Loss_ode: 0.0888\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23170, Loss_data: 0.0104, Loss_ode: 0.0892\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23180, Loss_data: 0.0104, Loss_ode: 0.0899\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23190, Loss_data: 0.0103, Loss_ode: 0.0911\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23200, Loss_data: 0.0104, Loss_ode: 0.0886\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23210, Loss_data: 0.0103, Loss_ode: 0.0881\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23220, Loss_data: 0.0104, Loss_ode: 0.0884\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23230, Loss_data: 0.0104, Loss_ode: 0.0886\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23240, Loss_data: 0.0105, Loss_ode: 0.0858\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23250, Loss_data: 0.0104, Loss_ode: 0.0902\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23260, Loss_data: 0.0105, Loss_ode: 0.0900\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23270, Loss_data: 0.0104, Loss_ode: 0.0870\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23280, Loss_data: 0.0104, Loss_ode: 0.0853\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23290, Loss_data: 0.0105, Loss_ode: 0.0928\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23300, Loss_data: 0.0104, Loss_ode: 0.0893\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23310, Loss_data: 0.0104, Loss_ode: 0.0900\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23320, Loss_data: 0.0104, Loss_ode: 0.0879\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23330, Loss_data: 0.0104, Loss_ode: 0.0862\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23340, Loss_data: 0.0104, Loss_ode: 0.0871\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23350, Loss_data: 0.0104, Loss_ode: 0.0862\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23360, Loss_data: 0.0106, Loss_ode: 0.0861\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23370, Loss_data: 0.0105, Loss_ode: 0.0893\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23380, Loss_data: 0.0104, Loss_ode: 0.0890\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23390, Loss_data: 0.0105, Loss_ode: 0.0859\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23400, Loss_data: 0.0104, Loss_ode: 0.0882\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23410, Loss_data: 0.0105, Loss_ode: 0.0863\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23420, Loss_data: 0.0105, Loss_ode: 0.0885\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23430, Loss_data: 0.0104, Loss_ode: 0.0893\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23440, Loss_data: 0.0104, Loss_ode: 0.0843\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23450, Loss_data: 0.0105, Loss_ode: 0.0890\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23460, Loss_data: 0.0104, Loss_ode: 0.0867\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23470, Loss_data: 0.0104, Loss_ode: 0.0855\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23480, Loss_data: 0.0104, Loss_ode: 0.0844\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23490, Loss_data: 0.0104, Loss_ode: 0.0909\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23500, Loss_data: 0.0105, Loss_ode: 0.0840\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23510, Loss_data: 0.0103, Loss_ode: 0.0820\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23520, Loss_data: 0.0104, Loss_ode: 0.0853\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23530, Loss_data: 0.0103, Loss_ode: 0.0849\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23540, Loss_data: 0.0104, Loss_ode: 0.0882\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23550, Loss_data: 0.0104, Loss_ode: 0.0878\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23560, Loss_data: 0.0104, Loss_ode: 0.0824\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23570, Loss_data: 0.0104, Loss_ode: 0.0866\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23580, Loss_data: 0.0105, Loss_ode: 0.0855\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23590, Loss_data: 0.0104, Loss_ode: 0.0864\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23600, Loss_data: 0.0104, Loss_ode: 0.0840\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23610, Loss_data: 0.0104, Loss_ode: 0.0829\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23620, Loss_data: 0.0104, Loss_ode: 0.0847\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23630, Loss_data: 0.0104, Loss_ode: 0.0813\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23640, Loss_data: 0.0104, Loss_ode: 0.0868\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23650, Loss_data: 0.0106, Loss_ode: 0.0845\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23660, Loss_data: 0.0104, Loss_ode: 0.0868\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23670, Loss_data: 0.0105, Loss_ode: 0.0863\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23680, Loss_data: 0.0104, Loss_ode: 0.0863\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23690, Loss_data: 0.0105, Loss_ode: 0.0852\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23700, Loss_data: 0.0106, Loss_ode: 0.0827\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23710, Loss_data: 0.0104, Loss_ode: 0.0826\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23720, Loss_data: 0.0105, Loss_ode: 0.0839\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23730, Loss_data: 0.0104, Loss_ode: 0.0851\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23740, Loss_data: 0.0104, Loss_ode: 0.0815\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23750, Loss_data: 0.0103, Loss_ode: 0.0860\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23760, Loss_data: 0.0104, Loss_ode: 0.0805\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23770, Loss_data: 0.0104, Loss_ode: 0.0866\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23780, Loss_data: 0.0104, Loss_ode: 0.0820\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23790, Loss_data: 0.0104, Loss_ode: 0.0813\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23800, Loss_data: 0.0104, Loss_ode: 0.0831\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23810, Loss_data: 0.0104, Loss_ode: 0.0812\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23820, Loss_data: 0.0105, Loss_ode: 0.0847\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23830, Loss_data: 0.0104, Loss_ode: 0.0863\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23840, Loss_data: 0.0105, Loss_ode: 0.0844\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23850, Loss_data: 0.0104, Loss_ode: 0.0853\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23860, Loss_data: 0.0104, Loss_ode: 0.0854\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23870, Loss_data: 0.0104, Loss_ode: 0.0828\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23880, Loss_data: 0.0104, Loss_ode: 0.0816\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23890, Loss_data: 0.0105, Loss_ode: 0.0789\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23900, Loss_data: 0.0103, Loss_ode: 0.0831\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23910, Loss_data: 0.0105, Loss_ode: 0.0841\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23920, Loss_data: 0.0104, Loss_ode: 0.0820\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23930, Loss_data: 0.0105, Loss_ode: 0.0808\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23940, Loss_data: 0.0104, Loss_ode: 0.0822\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23950, Loss_data: 0.0105, Loss_ode: 0.0809\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23960, Loss_data: 0.0103, Loss_ode: 0.0818\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23970, Loss_data: 0.0105, Loss_ode: 0.0824\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23980, Loss_data: 0.0105, Loss_ode: 0.0793\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 23990, Loss_data: 0.0104, Loss_ode: 0.0796\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24000, Loss_data: 0.0104, Loss_ode: 0.0830\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24010, Loss_data: 0.0104, Loss_ode: 0.0777\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24020, Loss_data: 0.0106, Loss_ode: 0.0802\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24030, Loss_data: 0.0105, Loss_ode: 0.0813\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24040, Loss_data: 0.0105, Loss_ode: 0.0808\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24050, Loss_data: 0.0104, Loss_ode: 0.0831\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24060, Loss_data: 0.0104, Loss_ode: 0.0791\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24070, Loss_data: 0.0104, Loss_ode: 0.0824\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24080, Loss_data: 0.0104, Loss_ode: 0.0868\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24090, Loss_data: 0.0105, Loss_ode: 0.0789\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24100, Loss_data: 0.0103, Loss_ode: 0.0780\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24110, Loss_data: 0.0105, Loss_ode: 0.0807\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24120, Loss_data: 0.0105, Loss_ode: 0.0811\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24130, Loss_data: 0.0104, Loss_ode: 0.0813\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24140, Loss_data: 0.0105, Loss_ode: 0.0812\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24150, Loss_data: 0.0103, Loss_ode: 0.0818\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24160, Loss_data: 0.0105, Loss_ode: 0.0809\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24170, Loss_data: 0.0103, Loss_ode: 0.0795\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24180, Loss_data: 0.0106, Loss_ode: 0.0793\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24190, Loss_data: 0.0105, Loss_ode: 0.0773\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24200, Loss_data: 0.0104, Loss_ode: 0.0797\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24210, Loss_data: 0.0105, Loss_ode: 0.0781\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24220, Loss_data: 0.0104, Loss_ode: 0.0795\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24230, Loss_data: 0.0105, Loss_ode: 0.0805\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24240, Loss_data: 0.0104, Loss_ode: 0.0780\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24250, Loss_data: 0.0105, Loss_ode: 0.0771\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24260, Loss_data: 0.0104, Loss_ode: 0.0775\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24270, Loss_data: 0.0105, Loss_ode: 0.0797\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24280, Loss_data: 0.0104, Loss_ode: 0.0783\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24290, Loss_data: 0.0104, Loss_ode: 0.0774\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24300, Loss_data: 0.0104, Loss_ode: 0.0778\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24310, Loss_data: 0.0104, Loss_ode: 0.0780\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24320, Loss_data: 0.0104, Loss_ode: 0.0786\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24330, Loss_data: 0.0104, Loss_ode: 0.0809\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24340, Loss_data: 0.0104, Loss_ode: 0.0802\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24350, Loss_data: 0.0104, Loss_ode: 0.0747\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24360, Loss_data: 0.0104, Loss_ode: 0.0822\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24370, Loss_data: 0.0105, Loss_ode: 0.0782\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24380, Loss_data: 0.0105, Loss_ode: 0.0769\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24390, Loss_data: 0.0104, Loss_ode: 0.0780\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24400, Loss_data: 0.0104, Loss_ode: 0.0750\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24410, Loss_data: 0.0104, Loss_ode: 0.0791\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24420, Loss_data: 0.0105, Loss_ode: 0.0783\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24430, Loss_data: 0.0104, Loss_ode: 0.0790\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24440, Loss_data: 0.0104, Loss_ode: 0.0772\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24450, Loss_data: 0.0105, Loss_ode: 0.0762\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24460, Loss_data: 0.0104, Loss_ode: 0.0777\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24470, Loss_data: 0.0104, Loss_ode: 0.0767\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24480, Loss_data: 0.0104, Loss_ode: 0.0758\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24490, Loss_data: 0.0104, Loss_ode: 0.0762\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24500, Loss_data: 0.0105, Loss_ode: 0.0755\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24510, Loss_data: 0.0104, Loss_ode: 0.0773\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24520, Loss_data: 0.0105, Loss_ode: 0.0745\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24530, Loss_data: 0.0104, Loss_ode: 0.0758\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24540, Loss_data: 0.0105, Loss_ode: 0.0758\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24550, Loss_data: 0.0103, Loss_ode: 0.0786\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24560, Loss_data: 0.0104, Loss_ode: 0.0756\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24570, Loss_data: 0.0103, Loss_ode: 0.0748\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24580, Loss_data: 0.0104, Loss_ode: 0.0759\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24590, Loss_data: 0.0105, Loss_ode: 0.0741\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24600, Loss_data: 0.0103, Loss_ode: 0.0748\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24610, Loss_data: 0.0103, Loss_ode: 0.0749\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24620, Loss_data: 0.0104, Loss_ode: 0.0744\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24630, Loss_data: 0.0104, Loss_ode: 0.0749\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24640, Loss_data: 0.0104, Loss_ode: 0.0754\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24650, Loss_data: 0.0104, Loss_ode: 0.0775\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24660, Loss_data: 0.0103, Loss_ode: 0.0736\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24670, Loss_data: 0.0104, Loss_ode: 0.0746\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24680, Loss_data: 0.0105, Loss_ode: 0.0749\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24690, Loss_data: 0.0103, Loss_ode: 0.0749\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24700, Loss_data: 0.0104, Loss_ode: 0.0722\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24710, Loss_data: 0.0103, Loss_ode: 0.0756\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24720, Loss_data: 0.0104, Loss_ode: 0.0745\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24730, Loss_data: 0.0104, Loss_ode: 0.0724\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24740, Loss_data: 0.0104, Loss_ode: 0.0745\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24750, Loss_data: 0.0104, Loss_ode: 0.0722\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24760, Loss_data: 0.0103, Loss_ode: 0.0722\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24770, Loss_data: 0.0104, Loss_ode: 0.0738\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24780, Loss_data: 0.0104, Loss_ode: 0.0746\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24790, Loss_data: 0.0104, Loss_ode: 0.0724\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24800, Loss_data: 0.0103, Loss_ode: 0.0761\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24810, Loss_data: 0.0104, Loss_ode: 0.0747\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24820, Loss_data: 0.0103, Loss_ode: 0.0746\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24830, Loss_data: 0.0104, Loss_ode: 0.0724\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24840, Loss_data: 0.0104, Loss_ode: 0.0709\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24850, Loss_data: 0.0103, Loss_ode: 0.0703\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24860, Loss_data: 0.0104, Loss_ode: 0.0741\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24870, Loss_data: 0.0104, Loss_ode: 0.0754\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24880, Loss_data: 0.0102, Loss_ode: 0.0745\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24890, Loss_data: 0.0103, Loss_ode: 0.0719\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24900, Loss_data: 0.0103, Loss_ode: 0.0717\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24910, Loss_data: 0.0102, Loss_ode: 0.0700\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24920, Loss_data: 0.0103, Loss_ode: 0.0711\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24930, Loss_data: 0.0102, Loss_ode: 0.0718\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24940, Loss_data: 0.0103, Loss_ode: 0.0713\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24950, Loss_data: 0.0103, Loss_ode: 0.0723\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24960, Loss_data: 0.0104, Loss_ode: 0.0721\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24970, Loss_data: 0.0104, Loss_ode: 0.0723\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24980, Loss_data: 0.0103, Loss_ode: 0.0739\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 24990, Loss_data: 0.0103, Loss_ode: 0.0699\n",
      "Current learning rate:  4.035360699999998e-06\n",
      "Epoch 25000, Loss_data: 0.0103, Loss_ode: 0.0728\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25010, Loss_data: 0.0104, Loss_ode: 0.0702\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25020, Loss_data: 0.0103, Loss_ode: 0.0716\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25030, Loss_data: 0.0102, Loss_ode: 0.0711\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25040, Loss_data: 0.0103, Loss_ode: 0.0734\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25050, Loss_data: 0.0104, Loss_ode: 0.0725\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25060, Loss_data: 0.0103, Loss_ode: 0.0717\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25070, Loss_data: 0.0103, Loss_ode: 0.0703\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25080, Loss_data: 0.0102, Loss_ode: 0.0681\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25090, Loss_data: 0.0103, Loss_ode: 0.0706\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25100, Loss_data: 0.0103, Loss_ode: 0.0730\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25110, Loss_data: 0.0103, Loss_ode: 0.0709\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25120, Loss_data: 0.0102, Loss_ode: 0.0703\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25130, Loss_data: 0.0102, Loss_ode: 0.0682\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25140, Loss_data: 0.0104, Loss_ode: 0.0687\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25150, Loss_data: 0.0103, Loss_ode: 0.0711\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25160, Loss_data: 0.0104, Loss_ode: 0.0683\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25170, Loss_data: 0.0103, Loss_ode: 0.0711\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25180, Loss_data: 0.0103, Loss_ode: 0.0698\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25190, Loss_data: 0.0103, Loss_ode: 0.0711\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25200, Loss_data: 0.0103, Loss_ode: 0.0695\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25210, Loss_data: 0.0104, Loss_ode: 0.0729\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25220, Loss_data: 0.0103, Loss_ode: 0.0728\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25230, Loss_data: 0.0103, Loss_ode: 0.0678\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25240, Loss_data: 0.0102, Loss_ode: 0.0686\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25250, Loss_data: 0.0102, Loss_ode: 0.0701\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25260, Loss_data: 0.0103, Loss_ode: 0.0700\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25270, Loss_data: 0.0103, Loss_ode: 0.0681\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25280, Loss_data: 0.0103, Loss_ode: 0.0692\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25290, Loss_data: 0.0103, Loss_ode: 0.0682\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25300, Loss_data: 0.0103, Loss_ode: 0.0677\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25310, Loss_data: 0.0102, Loss_ode: 0.0712\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25320, Loss_data: 0.0103, Loss_ode: 0.0688\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25330, Loss_data: 0.0103, Loss_ode: 0.0675\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25340, Loss_data: 0.0102, Loss_ode: 0.0684\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25350, Loss_data: 0.0103, Loss_ode: 0.0696\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25360, Loss_data: 0.0102, Loss_ode: 0.0686\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25370, Loss_data: 0.0104, Loss_ode: 0.0697\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25380, Loss_data: 0.0103, Loss_ode: 0.0691\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25390, Loss_data: 0.0102, Loss_ode: 0.0756\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25400, Loss_data: 0.0104, Loss_ode: 0.0701\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25410, Loss_data: 0.0103, Loss_ode: 0.0676\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25420, Loss_data: 0.0103, Loss_ode: 0.0688\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25430, Loss_data: 0.0103, Loss_ode: 0.0689\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25440, Loss_data: 0.0103, Loss_ode: 0.0682\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25450, Loss_data: 0.0102, Loss_ode: 0.0689\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25460, Loss_data: 0.0103, Loss_ode: 0.0685\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25470, Loss_data: 0.0102, Loss_ode: 0.0697\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25480, Loss_data: 0.0103, Loss_ode: 0.0667\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25490, Loss_data: 0.0103, Loss_ode: 0.0685\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25500, Loss_data: 0.0103, Loss_ode: 0.0659\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25510, Loss_data: 0.0103, Loss_ode: 0.0689\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25520, Loss_data: 0.0102, Loss_ode: 0.0671\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25530, Loss_data: 0.0102, Loss_ode: 0.0709\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25540, Loss_data: 0.0102, Loss_ode: 0.0670\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25550, Loss_data: 0.0102, Loss_ode: 0.0676\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25560, Loss_data: 0.0102, Loss_ode: 0.0684\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25570, Loss_data: 0.0102, Loss_ode: 0.0650\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25580, Loss_data: 0.0103, Loss_ode: 0.0694\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25590, Loss_data: 0.0103, Loss_ode: 0.0674\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25600, Loss_data: 0.0102, Loss_ode: 0.0680\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25610, Loss_data: 0.0103, Loss_ode: 0.0677\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25620, Loss_data: 0.0103, Loss_ode: 0.0675\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25630, Loss_data: 0.0102, Loss_ode: 0.0673\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25640, Loss_data: 0.0102, Loss_ode: 0.0644\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25650, Loss_data: 0.0102, Loss_ode: 0.0676\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25660, Loss_data: 0.0103, Loss_ode: 0.0687\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25670, Loss_data: 0.0103, Loss_ode: 0.0626\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25680, Loss_data: 0.0102, Loss_ode: 0.0673\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25690, Loss_data: 0.0103, Loss_ode: 0.0662\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25700, Loss_data: 0.0102, Loss_ode: 0.0691\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25710, Loss_data: 0.0103, Loss_ode: 0.0666\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25720, Loss_data: 0.0101, Loss_ode: 0.0655\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25730, Loss_data: 0.0102, Loss_ode: 0.0649\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25740, Loss_data: 0.0103, Loss_ode: 0.0647\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25750, Loss_data: 0.0103, Loss_ode: 0.0664\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25760, Loss_data: 0.0103, Loss_ode: 0.0641\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25770, Loss_data: 0.0103, Loss_ode: 0.0664\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25780, Loss_data: 0.0102, Loss_ode: 0.0671\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25790, Loss_data: 0.0102, Loss_ode: 0.0669\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25800, Loss_data: 0.0103, Loss_ode: 0.0655\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25810, Loss_data: 0.0103, Loss_ode: 0.0668\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25820, Loss_data: 0.0102, Loss_ode: 0.0636\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25830, Loss_data: 0.0103, Loss_ode: 0.0670\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25840, Loss_data: 0.0103, Loss_ode: 0.0663\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25850, Loss_data: 0.0103, Loss_ode: 0.0652\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25860, Loss_data: 0.0103, Loss_ode: 0.0658\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25870, Loss_data: 0.0103, Loss_ode: 0.0666\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25880, Loss_data: 0.0102, Loss_ode: 0.0666\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25890, Loss_data: 0.0102, Loss_ode: 0.0652\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25900, Loss_data: 0.0101, Loss_ode: 0.0654\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25910, Loss_data: 0.0102, Loss_ode: 0.0681\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25920, Loss_data: 0.0102, Loss_ode: 0.0648\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25930, Loss_data: 0.0102, Loss_ode: 0.0642\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25940, Loss_data: 0.0102, Loss_ode: 0.0650\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25950, Loss_data: 0.0102, Loss_ode: 0.0626\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25960, Loss_data: 0.0102, Loss_ode: 0.0652\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25970, Loss_data: 0.0102, Loss_ode: 0.0639\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25980, Loss_data: 0.0102, Loss_ode: 0.0619\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 25990, Loss_data: 0.0103, Loss_ode: 0.0655\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26000, Loss_data: 0.0102, Loss_ode: 0.0620\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26010, Loss_data: 0.0101, Loss_ode: 0.0635\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26020, Loss_data: 0.0102, Loss_ode: 0.0647\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26030, Loss_data: 0.0102, Loss_ode: 0.0637\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26040, Loss_data: 0.0101, Loss_ode: 0.0655\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26050, Loss_data: 0.0102, Loss_ode: 0.0616\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26060, Loss_data: 0.0101, Loss_ode: 0.0648\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26070, Loss_data: 0.0102, Loss_ode: 0.0611\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26080, Loss_data: 0.0102, Loss_ode: 0.0616\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26090, Loss_data: 0.0102, Loss_ode: 0.0651\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26100, Loss_data: 0.0102, Loss_ode: 0.0617\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26110, Loss_data: 0.0102, Loss_ode: 0.0609\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26120, Loss_data: 0.0101, Loss_ode: 0.0640\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26130, Loss_data: 0.0102, Loss_ode: 0.0630\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26140, Loss_data: 0.0102, Loss_ode: 0.0630\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26150, Loss_data: 0.0101, Loss_ode: 0.0610\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26160, Loss_data: 0.0102, Loss_ode: 0.0632\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26170, Loss_data: 0.0102, Loss_ode: 0.0619\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26180, Loss_data: 0.0102, Loss_ode: 0.0649\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26190, Loss_data: 0.0102, Loss_ode: 0.0638\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26200, Loss_data: 0.0102, Loss_ode: 0.0637\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26210, Loss_data: 0.0101, Loss_ode: 0.0607\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26220, Loss_data: 0.0102, Loss_ode: 0.0623\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26230, Loss_data: 0.0101, Loss_ode: 0.0635\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26240, Loss_data: 0.0101, Loss_ode: 0.0596\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26250, Loss_data: 0.0101, Loss_ode: 0.0633\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26260, Loss_data: 0.0101, Loss_ode: 0.0633\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26270, Loss_data: 0.0102, Loss_ode: 0.0631\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26280, Loss_data: 0.0101, Loss_ode: 0.0642\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26290, Loss_data: 0.0102, Loss_ode: 0.0637\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26300, Loss_data: 0.0102, Loss_ode: 0.0605\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26310, Loss_data: 0.0101, Loss_ode: 0.0614\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26320, Loss_data: 0.0102, Loss_ode: 0.0660\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26330, Loss_data: 0.0102, Loss_ode: 0.0632\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26340, Loss_data: 0.0102, Loss_ode: 0.0630\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26350, Loss_data: 0.0101, Loss_ode: 0.0609\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26360, Loss_data: 0.0101, Loss_ode: 0.0615\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26370, Loss_data: 0.0101, Loss_ode: 0.0628\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26380, Loss_data: 0.0102, Loss_ode: 0.0619\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26390, Loss_data: 0.0102, Loss_ode: 0.0630\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26400, Loss_data: 0.0101, Loss_ode: 0.0625\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26410, Loss_data: 0.0102, Loss_ode: 0.0636\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26420, Loss_data: 0.0101, Loss_ode: 0.0608\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26430, Loss_data: 0.0101, Loss_ode: 0.0630\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26440, Loss_data: 0.0102, Loss_ode: 0.0591\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26450, Loss_data: 0.0102, Loss_ode: 0.0620\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26460, Loss_data: 0.0101, Loss_ode: 0.0627\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26470, Loss_data: 0.0101, Loss_ode: 0.0598\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26480, Loss_data: 0.0101, Loss_ode: 0.0592\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26490, Loss_data: 0.0102, Loss_ode: 0.0596\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26500, Loss_data: 0.0102, Loss_ode: 0.0618\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26510, Loss_data: 0.0102, Loss_ode: 0.0594\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26520, Loss_data: 0.0101, Loss_ode: 0.0588\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26530, Loss_data: 0.0101, Loss_ode: 0.0628\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26540, Loss_data: 0.0102, Loss_ode: 0.0590\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26550, Loss_data: 0.0101, Loss_ode: 0.0605\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26560, Loss_data: 0.0100, Loss_ode: 0.0625\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26570, Loss_data: 0.0102, Loss_ode: 0.0630\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26580, Loss_data: 0.0101, Loss_ode: 0.0614\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26590, Loss_data: 0.0101, Loss_ode: 0.0602\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26600, Loss_data: 0.0102, Loss_ode: 0.0581\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26610, Loss_data: 0.0101, Loss_ode: 0.0586\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26620, Loss_data: 0.0101, Loss_ode: 0.0584\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26630, Loss_data: 0.0103, Loss_ode: 0.0593\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26640, Loss_data: 0.0101, Loss_ode: 0.0603\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26650, Loss_data: 0.0101, Loss_ode: 0.0587\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26660, Loss_data: 0.0101, Loss_ode: 0.0590\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26670, Loss_data: 0.0101, Loss_ode: 0.0611\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26680, Loss_data: 0.0102, Loss_ode: 0.0602\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26690, Loss_data: 0.0101, Loss_ode: 0.0587\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26700, Loss_data: 0.0101, Loss_ode: 0.0562\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26710, Loss_data: 0.0101, Loss_ode: 0.0590\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26720, Loss_data: 0.0101, Loss_ode: 0.0574\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26730, Loss_data: 0.0101, Loss_ode: 0.0614\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26740, Loss_data: 0.0100, Loss_ode: 0.0589\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26750, Loss_data: 0.0102, Loss_ode: 0.0590\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26760, Loss_data: 0.0101, Loss_ode: 0.0597\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26770, Loss_data: 0.0101, Loss_ode: 0.0587\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26780, Loss_data: 0.0101, Loss_ode: 0.0590\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26790, Loss_data: 0.0101, Loss_ode: 0.0583\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26800, Loss_data: 0.0101, Loss_ode: 0.0577\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26810, Loss_data: 0.0101, Loss_ode: 0.0603\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26820, Loss_data: 0.0100, Loss_ode: 0.0597\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26830, Loss_data: 0.0101, Loss_ode: 0.0577\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26840, Loss_data: 0.0100, Loss_ode: 0.0597\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26850, Loss_data: 0.0101, Loss_ode: 0.0568\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26860, Loss_data: 0.0101, Loss_ode: 0.0570\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26870, Loss_data: 0.0102, Loss_ode: 0.0570\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26880, Loss_data: 0.0101, Loss_ode: 0.0601\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26890, Loss_data: 0.0102, Loss_ode: 0.0585\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26900, Loss_data: 0.0100, Loss_ode: 0.0585\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26910, Loss_data: 0.0100, Loss_ode: 0.0571\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26920, Loss_data: 0.0101, Loss_ode: 0.0578\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26930, Loss_data: 0.0101, Loss_ode: 0.0594\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26940, Loss_data: 0.0101, Loss_ode: 0.0592\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26950, Loss_data: 0.0101, Loss_ode: 0.0582\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26960, Loss_data: 0.0101, Loss_ode: 0.0565\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26970, Loss_data: 0.0101, Loss_ode: 0.0547\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26980, Loss_data: 0.0101, Loss_ode: 0.0586\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 26990, Loss_data: 0.0102, Loss_ode: 0.0578\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27000, Loss_data: 0.0101, Loss_ode: 0.0615\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27010, Loss_data: 0.0101, Loss_ode: 0.0558\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27020, Loss_data: 0.0101, Loss_ode: 0.0573\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27030, Loss_data: 0.0101, Loss_ode: 0.0594\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27040, Loss_data: 0.0101, Loss_ode: 0.0574\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27050, Loss_data: 0.0101, Loss_ode: 0.0545\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27060, Loss_data: 0.0101, Loss_ode: 0.0559\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27070, Loss_data: 0.0100, Loss_ode: 0.0567\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27080, Loss_data: 0.0102, Loss_ode: 0.0597\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27090, Loss_data: 0.0101, Loss_ode: 0.0577\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27100, Loss_data: 0.0101, Loss_ode: 0.0558\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27110, Loss_data: 0.0101, Loss_ode: 0.0538\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27120, Loss_data: 0.0100, Loss_ode: 0.0573\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27130, Loss_data: 0.0101, Loss_ode: 0.0564\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27140, Loss_data: 0.0101, Loss_ode: 0.0560\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27150, Loss_data: 0.0101, Loss_ode: 0.0569\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27160, Loss_data: 0.0102, Loss_ode: 0.0565\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27170, Loss_data: 0.0101, Loss_ode: 0.0573\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27180, Loss_data: 0.0100, Loss_ode: 0.0564\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27190, Loss_data: 0.0101, Loss_ode: 0.0578\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27200, Loss_data: 0.0101, Loss_ode: 0.0544\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27210, Loss_data: 0.0100, Loss_ode: 0.0542\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27220, Loss_data: 0.0101, Loss_ode: 0.0559\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27230, Loss_data: 0.0101, Loss_ode: 0.0577\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27240, Loss_data: 0.0100, Loss_ode: 0.0560\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27250, Loss_data: 0.0100, Loss_ode: 0.0555\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27260, Loss_data: 0.0100, Loss_ode: 0.0535\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27270, Loss_data: 0.0100, Loss_ode: 0.0568\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27280, Loss_data: 0.0100, Loss_ode: 0.0570\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27290, Loss_data: 0.0100, Loss_ode: 0.0545\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27300, Loss_data: 0.0100, Loss_ode: 0.0554\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27310, Loss_data: 0.0101, Loss_ode: 0.0550\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27320, Loss_data: 0.0102, Loss_ode: 0.0573\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27330, Loss_data: 0.0101, Loss_ode: 0.0551\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27340, Loss_data: 0.0100, Loss_ode: 0.0558\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27350, Loss_data: 0.0100, Loss_ode: 0.0574\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27360, Loss_data: 0.0100, Loss_ode: 0.0542\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27370, Loss_data: 0.0100, Loss_ode: 0.0556\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27380, Loss_data: 0.0101, Loss_ode: 0.0555\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27390, Loss_data: 0.0101, Loss_ode: 0.0526\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27400, Loss_data: 0.0101, Loss_ode: 0.0552\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27410, Loss_data: 0.0100, Loss_ode: 0.0553\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27420, Loss_data: 0.0100, Loss_ode: 0.0538\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27430, Loss_data: 0.0100, Loss_ode: 0.0530\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27440, Loss_data: 0.0101, Loss_ode: 0.0523\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27450, Loss_data: 0.0101, Loss_ode: 0.0543\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27460, Loss_data: 0.0100, Loss_ode: 0.0537\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27470, Loss_data: 0.0100, Loss_ode: 0.0550\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27480, Loss_data: 0.0101, Loss_ode: 0.0545\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27490, Loss_data: 0.0101, Loss_ode: 0.0541\n",
      "Current learning rate:  2.8247524899999986e-06\n",
      "Epoch 27500, Loss_data: 0.0100, Loss_ode: 0.0527\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27510, Loss_data: 0.0101, Loss_ode: 0.0533\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27520, Loss_data: 0.0100, Loss_ode: 0.0548\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27530, Loss_data: 0.0101, Loss_ode: 0.0527\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27540, Loss_data: 0.0101, Loss_ode: 0.0552\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27550, Loss_data: 0.0101, Loss_ode: 0.0532\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27560, Loss_data: 0.0101, Loss_ode: 0.0533\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27570, Loss_data: 0.0101, Loss_ode: 0.0545\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27580, Loss_data: 0.0101, Loss_ode: 0.0532\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27590, Loss_data: 0.0100, Loss_ode: 0.0544\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27600, Loss_data: 0.0100, Loss_ode: 0.0542\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27610, Loss_data: 0.0101, Loss_ode: 0.0524\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27620, Loss_data: 0.0100, Loss_ode: 0.0555\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27630, Loss_data: 0.0101, Loss_ode: 0.0505\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27640, Loss_data: 0.0100, Loss_ode: 0.0560\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27650, Loss_data: 0.0100, Loss_ode: 0.0539\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27660, Loss_data: 0.0100, Loss_ode: 0.0524\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27670, Loss_data: 0.0100, Loss_ode: 0.0529\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27680, Loss_data: 0.0100, Loss_ode: 0.0561\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27690, Loss_data: 0.0100, Loss_ode: 0.0514\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27700, Loss_data: 0.0100, Loss_ode: 0.0537\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27710, Loss_data: 0.0101, Loss_ode: 0.0518\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27720, Loss_data: 0.0101, Loss_ode: 0.0523\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27730, Loss_data: 0.0100, Loss_ode: 0.0551\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27740, Loss_data: 0.0100, Loss_ode: 0.0543\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27750, Loss_data: 0.0101, Loss_ode: 0.0517\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27760, Loss_data: 0.0100, Loss_ode: 0.0531\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27770, Loss_data: 0.0101, Loss_ode: 0.0538\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27780, Loss_data: 0.0100, Loss_ode: 0.0525\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27790, Loss_data: 0.0100, Loss_ode: 0.0524\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27800, Loss_data: 0.0100, Loss_ode: 0.0534\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27810, Loss_data: 0.0100, Loss_ode: 0.0522\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27820, Loss_data: 0.0100, Loss_ode: 0.0539\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27830, Loss_data: 0.0101, Loss_ode: 0.0540\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27840, Loss_data: 0.0101, Loss_ode: 0.0517\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27850, Loss_data: 0.0100, Loss_ode: 0.0533\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27860, Loss_data: 0.0100, Loss_ode: 0.0529\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27870, Loss_data: 0.0101, Loss_ode: 0.0540\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27880, Loss_data: 0.0101, Loss_ode: 0.0513\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27890, Loss_data: 0.0100, Loss_ode: 0.0525\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27900, Loss_data: 0.0100, Loss_ode: 0.0527\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27910, Loss_data: 0.0100, Loss_ode: 0.0506\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27920, Loss_data: 0.0100, Loss_ode: 0.0509\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27930, Loss_data: 0.0101, Loss_ode: 0.0540\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27940, Loss_data: 0.0100, Loss_ode: 0.0534\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27950, Loss_data: 0.0100, Loss_ode: 0.0521\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27960, Loss_data: 0.0101, Loss_ode: 0.0511\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27970, Loss_data: 0.0100, Loss_ode: 0.0527\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27980, Loss_data: 0.0100, Loss_ode: 0.0507\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 27990, Loss_data: 0.0101, Loss_ode: 0.0522\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28000, Loss_data: 0.0100, Loss_ode: 0.0532\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28010, Loss_data: 0.0100, Loss_ode: 0.0530\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28020, Loss_data: 0.0100, Loss_ode: 0.0522\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28030, Loss_data: 0.0101, Loss_ode: 0.0491\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28040, Loss_data: 0.0101, Loss_ode: 0.0528\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28050, Loss_data: 0.0101, Loss_ode: 0.0518\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28060, Loss_data: 0.0100, Loss_ode: 0.0527\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28070, Loss_data: 0.0100, Loss_ode: 0.0516\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28080, Loss_data: 0.0100, Loss_ode: 0.0516\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28090, Loss_data: 0.0099, Loss_ode: 0.0500\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28100, Loss_data: 0.0100, Loss_ode: 0.0500\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28110, Loss_data: 0.0100, Loss_ode: 0.0512\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28120, Loss_data: 0.0100, Loss_ode: 0.0490\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28130, Loss_data: 0.0100, Loss_ode: 0.0520\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28140, Loss_data: 0.0100, Loss_ode: 0.0541\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28150, Loss_data: 0.0100, Loss_ode: 0.0532\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28160, Loss_data: 0.0100, Loss_ode: 0.0522\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28170, Loss_data: 0.0101, Loss_ode: 0.0496\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28180, Loss_data: 0.0100, Loss_ode: 0.0508\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28190, Loss_data: 0.0101, Loss_ode: 0.0498\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28200, Loss_data: 0.0101, Loss_ode: 0.0500\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28210, Loss_data: 0.0100, Loss_ode: 0.0503\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28220, Loss_data: 0.0100, Loss_ode: 0.0505\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28230, Loss_data: 0.0101, Loss_ode: 0.0504\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28240, Loss_data: 0.0100, Loss_ode: 0.0494\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28250, Loss_data: 0.0100, Loss_ode: 0.0527\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28260, Loss_data: 0.0100, Loss_ode: 0.0508\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28270, Loss_data: 0.0100, Loss_ode: 0.0484\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28280, Loss_data: 0.0100, Loss_ode: 0.0487\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28290, Loss_data: 0.0100, Loss_ode: 0.0538\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28300, Loss_data: 0.0100, Loss_ode: 0.0505\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28310, Loss_data: 0.0100, Loss_ode: 0.0507\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28320, Loss_data: 0.0099, Loss_ode: 0.0507\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28330, Loss_data: 0.0101, Loss_ode: 0.0491\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28340, Loss_data: 0.0101, Loss_ode: 0.0503\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28350, Loss_data: 0.0101, Loss_ode: 0.0484\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28360, Loss_data: 0.0101, Loss_ode: 0.0485\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28370, Loss_data: 0.0100, Loss_ode: 0.0505\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28380, Loss_data: 0.0100, Loss_ode: 0.0511\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28390, Loss_data: 0.0101, Loss_ode: 0.0480\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28400, Loss_data: 0.0099, Loss_ode: 0.0492\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28410, Loss_data: 0.0100, Loss_ode: 0.0510\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28420, Loss_data: 0.0100, Loss_ode: 0.0483\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28430, Loss_data: 0.0101, Loss_ode: 0.0454\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28440, Loss_data: 0.0100, Loss_ode: 0.0492\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28450, Loss_data: 0.0100, Loss_ode: 0.0510\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28460, Loss_data: 0.0101, Loss_ode: 0.0500\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28470, Loss_data: 0.0100, Loss_ode: 0.0494\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28480, Loss_data: 0.0100, Loss_ode: 0.0496\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28490, Loss_data: 0.0100, Loss_ode: 0.0488\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28500, Loss_data: 0.0100, Loss_ode: 0.0520\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28510, Loss_data: 0.0100, Loss_ode: 0.0485\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28520, Loss_data: 0.0099, Loss_ode: 0.0502\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28530, Loss_data: 0.0100, Loss_ode: 0.0523\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28540, Loss_data: 0.0100, Loss_ode: 0.0502\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28550, Loss_data: 0.0100, Loss_ode: 0.0491\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28560, Loss_data: 0.0100, Loss_ode: 0.0497\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28570, Loss_data: 0.0099, Loss_ode: 0.0501\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28580, Loss_data: 0.0100, Loss_ode: 0.0513\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28590, Loss_data: 0.0100, Loss_ode: 0.0464\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28600, Loss_data: 0.0100, Loss_ode: 0.0480\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28610, Loss_data: 0.0099, Loss_ode: 0.0463\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28620, Loss_data: 0.0101, Loss_ode: 0.0485\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28630, Loss_data: 0.0100, Loss_ode: 0.0468\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28640, Loss_data: 0.0099, Loss_ode: 0.0461\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28650, Loss_data: 0.0099, Loss_ode: 0.0478\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28660, Loss_data: 0.0101, Loss_ode: 0.0498\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28670, Loss_data: 0.0100, Loss_ode: 0.0483\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28680, Loss_data: 0.0100, Loss_ode: 0.0485\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28690, Loss_data: 0.0100, Loss_ode: 0.0469\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28700, Loss_data: 0.0100, Loss_ode: 0.0491\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28710, Loss_data: 0.0100, Loss_ode: 0.0487\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28720, Loss_data: 0.0099, Loss_ode: 0.0481\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28730, Loss_data: 0.0099, Loss_ode: 0.0479\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28740, Loss_data: 0.0100, Loss_ode: 0.0483\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28750, Loss_data: 0.0100, Loss_ode: 0.0480\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28760, Loss_data: 0.0100, Loss_ode: 0.0502\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28770, Loss_data: 0.0100, Loss_ode: 0.0485\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28780, Loss_data: 0.0099, Loss_ode: 0.0478\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28790, Loss_data: 0.0100, Loss_ode: 0.0479\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28800, Loss_data: 0.0100, Loss_ode: 0.0465\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28810, Loss_data: 0.0100, Loss_ode: 0.0476\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28820, Loss_data: 0.0100, Loss_ode: 0.0483\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28830, Loss_data: 0.0100, Loss_ode: 0.0463\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28840, Loss_data: 0.0099, Loss_ode: 0.0487\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28850, Loss_data: 0.0100, Loss_ode: 0.0494\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28860, Loss_data: 0.0099, Loss_ode: 0.0469\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28870, Loss_data: 0.0100, Loss_ode: 0.0470\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28880, Loss_data: 0.0100, Loss_ode: 0.0470\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28890, Loss_data: 0.0100, Loss_ode: 0.0480\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28900, Loss_data: 0.0100, Loss_ode: 0.0456\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28910, Loss_data: 0.0100, Loss_ode: 0.0475\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28920, Loss_data: 0.0100, Loss_ode: 0.0464\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28930, Loss_data: 0.0100, Loss_ode: 0.0481\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28940, Loss_data: 0.0101, Loss_ode: 0.0463\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28950, Loss_data: 0.0100, Loss_ode: 0.0479\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28960, Loss_data: 0.0100, Loss_ode: 0.0479\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28970, Loss_data: 0.0100, Loss_ode: 0.0444\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28980, Loss_data: 0.0100, Loss_ode: 0.0472\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 28990, Loss_data: 0.0099, Loss_ode: 0.0468\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29000, Loss_data: 0.0100, Loss_ode: 0.0455\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29010, Loss_data: 0.0099, Loss_ode: 0.0478\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29020, Loss_data: 0.0099, Loss_ode: 0.0475\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29030, Loss_data: 0.0099, Loss_ode: 0.0464\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29040, Loss_data: 0.0099, Loss_ode: 0.0466\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29050, Loss_data: 0.0099, Loss_ode: 0.0472\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29060, Loss_data: 0.0099, Loss_ode: 0.0481\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29070, Loss_data: 0.0100, Loss_ode: 0.0455\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29080, Loss_data: 0.0100, Loss_ode: 0.0452\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29090, Loss_data: 0.0099, Loss_ode: 0.0447\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29100, Loss_data: 0.0100, Loss_ode: 0.0455\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29110, Loss_data: 0.0099, Loss_ode: 0.0488\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29120, Loss_data: 0.0099, Loss_ode: 0.0450\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29130, Loss_data: 0.0099, Loss_ode: 0.0462\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29140, Loss_data: 0.0099, Loss_ode: 0.0471\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29150, Loss_data: 0.0099, Loss_ode: 0.0461\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29160, Loss_data: 0.0099, Loss_ode: 0.0461\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29170, Loss_data: 0.0099, Loss_ode: 0.0446\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29180, Loss_data: 0.0099, Loss_ode: 0.0475\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29190, Loss_data: 0.0099, Loss_ode: 0.0483\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29200, Loss_data: 0.0099, Loss_ode: 0.0461\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29210, Loss_data: 0.0099, Loss_ode: 0.0455\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29220, Loss_data: 0.0100, Loss_ode: 0.0455\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29230, Loss_data: 0.0099, Loss_ode: 0.0452\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29240, Loss_data: 0.0099, Loss_ode: 0.0436\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29250, Loss_data: 0.0099, Loss_ode: 0.0451\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29260, Loss_data: 0.0099, Loss_ode: 0.0445\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29270, Loss_data: 0.0099, Loss_ode: 0.0470\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29280, Loss_data: 0.0098, Loss_ode: 0.0446\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29290, Loss_data: 0.0099, Loss_ode: 0.0441\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29300, Loss_data: 0.0099, Loss_ode: 0.0451\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29310, Loss_data: 0.0098, Loss_ode: 0.0468\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29320, Loss_data: 0.0099, Loss_ode: 0.0466\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29330, Loss_data: 0.0099, Loss_ode: 0.0463\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29340, Loss_data: 0.0099, Loss_ode: 0.0455\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29350, Loss_data: 0.0099, Loss_ode: 0.0450\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29360, Loss_data: 0.0099, Loss_ode: 0.0476\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29370, Loss_data: 0.0099, Loss_ode: 0.0444\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29380, Loss_data: 0.0099, Loss_ode: 0.0449\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29390, Loss_data: 0.0100, Loss_ode: 0.0453\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29400, Loss_data: 0.0099, Loss_ode: 0.0466\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29410, Loss_data: 0.0099, Loss_ode: 0.0445\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29420, Loss_data: 0.0099, Loss_ode: 0.0465\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29430, Loss_data: 0.0099, Loss_ode: 0.0459\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29440, Loss_data: 0.0099, Loss_ode: 0.0458\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29450, Loss_data: 0.0099, Loss_ode: 0.0469\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29460, Loss_data: 0.0100, Loss_ode: 0.0429\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29470, Loss_data: 0.0099, Loss_ode: 0.0439\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29480, Loss_data: 0.0099, Loss_ode: 0.0453\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29490, Loss_data: 0.0100, Loss_ode: 0.0446\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29500, Loss_data: 0.0098, Loss_ode: 0.0451\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29510, Loss_data: 0.0099, Loss_ode: 0.0462\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29520, Loss_data: 0.0099, Loss_ode: 0.0438\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29530, Loss_data: 0.0100, Loss_ode: 0.0448\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29540, Loss_data: 0.0099, Loss_ode: 0.0446\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29550, Loss_data: 0.0099, Loss_ode: 0.0448\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29560, Loss_data: 0.0098, Loss_ode: 0.0461\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29570, Loss_data: 0.0099, Loss_ode: 0.0446\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29580, Loss_data: 0.0099, Loss_ode: 0.0452\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29590, Loss_data: 0.0099, Loss_ode: 0.0451\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29600, Loss_data: 0.0100, Loss_ode: 0.0456\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29610, Loss_data: 0.0098, Loss_ode: 0.0450\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29620, Loss_data: 0.0099, Loss_ode: 0.0448\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29630, Loss_data: 0.0099, Loss_ode: 0.0444\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29640, Loss_data: 0.0099, Loss_ode: 0.0439\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29650, Loss_data: 0.0099, Loss_ode: 0.0454\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29660, Loss_data: 0.0099, Loss_ode: 0.0424\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29670, Loss_data: 0.0099, Loss_ode: 0.0451\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29680, Loss_data: 0.0099, Loss_ode: 0.0430\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29690, Loss_data: 0.0099, Loss_ode: 0.0443\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29700, Loss_data: 0.0099, Loss_ode: 0.0434\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29710, Loss_data: 0.0099, Loss_ode: 0.0436\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29720, Loss_data: 0.0099, Loss_ode: 0.0422\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29730, Loss_data: 0.0099, Loss_ode: 0.0442\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29740, Loss_data: 0.0099, Loss_ode: 0.0409\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29750, Loss_data: 0.0099, Loss_ode: 0.0445\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29760, Loss_data: 0.0099, Loss_ode: 0.0441\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29770, Loss_data: 0.0099, Loss_ode: 0.0448\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29780, Loss_data: 0.0098, Loss_ode: 0.0407\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29790, Loss_data: 0.0099, Loss_ode: 0.0462\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29800, Loss_data: 0.0098, Loss_ode: 0.0459\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29810, Loss_data: 0.0098, Loss_ode: 0.0425\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29820, Loss_data: 0.0099, Loss_ode: 0.0447\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29830, Loss_data: 0.0099, Loss_ode: 0.0451\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29840, Loss_data: 0.0098, Loss_ode: 0.0436\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29850, Loss_data: 0.0099, Loss_ode: 0.0405\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29860, Loss_data: 0.0099, Loss_ode: 0.0443\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29870, Loss_data: 0.0099, Loss_ode: 0.0417\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29880, Loss_data: 0.0099, Loss_ode: 0.0436\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29890, Loss_data: 0.0099, Loss_ode: 0.0436\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29900, Loss_data: 0.0099, Loss_ode: 0.0411\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29910, Loss_data: 0.0099, Loss_ode: 0.0444\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29920, Loss_data: 0.0099, Loss_ode: 0.0411\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29930, Loss_data: 0.0100, Loss_ode: 0.0422\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29940, Loss_data: 0.0099, Loss_ode: 0.0402\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29950, Loss_data: 0.0098, Loss_ode: 0.0409\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29960, Loss_data: 0.0099, Loss_ode: 0.0425\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29970, Loss_data: 0.0098, Loss_ode: 0.0447\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29980, Loss_data: 0.0098, Loss_ode: 0.0440\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 29990, Loss_data: 0.0099, Loss_ode: 0.0427\n",
      "Current learning rate:  1.977326742999999e-06\n",
      "Epoch 30000, Loss_data: 0.0099, Loss_ode: 0.0406\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30010, Loss_data: 0.0099, Loss_ode: 0.0440\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30020, Loss_data: 0.0099, Loss_ode: 0.0420\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30030, Loss_data: 0.0098, Loss_ode: 0.0425\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30040, Loss_data: 0.0099, Loss_ode: 0.0427\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30050, Loss_data: 0.0098, Loss_ode: 0.0437\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30060, Loss_data: 0.0098, Loss_ode: 0.0404\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30070, Loss_data: 0.0098, Loss_ode: 0.0417\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30080, Loss_data: 0.0098, Loss_ode: 0.0424\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30090, Loss_data: 0.0099, Loss_ode: 0.0403\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30100, Loss_data: 0.0098, Loss_ode: 0.0400\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30110, Loss_data: 0.0098, Loss_ode: 0.0424\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30120, Loss_data: 0.0098, Loss_ode: 0.0416\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30130, Loss_data: 0.0098, Loss_ode: 0.0436\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30140, Loss_data: 0.0098, Loss_ode: 0.0422\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30150, Loss_data: 0.0098, Loss_ode: 0.0410\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30160, Loss_data: 0.0099, Loss_ode: 0.0411\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30170, Loss_data: 0.0099, Loss_ode: 0.0421\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30180, Loss_data: 0.0098, Loss_ode: 0.0427\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30190, Loss_data: 0.0098, Loss_ode: 0.0406\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30200, Loss_data: 0.0099, Loss_ode: 0.0420\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30210, Loss_data: 0.0098, Loss_ode: 0.0414\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30220, Loss_data: 0.0098, Loss_ode: 0.0447\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30230, Loss_data: 0.0099, Loss_ode: 0.0443\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30240, Loss_data: 0.0098, Loss_ode: 0.0411\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30250, Loss_data: 0.0098, Loss_ode: 0.0442\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30260, Loss_data: 0.0099, Loss_ode: 0.0402\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30270, Loss_data: 0.0098, Loss_ode: 0.0448\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30280, Loss_data: 0.0098, Loss_ode: 0.0402\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30290, Loss_data: 0.0099, Loss_ode: 0.0407\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30300, Loss_data: 0.0099, Loss_ode: 0.0414\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30310, Loss_data: 0.0098, Loss_ode: 0.0422\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30320, Loss_data: 0.0098, Loss_ode: 0.0418\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30330, Loss_data: 0.0098, Loss_ode: 0.0416\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30340, Loss_data: 0.0098, Loss_ode: 0.0418\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30350, Loss_data: 0.0099, Loss_ode: 0.0417\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30360, Loss_data: 0.0098, Loss_ode: 0.0416\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30370, Loss_data: 0.0099, Loss_ode: 0.0408\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30380, Loss_data: 0.0098, Loss_ode: 0.0419\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30390, Loss_data: 0.0098, Loss_ode: 0.0414\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30400, Loss_data: 0.0098, Loss_ode: 0.0409\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30410, Loss_data: 0.0098, Loss_ode: 0.0408\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30420, Loss_data: 0.0098, Loss_ode: 0.0416\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30430, Loss_data: 0.0098, Loss_ode: 0.0430\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30440, Loss_data: 0.0098, Loss_ode: 0.0408\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30450, Loss_data: 0.0099, Loss_ode: 0.0405\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30460, Loss_data: 0.0098, Loss_ode: 0.0408\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30470, Loss_data: 0.0098, Loss_ode: 0.0394\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30480, Loss_data: 0.0098, Loss_ode: 0.0389\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30490, Loss_data: 0.0098, Loss_ode: 0.0420\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30500, Loss_data: 0.0098, Loss_ode: 0.0416\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30510, Loss_data: 0.0098, Loss_ode: 0.0400\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30520, Loss_data: 0.0098, Loss_ode: 0.0428\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30530, Loss_data: 0.0098, Loss_ode: 0.0397\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30540, Loss_data: 0.0098, Loss_ode: 0.0419\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30550, Loss_data: 0.0098, Loss_ode: 0.0409\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30560, Loss_data: 0.0097, Loss_ode: 0.0390\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30570, Loss_data: 0.0098, Loss_ode: 0.0422\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30580, Loss_data: 0.0098, Loss_ode: 0.0408\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30590, Loss_data: 0.0098, Loss_ode: 0.0378\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30600, Loss_data: 0.0098, Loss_ode: 0.0405\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30610, Loss_data: 0.0098, Loss_ode: 0.0415\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30620, Loss_data: 0.0098, Loss_ode: 0.0418\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30630, Loss_data: 0.0098, Loss_ode: 0.0411\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30640, Loss_data: 0.0098, Loss_ode: 0.0423\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30650, Loss_data: 0.0098, Loss_ode: 0.0410\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30660, Loss_data: 0.0098, Loss_ode: 0.0420\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30670, Loss_data: 0.0098, Loss_ode: 0.0402\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30680, Loss_data: 0.0098, Loss_ode: 0.0405\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30690, Loss_data: 0.0097, Loss_ode: 0.0371\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30700, Loss_data: 0.0098, Loss_ode: 0.0402\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30710, Loss_data: 0.0098, Loss_ode: 0.0412\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30720, Loss_data: 0.0097, Loss_ode: 0.0414\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30730, Loss_data: 0.0098, Loss_ode: 0.0393\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30740, Loss_data: 0.0098, Loss_ode: 0.0424\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30750, Loss_data: 0.0099, Loss_ode: 0.0401\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30760, Loss_data: 0.0098, Loss_ode: 0.0427\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30770, Loss_data: 0.0099, Loss_ode: 0.0393\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30780, Loss_data: 0.0098, Loss_ode: 0.0416\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30790, Loss_data: 0.0098, Loss_ode: 0.0416\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30800, Loss_data: 0.0098, Loss_ode: 0.0415\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30810, Loss_data: 0.0098, Loss_ode: 0.0402\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30820, Loss_data: 0.0099, Loss_ode: 0.0404\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30830, Loss_data: 0.0098, Loss_ode: 0.0391\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30840, Loss_data: 0.0097, Loss_ode: 0.0419\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30850, Loss_data: 0.0098, Loss_ode: 0.0384\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30860, Loss_data: 0.0098, Loss_ode: 0.0411\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30870, Loss_data: 0.0098, Loss_ode: 0.0381\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30880, Loss_data: 0.0097, Loss_ode: 0.0395\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30890, Loss_data: 0.0098, Loss_ode: 0.0371\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30900, Loss_data: 0.0098, Loss_ode: 0.0409\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30910, Loss_data: 0.0098, Loss_ode: 0.0385\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30920, Loss_data: 0.0098, Loss_ode: 0.0390\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30930, Loss_data: 0.0098, Loss_ode: 0.0390\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30940, Loss_data: 0.0098, Loss_ode: 0.0419\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30950, Loss_data: 0.0098, Loss_ode: 0.0373\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30960, Loss_data: 0.0098, Loss_ode: 0.0381\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30970, Loss_data: 0.0098, Loss_ode: 0.0393\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30980, Loss_data: 0.0098, Loss_ode: 0.0376\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 30990, Loss_data: 0.0097, Loss_ode: 0.0378\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31000, Loss_data: 0.0098, Loss_ode: 0.0389\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31010, Loss_data: 0.0098, Loss_ode: 0.0405\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31020, Loss_data: 0.0098, Loss_ode: 0.0393\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31030, Loss_data: 0.0098, Loss_ode: 0.0396\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31040, Loss_data: 0.0098, Loss_ode: 0.0388\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31050, Loss_data: 0.0098, Loss_ode: 0.0393\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31060, Loss_data: 0.0098, Loss_ode: 0.0373\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31070, Loss_data: 0.0097, Loss_ode: 0.0387\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31080, Loss_data: 0.0098, Loss_ode: 0.0400\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31090, Loss_data: 0.0098, Loss_ode: 0.0357\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31100, Loss_data: 0.0098, Loss_ode: 0.0389\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31110, Loss_data: 0.0097, Loss_ode: 0.0402\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31120, Loss_data: 0.0097, Loss_ode: 0.0390\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31130, Loss_data: 0.0097, Loss_ode: 0.0377\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31140, Loss_data: 0.0097, Loss_ode: 0.0382\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31150, Loss_data: 0.0097, Loss_ode: 0.0385\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31160, Loss_data: 0.0098, Loss_ode: 0.0383\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31170, Loss_data: 0.0098, Loss_ode: 0.0377\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31180, Loss_data: 0.0098, Loss_ode: 0.0372\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31190, Loss_data: 0.0098, Loss_ode: 0.0415\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31200, Loss_data: 0.0098, Loss_ode: 0.0390\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31210, Loss_data: 0.0097, Loss_ode: 0.0380\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31220, Loss_data: 0.0097, Loss_ode: 0.0388\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31230, Loss_data: 0.0098, Loss_ode: 0.0374\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31240, Loss_data: 0.0097, Loss_ode: 0.0390\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31250, Loss_data: 0.0097, Loss_ode: 0.0398\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31260, Loss_data: 0.0097, Loss_ode: 0.0383\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31270, Loss_data: 0.0098, Loss_ode: 0.0404\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31280, Loss_data: 0.0098, Loss_ode: 0.0383\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31290, Loss_data: 0.0097, Loss_ode: 0.0361\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31300, Loss_data: 0.0098, Loss_ode: 0.0412\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31310, Loss_data: 0.0097, Loss_ode: 0.0389\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31320, Loss_data: 0.0098, Loss_ode: 0.0364\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31330, Loss_data: 0.0098, Loss_ode: 0.0408\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31340, Loss_data: 0.0098, Loss_ode: 0.0375\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31350, Loss_data: 0.0097, Loss_ode: 0.0376\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31360, Loss_data: 0.0098, Loss_ode: 0.0379\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31370, Loss_data: 0.0097, Loss_ode: 0.0359\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31380, Loss_data: 0.0097, Loss_ode: 0.0387\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31390, Loss_data: 0.0097, Loss_ode: 0.0365\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31400, Loss_data: 0.0097, Loss_ode: 0.0382\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31410, Loss_data: 0.0098, Loss_ode: 0.0404\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31420, Loss_data: 0.0097, Loss_ode: 0.0344\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31430, Loss_data: 0.0097, Loss_ode: 0.0404\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31440, Loss_data: 0.0097, Loss_ode: 0.0374\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31450, Loss_data: 0.0097, Loss_ode: 0.0377\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31460, Loss_data: 0.0098, Loss_ode: 0.0332\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31470, Loss_data: 0.0098, Loss_ode: 0.0363\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31480, Loss_data: 0.0097, Loss_ode: 0.0393\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31490, Loss_data: 0.0097, Loss_ode: 0.0402\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31500, Loss_data: 0.0097, Loss_ode: 0.0368\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31510, Loss_data: 0.0097, Loss_ode: 0.0371\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31520, Loss_data: 0.0097, Loss_ode: 0.0360\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31530, Loss_data: 0.0097, Loss_ode: 0.0396\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31540, Loss_data: 0.0097, Loss_ode: 0.0371\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31550, Loss_data: 0.0098, Loss_ode: 0.0390\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31560, Loss_data: 0.0097, Loss_ode: 0.0372\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31570, Loss_data: 0.0097, Loss_ode: 0.0363\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31580, Loss_data: 0.0097, Loss_ode: 0.0384\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31590, Loss_data: 0.0097, Loss_ode: 0.0388\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31600, Loss_data: 0.0096, Loss_ode: 0.0390\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31610, Loss_data: 0.0097, Loss_ode: 0.0377\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31620, Loss_data: 0.0098, Loss_ode: 0.0395\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31630, Loss_data: 0.0097, Loss_ode: 0.0385\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31640, Loss_data: 0.0096, Loss_ode: 0.0377\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31650, Loss_data: 0.0097, Loss_ode: 0.0371\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31660, Loss_data: 0.0098, Loss_ode: 0.0367\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31670, Loss_data: 0.0097, Loss_ode: 0.0377\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31680, Loss_data: 0.0097, Loss_ode: 0.0356\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31690, Loss_data: 0.0097, Loss_ode: 0.0373\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31700, Loss_data: 0.0098, Loss_ode: 0.0374\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31710, Loss_data: 0.0097, Loss_ode: 0.0368\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31720, Loss_data: 0.0097, Loss_ode: 0.0367\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31730, Loss_data: 0.0097, Loss_ode: 0.0379\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31740, Loss_data: 0.0097, Loss_ode: 0.0381\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31750, Loss_data: 0.0098, Loss_ode: 0.0375\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31760, Loss_data: 0.0096, Loss_ode: 0.0374\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31770, Loss_data: 0.0097, Loss_ode: 0.0385\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31780, Loss_data: 0.0097, Loss_ode: 0.0365\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31790, Loss_data: 0.0097, Loss_ode: 0.0373\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31800, Loss_data: 0.0097, Loss_ode: 0.0376\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31810, Loss_data: 0.0096, Loss_ode: 0.0354\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31820, Loss_data: 0.0096, Loss_ode: 0.0374\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31830, Loss_data: 0.0097, Loss_ode: 0.0343\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31840, Loss_data: 0.0097, Loss_ode: 0.0362\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31850, Loss_data: 0.0096, Loss_ode: 0.0358\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31860, Loss_data: 0.0097, Loss_ode: 0.0346\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31870, Loss_data: 0.0097, Loss_ode: 0.0369\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31880, Loss_data: 0.0097, Loss_ode: 0.0356\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31890, Loss_data: 0.0096, Loss_ode: 0.0371\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31900, Loss_data: 0.0097, Loss_ode: 0.0359\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31910, Loss_data: 0.0097, Loss_ode: 0.0362\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31920, Loss_data: 0.0097, Loss_ode: 0.0335\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31930, Loss_data: 0.0097, Loss_ode: 0.0350\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31940, Loss_data: 0.0097, Loss_ode: 0.0356\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31950, Loss_data: 0.0097, Loss_ode: 0.0355\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31960, Loss_data: 0.0097, Loss_ode: 0.0346\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31970, Loss_data: 0.0097, Loss_ode: 0.0375\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31980, Loss_data: 0.0097, Loss_ode: 0.0383\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 31990, Loss_data: 0.0097, Loss_ode: 0.0362\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32000, Loss_data: 0.0097, Loss_ode: 0.0368\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32010, Loss_data: 0.0096, Loss_ode: 0.0374\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32020, Loss_data: 0.0096, Loss_ode: 0.0376\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32030, Loss_data: 0.0097, Loss_ode: 0.0363\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32040, Loss_data: 0.0097, Loss_ode: 0.0355\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32050, Loss_data: 0.0097, Loss_ode: 0.0341\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32060, Loss_data: 0.0097, Loss_ode: 0.0370\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32070, Loss_data: 0.0097, Loss_ode: 0.0397\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32080, Loss_data: 0.0096, Loss_ode: 0.0374\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32090, Loss_data: 0.0096, Loss_ode: 0.0363\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32100, Loss_data: 0.0096, Loss_ode: 0.0379\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32110, Loss_data: 0.0096, Loss_ode: 0.0338\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32120, Loss_data: 0.0096, Loss_ode: 0.0370\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32130, Loss_data: 0.0096, Loss_ode: 0.0371\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32140, Loss_data: 0.0097, Loss_ode: 0.0379\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32150, Loss_data: 0.0096, Loss_ode: 0.0352\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32160, Loss_data: 0.0096, Loss_ode: 0.0359\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32170, Loss_data: 0.0096, Loss_ode: 0.0342\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32180, Loss_data: 0.0096, Loss_ode: 0.0342\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32190, Loss_data: 0.0097, Loss_ode: 0.0336\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32200, Loss_data: 0.0097, Loss_ode: 0.0373\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32210, Loss_data: 0.0096, Loss_ode: 0.0342\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32220, Loss_data: 0.0097, Loss_ode: 0.0366\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32230, Loss_data: 0.0097, Loss_ode: 0.0362\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32240, Loss_data: 0.0096, Loss_ode: 0.0340\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32250, Loss_data: 0.0097, Loss_ode: 0.0353\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32260, Loss_data: 0.0096, Loss_ode: 0.0347\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32270, Loss_data: 0.0097, Loss_ode: 0.0363\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32280, Loss_data: 0.0096, Loss_ode: 0.0351\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32290, Loss_data: 0.0096, Loss_ode: 0.0364\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32300, Loss_data: 0.0097, Loss_ode: 0.0346\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32310, Loss_data: 0.0096, Loss_ode: 0.0357\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32320, Loss_data: 0.0097, Loss_ode: 0.0358\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32330, Loss_data: 0.0097, Loss_ode: 0.0353\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32340, Loss_data: 0.0097, Loss_ode: 0.0346\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32350, Loss_data: 0.0097, Loss_ode: 0.0375\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32360, Loss_data: 0.0096, Loss_ode: 0.0361\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32370, Loss_data: 0.0096, Loss_ode: 0.0354\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32380, Loss_data: 0.0096, Loss_ode: 0.0373\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32390, Loss_data: 0.0097, Loss_ode: 0.0352\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32400, Loss_data: 0.0097, Loss_ode: 0.0368\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32410, Loss_data: 0.0096, Loss_ode: 0.0352\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32420, Loss_data: 0.0096, Loss_ode: 0.0352\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32430, Loss_data: 0.0096, Loss_ode: 0.0348\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32440, Loss_data: 0.0096, Loss_ode: 0.0329\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32450, Loss_data: 0.0096, Loss_ode: 0.0335\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32460, Loss_data: 0.0096, Loss_ode: 0.0342\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32470, Loss_data: 0.0097, Loss_ode: 0.0349\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32480, Loss_data: 0.0096, Loss_ode: 0.0345\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32490, Loss_data: 0.0096, Loss_ode: 0.0339\n",
      "Current learning rate:  1.3841287200999992e-06\n",
      "Epoch 32500, Loss_data: 0.0096, Loss_ode: 0.0353\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32510, Loss_data: 0.0096, Loss_ode: 0.0373\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32520, Loss_data: 0.0095, Loss_ode: 0.0360\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32530, Loss_data: 0.0096, Loss_ode: 0.0340\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32540, Loss_data: 0.0096, Loss_ode: 0.0386\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32550, Loss_data: 0.0096, Loss_ode: 0.0343\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32560, Loss_data: 0.0096, Loss_ode: 0.0342\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32570, Loss_data: 0.0097, Loss_ode: 0.0331\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32580, Loss_data: 0.0097, Loss_ode: 0.0333\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32590, Loss_data: 0.0096, Loss_ode: 0.0368\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32600, Loss_data: 0.0096, Loss_ode: 0.0351\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32610, Loss_data: 0.0096, Loss_ode: 0.0322\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32620, Loss_data: 0.0096, Loss_ode: 0.0355\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32630, Loss_data: 0.0096, Loss_ode: 0.0342\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32640, Loss_data: 0.0096, Loss_ode: 0.0345\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32650, Loss_data: 0.0096, Loss_ode: 0.0345\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32660, Loss_data: 0.0095, Loss_ode: 0.0359\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32670, Loss_data: 0.0096, Loss_ode: 0.0346\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32680, Loss_data: 0.0096, Loss_ode: 0.0348\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32690, Loss_data: 0.0096, Loss_ode: 0.0337\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32700, Loss_data: 0.0096, Loss_ode: 0.0345\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32710, Loss_data: 0.0096, Loss_ode: 0.0358\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32720, Loss_data: 0.0096, Loss_ode: 0.0334\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32730, Loss_data: 0.0096, Loss_ode: 0.0339\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32740, Loss_data: 0.0097, Loss_ode: 0.0317\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32750, Loss_data: 0.0096, Loss_ode: 0.0326\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32760, Loss_data: 0.0096, Loss_ode: 0.0343\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32770, Loss_data: 0.0096, Loss_ode: 0.0348\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32780, Loss_data: 0.0096, Loss_ode: 0.0333\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32790, Loss_data: 0.0096, Loss_ode: 0.0330\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32800, Loss_data: 0.0096, Loss_ode: 0.0341\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32810, Loss_data: 0.0096, Loss_ode: 0.0327\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32820, Loss_data: 0.0096, Loss_ode: 0.0368\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32830, Loss_data: 0.0096, Loss_ode: 0.0332\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32840, Loss_data: 0.0096, Loss_ode: 0.0315\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32850, Loss_data: 0.0096, Loss_ode: 0.0335\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32860, Loss_data: 0.0096, Loss_ode: 0.0324\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32870, Loss_data: 0.0096, Loss_ode: 0.0315\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32880, Loss_data: 0.0096, Loss_ode: 0.0363\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32890, Loss_data: 0.0096, Loss_ode: 0.0327\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32900, Loss_data: 0.0096, Loss_ode: 0.0357\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32910, Loss_data: 0.0096, Loss_ode: 0.0339\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32920, Loss_data: 0.0096, Loss_ode: 0.0361\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32930, Loss_data: 0.0096, Loss_ode: 0.0329\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32940, Loss_data: 0.0096, Loss_ode: 0.0327\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32950, Loss_data: 0.0096, Loss_ode: 0.0344\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32960, Loss_data: 0.0096, Loss_ode: 0.0343\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32970, Loss_data: 0.0095, Loss_ode: 0.0323\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32980, Loss_data: 0.0096, Loss_ode: 0.0320\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 32990, Loss_data: 0.0095, Loss_ode: 0.0350\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33000, Loss_data: 0.0096, Loss_ode: 0.0346\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33010, Loss_data: 0.0096, Loss_ode: 0.0337\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33020, Loss_data: 0.0096, Loss_ode: 0.0317\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33030, Loss_data: 0.0096, Loss_ode: 0.0328\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33040, Loss_data: 0.0095, Loss_ode: 0.0344\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33050, Loss_data: 0.0096, Loss_ode: 0.0326\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33060, Loss_data: 0.0096, Loss_ode: 0.0349\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33070, Loss_data: 0.0096, Loss_ode: 0.0323\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33080, Loss_data: 0.0096, Loss_ode: 0.0319\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33090, Loss_data: 0.0095, Loss_ode: 0.0341\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33100, Loss_data: 0.0095, Loss_ode: 0.0319\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33110, Loss_data: 0.0095, Loss_ode: 0.0336\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33120, Loss_data: 0.0095, Loss_ode: 0.0318\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33130, Loss_data: 0.0095, Loss_ode: 0.0321\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33140, Loss_data: 0.0095, Loss_ode: 0.0336\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33150, Loss_data: 0.0095, Loss_ode: 0.0342\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33160, Loss_data: 0.0095, Loss_ode: 0.0355\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33170, Loss_data: 0.0096, Loss_ode: 0.0338\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33180, Loss_data: 0.0095, Loss_ode: 0.0323\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33190, Loss_data: 0.0096, Loss_ode: 0.0352\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33200, Loss_data: 0.0095, Loss_ode: 0.0323\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33210, Loss_data: 0.0095, Loss_ode: 0.0339\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33220, Loss_data: 0.0096, Loss_ode: 0.0342\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33230, Loss_data: 0.0096, Loss_ode: 0.0348\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33240, Loss_data: 0.0096, Loss_ode: 0.0335\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33250, Loss_data: 0.0096, Loss_ode: 0.0331\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33260, Loss_data: 0.0095, Loss_ode: 0.0320\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33270, Loss_data: 0.0095, Loss_ode: 0.0344\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33280, Loss_data: 0.0095, Loss_ode: 0.0335\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33290, Loss_data: 0.0095, Loss_ode: 0.0334\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33300, Loss_data: 0.0095, Loss_ode: 0.0307\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33310, Loss_data: 0.0096, Loss_ode: 0.0315\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33320, Loss_data: 0.0095, Loss_ode: 0.0356\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33330, Loss_data: 0.0095, Loss_ode: 0.0324\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33340, Loss_data: 0.0096, Loss_ode: 0.0329\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33350, Loss_data: 0.0095, Loss_ode: 0.0346\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33360, Loss_data: 0.0095, Loss_ode: 0.0327\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33370, Loss_data: 0.0096, Loss_ode: 0.0331\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33380, Loss_data: 0.0095, Loss_ode: 0.0324\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33390, Loss_data: 0.0095, Loss_ode: 0.0324\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33400, Loss_data: 0.0095, Loss_ode: 0.0336\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33410, Loss_data: 0.0096, Loss_ode: 0.0342\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33420, Loss_data: 0.0096, Loss_ode: 0.0320\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33430, Loss_data: 0.0095, Loss_ode: 0.0338\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33440, Loss_data: 0.0095, Loss_ode: 0.0334\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33450, Loss_data: 0.0095, Loss_ode: 0.0327\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33460, Loss_data: 0.0095, Loss_ode: 0.0327\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33470, Loss_data: 0.0095, Loss_ode: 0.0324\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33480, Loss_data: 0.0095, Loss_ode: 0.0335\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33490, Loss_data: 0.0095, Loss_ode: 0.0328\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33500, Loss_data: 0.0095, Loss_ode: 0.0326\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33510, Loss_data: 0.0095, Loss_ode: 0.0339\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33520, Loss_data: 0.0095, Loss_ode: 0.0338\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33530, Loss_data: 0.0095, Loss_ode: 0.0332\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33540, Loss_data: 0.0095, Loss_ode: 0.0335\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33550, Loss_data: 0.0096, Loss_ode: 0.0331\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33560, Loss_data: 0.0095, Loss_ode: 0.0322\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33570, Loss_data: 0.0095, Loss_ode: 0.0318\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33580, Loss_data: 0.0096, Loss_ode: 0.0312\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33590, Loss_data: 0.0095, Loss_ode: 0.0350\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33600, Loss_data: 0.0095, Loss_ode: 0.0312\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33610, Loss_data: 0.0095, Loss_ode: 0.0332\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33620, Loss_data: 0.0096, Loss_ode: 0.0339\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33630, Loss_data: 0.0095, Loss_ode: 0.0314\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33640, Loss_data: 0.0095, Loss_ode: 0.0320\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33650, Loss_data: 0.0095, Loss_ode: 0.0337\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33660, Loss_data: 0.0095, Loss_ode: 0.0321\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33670, Loss_data: 0.0095, Loss_ode: 0.0322\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33680, Loss_data: 0.0095, Loss_ode: 0.0315\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33690, Loss_data: 0.0095, Loss_ode: 0.0319\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33700, Loss_data: 0.0094, Loss_ode: 0.0311\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33710, Loss_data: 0.0095, Loss_ode: 0.0318\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33720, Loss_data: 0.0096, Loss_ode: 0.0314\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33730, Loss_data: 0.0095, Loss_ode: 0.0319\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33740, Loss_data: 0.0095, Loss_ode: 0.0324\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33750, Loss_data: 0.0095, Loss_ode: 0.0332\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33760, Loss_data: 0.0096, Loss_ode: 0.0327\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33770, Loss_data: 0.0095, Loss_ode: 0.0334\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33780, Loss_data: 0.0095, Loss_ode: 0.0331\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33790, Loss_data: 0.0095, Loss_ode: 0.0324\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33800, Loss_data: 0.0095, Loss_ode: 0.0316\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33810, Loss_data: 0.0095, Loss_ode: 0.0301\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33820, Loss_data: 0.0095, Loss_ode: 0.0332\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33830, Loss_data: 0.0095, Loss_ode: 0.0319\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33840, Loss_data: 0.0095, Loss_ode: 0.0292\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33850, Loss_data: 0.0095, Loss_ode: 0.0329\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33860, Loss_data: 0.0095, Loss_ode: 0.0330\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33870, Loss_data: 0.0095, Loss_ode: 0.0315\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33880, Loss_data: 0.0095, Loss_ode: 0.0305\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33890, Loss_data: 0.0095, Loss_ode: 0.0286\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33900, Loss_data: 0.0095, Loss_ode: 0.0308\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33910, Loss_data: 0.0095, Loss_ode: 0.0319\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33920, Loss_data: 0.0095, Loss_ode: 0.0298\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33930, Loss_data: 0.0095, Loss_ode: 0.0299\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33940, Loss_data: 0.0095, Loss_ode: 0.0295\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33950, Loss_data: 0.0095, Loss_ode: 0.0329\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33960, Loss_data: 0.0095, Loss_ode: 0.0325\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33970, Loss_data: 0.0094, Loss_ode: 0.0331\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33980, Loss_data: 0.0095, Loss_ode: 0.0312\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 33990, Loss_data: 0.0095, Loss_ode: 0.0321\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34000, Loss_data: 0.0095, Loss_ode: 0.0315\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34010, Loss_data: 0.0095, Loss_ode: 0.0333\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34020, Loss_data: 0.0095, Loss_ode: 0.0310\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34030, Loss_data: 0.0095, Loss_ode: 0.0312\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34040, Loss_data: 0.0094, Loss_ode: 0.0306\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34050, Loss_data: 0.0095, Loss_ode: 0.0318\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34060, Loss_data: 0.0095, Loss_ode: 0.0305\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34070, Loss_data: 0.0094, Loss_ode: 0.0330\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34080, Loss_data: 0.0095, Loss_ode: 0.0301\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34090, Loss_data: 0.0094, Loss_ode: 0.0339\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34100, Loss_data: 0.0094, Loss_ode: 0.0323\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34110, Loss_data: 0.0094, Loss_ode: 0.0303\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34120, Loss_data: 0.0095, Loss_ode: 0.0326\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34130, Loss_data: 0.0094, Loss_ode: 0.0298\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34140, Loss_data: 0.0094, Loss_ode: 0.0318\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34150, Loss_data: 0.0094, Loss_ode: 0.0308\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34160, Loss_data: 0.0094, Loss_ode: 0.0299\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34170, Loss_data: 0.0095, Loss_ode: 0.0314\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34180, Loss_data: 0.0094, Loss_ode: 0.0303\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34190, Loss_data: 0.0094, Loss_ode: 0.0302\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34200, Loss_data: 0.0094, Loss_ode: 0.0283\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34210, Loss_data: 0.0095, Loss_ode: 0.0286\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34220, Loss_data: 0.0094, Loss_ode: 0.0326\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34230, Loss_data: 0.0094, Loss_ode: 0.0322\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34240, Loss_data: 0.0094, Loss_ode: 0.0315\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34250, Loss_data: 0.0094, Loss_ode: 0.0318\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34260, Loss_data: 0.0094, Loss_ode: 0.0307\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34270, Loss_data: 0.0095, Loss_ode: 0.0326\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34280, Loss_data: 0.0094, Loss_ode: 0.0301\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34290, Loss_data: 0.0094, Loss_ode: 0.0312\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34300, Loss_data: 0.0094, Loss_ode: 0.0318\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34310, Loss_data: 0.0094, Loss_ode: 0.0302\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34320, Loss_data: 0.0094, Loss_ode: 0.0302\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34330, Loss_data: 0.0094, Loss_ode: 0.0302\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34340, Loss_data: 0.0095, Loss_ode: 0.0317\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34350, Loss_data: 0.0094, Loss_ode: 0.0309\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34360, Loss_data: 0.0094, Loss_ode: 0.0299\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34370, Loss_data: 0.0094, Loss_ode: 0.0297\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34380, Loss_data: 0.0094, Loss_ode: 0.0329\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34390, Loss_data: 0.0094, Loss_ode: 0.0313\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34400, Loss_data: 0.0094, Loss_ode: 0.0316\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34410, Loss_data: 0.0094, Loss_ode: 0.0309\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34420, Loss_data: 0.0094, Loss_ode: 0.0283\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34430, Loss_data: 0.0095, Loss_ode: 0.0318\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34440, Loss_data: 0.0095, Loss_ode: 0.0306\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34450, Loss_data: 0.0095, Loss_ode: 0.0284\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34460, Loss_data: 0.0094, Loss_ode: 0.0297\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34470, Loss_data: 0.0094, Loss_ode: 0.0305\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34480, Loss_data: 0.0094, Loss_ode: 0.0309\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34490, Loss_data: 0.0094, Loss_ode: 0.0314\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34500, Loss_data: 0.0094, Loss_ode: 0.0299\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34510, Loss_data: 0.0094, Loss_ode: 0.0300\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34520, Loss_data: 0.0094, Loss_ode: 0.0306\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34530, Loss_data: 0.0094, Loss_ode: 0.0288\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34540, Loss_data: 0.0095, Loss_ode: 0.0307\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34550, Loss_data: 0.0094, Loss_ode: 0.0302\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34560, Loss_data: 0.0094, Loss_ode: 0.0285\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34570, Loss_data: 0.0094, Loss_ode: 0.0322\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34580, Loss_data: 0.0094, Loss_ode: 0.0287\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34590, Loss_data: 0.0094, Loss_ode: 0.0318\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34600, Loss_data: 0.0095, Loss_ode: 0.0300\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34610, Loss_data: 0.0094, Loss_ode: 0.0307\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34620, Loss_data: 0.0093, Loss_ode: 0.0308\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34630, Loss_data: 0.0094, Loss_ode: 0.0266\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34640, Loss_data: 0.0094, Loss_ode: 0.0303\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34650, Loss_data: 0.0094, Loss_ode: 0.0298\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34660, Loss_data: 0.0094, Loss_ode: 0.0313\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34670, Loss_data: 0.0094, Loss_ode: 0.0328\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34680, Loss_data: 0.0094, Loss_ode: 0.0310\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34690, Loss_data: 0.0094, Loss_ode: 0.0305\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34700, Loss_data: 0.0094, Loss_ode: 0.0307\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34710, Loss_data: 0.0094, Loss_ode: 0.0285\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34720, Loss_data: 0.0094, Loss_ode: 0.0318\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34730, Loss_data: 0.0094, Loss_ode: 0.0319\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34740, Loss_data: 0.0094, Loss_ode: 0.0301\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34750, Loss_data: 0.0094, Loss_ode: 0.0283\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34760, Loss_data: 0.0094, Loss_ode: 0.0277\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34770, Loss_data: 0.0094, Loss_ode: 0.0306\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34780, Loss_data: 0.0093, Loss_ode: 0.0286\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34790, Loss_data: 0.0094, Loss_ode: 0.0291\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34800, Loss_data: 0.0094, Loss_ode: 0.0304\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34810, Loss_data: 0.0094, Loss_ode: 0.0296\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34820, Loss_data: 0.0093, Loss_ode: 0.0288\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34830, Loss_data: 0.0094, Loss_ode: 0.0268\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34840, Loss_data: 0.0094, Loss_ode: 0.0299\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34850, Loss_data: 0.0095, Loss_ode: 0.0289\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34860, Loss_data: 0.0094, Loss_ode: 0.0305\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34870, Loss_data: 0.0094, Loss_ode: 0.0312\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34880, Loss_data: 0.0094, Loss_ode: 0.0312\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34890, Loss_data: 0.0094, Loss_ode: 0.0291\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34900, Loss_data: 0.0094, Loss_ode: 0.0282\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34910, Loss_data: 0.0094, Loss_ode: 0.0292\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34920, Loss_data: 0.0094, Loss_ode: 0.0314\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34930, Loss_data: 0.0094, Loss_ode: 0.0313\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34940, Loss_data: 0.0094, Loss_ode: 0.0307\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34950, Loss_data: 0.0094, Loss_ode: 0.0294\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34960, Loss_data: 0.0094, Loss_ode: 0.0285\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34970, Loss_data: 0.0094, Loss_ode: 0.0318\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34980, Loss_data: 0.0094, Loss_ode: 0.0291\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 34990, Loss_data: 0.0094, Loss_ode: 0.0299\n",
      "Current learning rate:  9.688901040699995e-07\n",
      "Epoch 35000, Loss_data: 0.0094, Loss_ode: 0.0288\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35010, Loss_data: 0.0094, Loss_ode: 0.0293\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35020, Loss_data: 0.0094, Loss_ode: 0.0286\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35030, Loss_data: 0.0094, Loss_ode: 0.0319\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35040, Loss_data: 0.0094, Loss_ode: 0.0294\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35050, Loss_data: 0.0093, Loss_ode: 0.0277\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35060, Loss_data: 0.0093, Loss_ode: 0.0291\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35070, Loss_data: 0.0093, Loss_ode: 0.0290\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35080, Loss_data: 0.0093, Loss_ode: 0.0295\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35090, Loss_data: 0.0093, Loss_ode: 0.0298\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35100, Loss_data: 0.0094, Loss_ode: 0.0281\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35110, Loss_data: 0.0093, Loss_ode: 0.0281\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35120, Loss_data: 0.0093, Loss_ode: 0.0292\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35130, Loss_data: 0.0094, Loss_ode: 0.0291\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35140, Loss_data: 0.0093, Loss_ode: 0.0280\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35150, Loss_data: 0.0094, Loss_ode: 0.0310\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35160, Loss_data: 0.0094, Loss_ode: 0.0298\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35170, Loss_data: 0.0093, Loss_ode: 0.0272\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35180, Loss_data: 0.0093, Loss_ode: 0.0308\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35190, Loss_data: 0.0093, Loss_ode: 0.0283\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35200, Loss_data: 0.0094, Loss_ode: 0.0289\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35210, Loss_data: 0.0094, Loss_ode: 0.0272\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35220, Loss_data: 0.0094, Loss_ode: 0.0294\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35230, Loss_data: 0.0093, Loss_ode: 0.0282\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35240, Loss_data: 0.0093, Loss_ode: 0.0303\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35250, Loss_data: 0.0093, Loss_ode: 0.0289\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35260, Loss_data: 0.0093, Loss_ode: 0.0299\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35270, Loss_data: 0.0094, Loss_ode: 0.0314\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35280, Loss_data: 0.0093, Loss_ode: 0.0266\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35290, Loss_data: 0.0093, Loss_ode: 0.0303\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35300, Loss_data: 0.0094, Loss_ode: 0.0273\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35310, Loss_data: 0.0094, Loss_ode: 0.0288\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35320, Loss_data: 0.0094, Loss_ode: 0.0312\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35330, Loss_data: 0.0094, Loss_ode: 0.0275\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35340, Loss_data: 0.0094, Loss_ode: 0.0294\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35350, Loss_data: 0.0093, Loss_ode: 0.0282\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35360, Loss_data: 0.0093, Loss_ode: 0.0281\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35370, Loss_data: 0.0094, Loss_ode: 0.0289\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35380, Loss_data: 0.0094, Loss_ode: 0.0292\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35390, Loss_data: 0.0093, Loss_ode: 0.0300\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35400, Loss_data: 0.0093, Loss_ode: 0.0293\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35410, Loss_data: 0.0093, Loss_ode: 0.0310\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35420, Loss_data: 0.0094, Loss_ode: 0.0289\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35430, Loss_data: 0.0093, Loss_ode: 0.0292\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35440, Loss_data: 0.0094, Loss_ode: 0.0272\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35450, Loss_data: 0.0093, Loss_ode: 0.0274\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35460, Loss_data: 0.0093, Loss_ode: 0.0288\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35470, Loss_data: 0.0093, Loss_ode: 0.0317\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35480, Loss_data: 0.0093, Loss_ode: 0.0298\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35490, Loss_data: 0.0093, Loss_ode: 0.0277\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35500, Loss_data: 0.0094, Loss_ode: 0.0285\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35510, Loss_data: 0.0093, Loss_ode: 0.0292\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35520, Loss_data: 0.0093, Loss_ode: 0.0298\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35530, Loss_data: 0.0093, Loss_ode: 0.0308\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35540, Loss_data: 0.0094, Loss_ode: 0.0281\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35550, Loss_data: 0.0094, Loss_ode: 0.0296\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35560, Loss_data: 0.0093, Loss_ode: 0.0284\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35570, Loss_data: 0.0093, Loss_ode: 0.0278\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35580, Loss_data: 0.0094, Loss_ode: 0.0310\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35590, Loss_data: 0.0093, Loss_ode: 0.0271\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35600, Loss_data: 0.0093, Loss_ode: 0.0300\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35610, Loss_data: 0.0093, Loss_ode: 0.0285\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35620, Loss_data: 0.0093, Loss_ode: 0.0295\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35630, Loss_data: 0.0093, Loss_ode: 0.0282\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35640, Loss_data: 0.0093, Loss_ode: 0.0297\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35650, Loss_data: 0.0094, Loss_ode: 0.0279\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35660, Loss_data: 0.0093, Loss_ode: 0.0292\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35670, Loss_data: 0.0093, Loss_ode: 0.0294\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35680, Loss_data: 0.0094, Loss_ode: 0.0277\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35690, Loss_data: 0.0093, Loss_ode: 0.0291\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35700, Loss_data: 0.0093, Loss_ode: 0.0299\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35710, Loss_data: 0.0093, Loss_ode: 0.0278\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35720, Loss_data: 0.0093, Loss_ode: 0.0285\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35730, Loss_data: 0.0093, Loss_ode: 0.0293\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35740, Loss_data: 0.0093, Loss_ode: 0.0282\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35750, Loss_data: 0.0093, Loss_ode: 0.0295\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35760, Loss_data: 0.0094, Loss_ode: 0.0279\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35770, Loss_data: 0.0093, Loss_ode: 0.0277\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35780, Loss_data: 0.0093, Loss_ode: 0.0278\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35790, Loss_data: 0.0093, Loss_ode: 0.0283\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35800, Loss_data: 0.0094, Loss_ode: 0.0273\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35810, Loss_data: 0.0093, Loss_ode: 0.0270\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35820, Loss_data: 0.0093, Loss_ode: 0.0296\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35830, Loss_data: 0.0094, Loss_ode: 0.0278\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35840, Loss_data: 0.0093, Loss_ode: 0.0274\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35850, Loss_data: 0.0093, Loss_ode: 0.0269\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35860, Loss_data: 0.0093, Loss_ode: 0.0265\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35870, Loss_data: 0.0093, Loss_ode: 0.0282\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35880, Loss_data: 0.0093, Loss_ode: 0.0315\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35890, Loss_data: 0.0093, Loss_ode: 0.0280\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35900, Loss_data: 0.0093, Loss_ode: 0.0301\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35910, Loss_data: 0.0093, Loss_ode: 0.0288\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35920, Loss_data: 0.0093, Loss_ode: 0.0280\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35930, Loss_data: 0.0093, Loss_ode: 0.0259\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35940, Loss_data: 0.0093, Loss_ode: 0.0280\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35950, Loss_data: 0.0093, Loss_ode: 0.0279\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35960, Loss_data: 0.0093, Loss_ode: 0.0283\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35970, Loss_data: 0.0094, Loss_ode: 0.0288\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35980, Loss_data: 0.0093, Loss_ode: 0.0275\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 35990, Loss_data: 0.0093, Loss_ode: 0.0291\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36000, Loss_data: 0.0093, Loss_ode: 0.0286\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36010, Loss_data: 0.0093, Loss_ode: 0.0292\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36020, Loss_data: 0.0093, Loss_ode: 0.0286\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36030, Loss_data: 0.0093, Loss_ode: 0.0285\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36040, Loss_data: 0.0093, Loss_ode: 0.0273\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36050, Loss_data: 0.0093, Loss_ode: 0.0287\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36060, Loss_data: 0.0093, Loss_ode: 0.0259\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36070, Loss_data: 0.0093, Loss_ode: 0.0294\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36080, Loss_data: 0.0094, Loss_ode: 0.0295\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36090, Loss_data: 0.0093, Loss_ode: 0.0295\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Epoch 36100, Loss_data: 0.0094, Loss_ode: 0.0286\n",
      "Current learning rate:  6.782230728489996e-07\n",
      "Early stopping at epoch 36108\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('pinc_trained_exp.pth'):\n",
    "    net = torch.load(\"pinc_trained_exp.pth\")\n",
    "    print('Model loaded')\n",
    "else:\n",
    "    # Train network\n",
    "    net = main(full_df, in_train, out_train, t_start, t_end, Sin, mumax, Ks, Yxs, verbose=10)\n",
    "    torch.save(net, \"pinc_trained_exp.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PINN(\n",
       "  (input): Linear(in_features=5, out_features=128, bias=True)\n",
       "  (fc1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (fc3): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (output): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained net\n",
    "net = torch.load(\"pinc_trained_exp.pth\")\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from machinelearning_control_fedbatch import numpy_to_tensor\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "full_df['F'] = full_df['RTime'].apply(Fs)\n",
    "\n",
    "T_s = full_df['RTime'].iloc[1]\n",
    "t_test = numpy_to_tensor(np.array([full_df[\"RTime\"].values]))\n",
    "X_test = numpy_to_tensor(np.array([full_df[\"Biomass\"].values]))\n",
    "S_test = numpy_to_tensor(np.array([full_df[\"Glucose\"].values]))\n",
    "V_test = numpy_to_tensor(np.array([full_df[\"V\"].values]))\n",
    "F_test = numpy_to_tensor(np.array([full_df[\"F\"].values]))\n",
    "u_test = torch.cat([t_test, X_test, S_test, F_test], dim=1)\n",
    "x_test = torch.cat([X_test, S_test], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = X_test[0]\n",
    "S_0 = S_test[0]\n",
    "V_0 = V_test[0]\n",
    "F_0 = F_test[0]\n",
    "\n",
    "X_preds = []\n",
    "S_preds = []\n",
    "V_preds = []\n",
    "for i in range(len(u_test)):\n",
    "    x_k = net.forward(torch.tensor([T_s, X_0, S_0, V_0, F_0], dtype=torch.float32).to(DEVICE))\n",
    "    X_0 = X_test[i]\n",
    "    S_0 = S_test[i]\n",
    "    V_0 = V_test[i]\n",
    "    F_0 = F_test[i]\n",
    "    X_preds.append(x_k[0].item())\n",
    "    S_preds.append(x_k[1].item())\n",
    "    V_preds.append(x_k[2].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test = t_test.detach().cpu().numpy()\n",
    "X_test = X_test.detach().cpu().numpy()\n",
    "S_test = S_test.detach().cpu().numpy()\n",
    "V_test = V_test.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(t_test, X_test, s=10, label=\"X\")\n",
    "plt.scatter(t_test, S_test, s=10, label=\"S\")\n",
    "\n",
    "plt.plot(t_test, X_preds, marker='x', label=\"X_pred\")\n",
    "plt.plot(t_test, S_preds, marker='x', label=\"S_pred\")\n",
    "\n",
    "# Add vertical lines for feed\n",
    "for i in range(len(feeds)):\n",
    "    plt.axvline(x=feeds[\"Time\"].iloc[i], color='b', alpha=0.2, linestyle='--')\n",
    "\n",
    "plt.xlabel(\"Time (h)\")\n",
    "plt.ylabel(\"Concentration (g/L)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
