{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.fed_batch_pinn import PINN, numpy_to_tensor, train\n",
    "from src.utils import get_data_and_feed\n",
    "from typing import Optional, Union\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm \n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feed(feeds):\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.bar(feeds['Time'], feeds['F'], width=feeds['Duration'], align='edge')\n",
    "    ax.set_xlabel('Time (h)')\n",
    "    ax.set_ylabel('Feed (mL/h)')\n",
    "    ax.set_title('Feed vs Time')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_simulation(t=None, y=None, feeds: Optional[pd.DataFrame] = None, full_df: Optional[pd.DataFrame] = None, train_df: Optional[pd.DataFrame] = None, net_df: Optional[pd.DataFrame] = None, title: Optional[str] = None):\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "    if t is not None and y is not None:\n",
    "        ax1.plot(t, y[0], label='Biomass (ODE)', alpha=0.6)\n",
    "        ax1.plot(t, y[1], label='Glucose (ODE)', alpha=0.6)\n",
    "    \n",
    "    if full_df is not None:\n",
    "        ax1.scatter(full_df['RTime'], full_df['Glucose'], label='Glucose (EXP)', color='red', alpha=0.2)   \n",
    "        ax1.scatter(full_df['RTime'], full_df['Biomass'], label='Biomass (EXP)', color='green', alpha=0.2)\n",
    "    \n",
    "    if train_df is not None:\n",
    "        ax1.scatter(train_df['RTime'], train_df['Glucose'], label='Glucose (Train)', color='red', alpha=1)   \n",
    "        ax1.scatter(train_df['RTime'], train_df['Biomass'], label='Biomass (Train)', color='green', alpha=1)\n",
    "    \n",
    "    if net_df is not None:\n",
    "        ax1.scatter(net_df['RTime'], net_df['Glucose'], label='Glucose (Predicted)', marker='x', color='red', alpha=0.5)\n",
    "        ax1.scatter(net_df['RTime'], net_df['Biomass'], label='Biomass (Predicted)', marker='x', color='green', alpha=0.5)\n",
    "\n",
    "    plt.xlabel(\"Time (hours)\")\n",
    "    plt.ylabel(\"Concentration\")\n",
    "    plt.title(title)\n",
    "    \n",
    "    if feeds is not None:\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.bar(feeds['Time'], feeds['F'], width=feeds['Duration'], \\\n",
    "            align='edge', label='Feed', alpha=0.5, color=None, \\\n",
    "            edgecolor='black', linewidth=1, fill=False)\n",
    "        ax2.set_ylabel('Feed Rate')\n",
    "\n",
    "    \n",
    "    handles1, labels1 = ax1.get_legend_handles_labels()\n",
    "    if feeds is not None:\n",
    "        handles2, labels2 = ax2.get_legend_handles_labels()\n",
    "        handles = handles1 + handles2\n",
    "        labels = labels1 + labels2\n",
    "        ax2.legend(handles, labels, loc='upper left')\n",
    "    else:\n",
    "        ax1.legend(handles1, labels1, loc='upper left')\n",
    "\n",
    "    plt.show()\n",
    " \n",
    "def get_feed(feeds: pd.DataFrame, time: float) -> float:\n",
    "    for _, row in feeds.iterrows():\n",
    "        start_time = row[\"Time\"]\n",
    "        end_time = row[\"Time\"] + row[\"Duration\"]\n",
    "        if start_time <= time < end_time:\n",
    "            return row[\"F\"] / 1000\n",
    "    return 0\n",
    "\n",
    "def simulate(df: pd.DataFrame, feeds: pd.DataFrame, mu_max, Ks, Yxs, plot: bool = True):\n",
    "    mu_max = mu_max\n",
    "    Ks = Ks\n",
    "    Yxs = Yxs\n",
    "    Sin = 1.43 * 200\n",
    "\n",
    "    def system_ode(t, y):\n",
    "        X, S, V = y\n",
    "        mu = mu_max * S / (Ks + S)\n",
    "        F = get_feed(feeds, t)\n",
    "        dXdt = mu * X - F * X / V\n",
    "        dSdt = - mu * X / Yxs + F * (Sin - S) / V\n",
    "        dVdt = F\n",
    "        return [dXdt, dSdt, dVdt]\n",
    "    \n",
    "    t_start, t_end = df['RTime'].min(), df['RTime'].max()\n",
    "    t_span = (t_start, t_end)\n",
    "    y0 = [df['Biomass'].iloc[0], df['Glucose'].iloc[0], df['V'].iloc[0]]\n",
    "\n",
    "    t_eval = np.linspace(t_start, t_end, 10000)\n",
    "    sol = solve_ivp(system_ode, t_span=t_span, \\\n",
    "        y0=y0, t_eval=t_eval)\n",
    "    \n",
    "    if plot:\n",
    "        plot_simulation(sol.t, sol.y, feeds=feeds, full_df=df)\n",
    "\n",
    "    for i in range(sol.y.shape[0]):\n",
    "        sol.y[i][sol.y[i] < 0] = 0\n",
    "\n",
    "    return sol\n",
    "\n",
    "def get_predictions_df(net: nn.Module, df: pd.DataFrame):\n",
    "    net_df = pd.DataFrame(columns=['RTime', 'Biomass', 'Glucose'])\n",
    "    t_test = df['RTime'].values\n",
    "    t_test = numpy_to_tensor(t_test)\n",
    "    net_df[\"RTime\"] = df[\"RTime\"].values\n",
    "    net_df[\"Biomass\"] = net.forward(t_test).detach().cpu().numpy()[:, 0]\n",
    "    net_df[\"Glucose\"] = net.forward(t_test).detach().cpu().numpy()[:, 1]\n",
    "    net_df[\"V\"] = net.forward(t_test).detach().cpu().numpy()[:, 2]\n",
    "    net_df.loc[net_df['Glucose'] < 0, 'Glucose'] = 0\n",
    "    return net_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (11, 8)\n"
     ]
    }
   ],
   "source": [
    "FILENAME = '../data/data_processed.xlsx'\n",
    "EXPERIMENT = 'BR01'\n",
    "\n",
    "_df, feeds = get_data_and_feed(FILENAME, EXPERIMENT)\n",
    "\n",
    "# Only FED-BATCH data\n",
    "_df = _df[_df['Process'] == 'FB']\n",
    "feeds = feeds[feeds['Induction']==0]\n",
    "\n",
    "print(f'Dataset shape: {_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to literal here. Maybe you meant '==' instead of '='? (3412162932.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    16 = simulate(_df, feeds, mu_max=0.724, Ks=0.16, Yxs=0.66)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to literal here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "_ = simulate(_df, feeds, mu_max=0.724, Ks=0.16, Yxs=0.66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 5 data points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 || Total Loss: 34244756.0000, Loss Data: 277.0104, Loss ODE: 34244440.0000, Loss IC: 39.9219\n",
      "mu_max: 0.5005, Ks: 0.4995, Yxs: 0.4995\n",
      "ValueError caught. Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2500 [00:00<02:13, 18.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 || Total Loss: 1017.3076, Loss Data: 275.9870, Loss ODE: 702.0342, Loss IC: 39.2864\n",
      "mu_max: 0.5010, Ks: 0.4990, Yxs: 0.4990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 252/2500 [00:19<03:06, 12.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250 || Total Loss: 2.4645, Loss Data: 0.4237, Loss ODE: 1.9015, Loss IC: 0.1393\n",
      "mu_max: 0.4949, Ks: 0.5010, Yxs: 0.5117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 390/2500 [00:30<02:47, 12.58it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m     plot_simulation(sol\u001b[38;5;241m.\u001b[39mt, sol\u001b[38;5;241m.\u001b[39my, net_df\u001b[38;5;241m=\u001b[39mnet_df, train_df\u001b[38;5;241m=\u001b[39mdf, full_df\u001b[38;5;241m=\u001b[39m_df, title\u001b[38;5;241m=\u001b[39mtitle) \n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m net, net_df\n\u001b[0;32m---> 33\u001b[0m net, net_df \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[122], line 20\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(df, i)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m repeat:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m         net \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m         repeat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
      "File \u001b[0;32m~/dynamic-modeling/notebooks/../src/fed_batch_pinn.py:142\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, t_train, u_train, df, feeds, num_epochs, verbose)\u001b[0m\n\u001b[1;32m    139\u001b[0m loss_pde \u001b[38;5;241m=\u001b[39m loss_ode(net, feeds, df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRTime\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmin(), df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRTime\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.50\u001b[39m\n\u001b[1;32m    141\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m loss_data \u001b[38;5;241m+\u001b[39m loss_pde \u001b[38;5;241m+\u001b[39m loss_ic\n\u001b[0;32m--> 142\u001b[0m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m250\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/env/main/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/env/main/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch import Value\n",
    "\n",
    "\n",
    "def main(df: pd.DataFrame, i: int):\n",
    "    print(f'Training with {i} data points')\n",
    "    df = _df.iloc[:i]\n",
    "    t_start, t_end = df['RTime'].min(), df['RTime'].max()\n",
    "\n",
    "    t_train = numpy_to_tensor(df['RTime'].values)\n",
    "    Biomass_train = numpy_to_tensor(df['Biomass'].values)\n",
    "    Glucose_train = numpy_to_tensor(df['Glucose'].values)\n",
    "    V_train = numpy_to_tensor(df['V'].values)\n",
    "    u_train = torch.cat((Biomass_train, Glucose_train, V_train), 1)\n",
    "\n",
    "    net = PINN(input_dim=1, output_dim=3, t_start=t_start, t_end=t_end)\n",
    "\n",
    "    repeat = True\n",
    "    while repeat:\n",
    "        try:\n",
    "            net = train(net, t_train, u_train, df, feeds, num_epochs=2500, verbose=True)\n",
    "            repeat = False\n",
    "        except ValueError:\n",
    "            print('ValueError caught. Retrying...')\n",
    "\n",
    "    net_df = get_predictions_df(net, _df)    \n",
    "    display(net_df)\n",
    "    sol = simulate(_df, feeds, net.mu_max.item(), net.K_s.item(), net.Y_xs.item(), plot=False)\n",
    "\n",
    "    title = f\"mu_max: {net.mu_max.item():4f}, Ks: {net.K_s.item():4f}, Yxs: {net.Y_xs.item():.4f}\"\n",
    "    plot_simulation(sol.t, sol.y, net_df=net_df, train_df=df, full_df=_df, title=title) \n",
    "    return net, net_df\n",
    "\n",
    "net, net_df = main(_df, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
